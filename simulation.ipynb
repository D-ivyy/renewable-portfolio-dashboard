{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cb780e",
   "metadata": {},
   "source": [
    "Phase 0: Unified bootstrap generator (can create DA or RT selections)\n",
    "Phase 1a: Single generation preparation (used by both)\n",
    "Phase 1b: Unified price preparation (handles both DA and RT)\n",
    "Phase 1c: Unified revenue preparation (handles both DA and RT)\n",
    "Phase 2: Unified distribution calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9568edad",
   "metadata": {},
   "source": [
    "# Phase 0: Unified bootstrap generator (can create DA or RT selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4496c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌟 Bootstrap Selection Generator\n",
      "Select pipeline type:\n",
      "1. Day-Ahead (DA)\n",
      "2. Real-Time (RT)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 REAL-TIME Bootstrap Selection Generator - Phase 0-RT\n",
      "   (Generates monthly block selections for RT price synthetic paths)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "REAL-TIME BOOTSTRAP SELECTION GENERATOR - SITE SELECTION\n",
      "============================================================\n",
      "\n",
      "🔍 Checking sites for real-time price data...\n",
      "   Checking Albemarle_Beach_Solar... ✓ (RT prices found, starting 2012)\n",
      "   Checking Blue_Wing_Solar_Energy_Generator... ✓ (RT prices found, starting 2012)\n",
      "   Checking Lamesa_Solar... ✓ (RT prices found, starting 2016)\n",
      "   Checking Midway_Solar_Farm_III... ✓ (RT prices found, starting 2012)\n",
      "   Checking Misae_Solar... ✓ (RT prices found, starting 2012)\n",
      "   Checking Mount_Signal_Solar_Farm_II... ✓ (RT prices found, starting 2012)\n",
      "   Checking RE_Mustang_LLC... ✓ (RT prices found, starting 2012)\n",
      "\n",
      "✅ Found 7 sites with real-time price data\n",
      "\n",
      "Available options:\n",
      "0. ALL SITES (Generate selections for all sites with RT prices)\n",
      "1. Albemarle_Beach_Solar\n",
      "2. Blue_Wing_Solar_Energy_Generator\n",
      "3. Lamesa_Solar\n",
      "4. Midway_Solar_Farm_III\n",
      "5. Misae_Solar\n",
      "6. Mount_Signal_Solar_Farm_II\n",
      "7. RE_Mustang_LLC\n",
      "============================================================\n",
      "   Using random seed: 25878\n",
      "\n",
      "============================================================\n",
      "🚀 PROCESSING ALL SITES FOR REAL-TIME\n",
      "============================================================\n",
      "\n",
      "[1/7] Processing Albemarle_Beach_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing REAL-TIME bootstrap for: Albemarle_Beach_Solar\n",
      "============================================================\n",
      "\n",
      "📊 Analyzing REAL-TIME data availability for Albemarle_Beach_Solar...\n",
      "   Loading data...\n",
      "\n",
      "   📈 Generation data: 1980-2025 (46 years)\n",
      "   💰 REAL-TIME price data: 2012-2025 (14 years)\n",
      "\n",
      "   🔄 Overlapping years (Gen + RT price): 14 years\n",
      "      Years: 2012-2025\n",
      "      Using these 14 years for REAL-TIME bootstrap\n",
      "\n",
      "✅ Using 14 years with generation + real-time price\n",
      "   Years: 2012-2025\n",
      "\n",
      "🔍 Checking monthly data completeness for REAL-TIME pipeline...\n",
      "\n",
      "   Monthly data availability (Gen + RT):\n",
      "   Jan: 13 years available\n",
      "   Feb: 13 years available\n",
      "   Mar: 14 years available\n",
      "   Apr: 14 years available\n",
      "   May: 14 years available\n",
      "   Jun: 13 years available\n",
      "   Jul: 13 years available\n",
      "   Aug: 13 years available\n",
      "   Sep: 13 years available\n",
      "   Oct: 13 years available\n",
      "   Nov: 13 years available\n",
      "   Dec: 13 years available\n",
      "\n",
      "🎲 Generating 100 REAL-TIME bootstrap selections...\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME BOOTSTRAP SELECTIONS\n",
      "========================================\n",
      "\n",
      "path_1:\n",
      "   Jan: 2020\n",
      "   Feb: 2022\n",
      "   Mar: 2023\n",
      "   Apr: 2012\n",
      "   May: 2025\n",
      "   Jun: 2014\n",
      "   ...\n",
      "\n",
      "path_2:\n",
      "   Jan: 2024\n",
      "   Feb: 2020\n",
      "   Mar: 2019\n",
      "   Apr: 2017\n",
      "   May: 2017\n",
      "   Jun: 2012\n",
      "   ...\n",
      "\n",
      "path_3:\n",
      "   Jan: 2019\n",
      "   Feb: 2016\n",
      "   Mar: 2014\n",
      "   Apr: 2020\n",
      "   May: 2014\n",
      "   Jun: 2016\n",
      "   ...\n",
      "\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Albemarle_Beach_Solar_bootstrap_selections_rt_20250716_131744.json\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Albemarle_Beach_Solar_bootstrap_selections_rt_latest.json (latest RT version)\n",
      "\n",
      "[2/7] Processing Blue_Wing_Solar_Energy_Generator...\n",
      "\n",
      "============================================================\n",
      "Processing REAL-TIME bootstrap for: Blue_Wing_Solar_Energy_Generator\n",
      "============================================================\n",
      "\n",
      "📊 Analyzing REAL-TIME data availability for Blue_Wing_Solar_Energy_Generator...\n",
      "   Loading data...\n",
      "\n",
      "   📈 Generation data: 1980-2024 (45 years)\n",
      "   💰 REAL-TIME price data: 2012-2024 (13 years)\n",
      "\n",
      "   🔄 Overlapping years (Gen + RT price): 13 years\n",
      "      Years: 2012-2024\n",
      "      Using these 13 years for REAL-TIME bootstrap\n",
      "\n",
      "✅ Using 13 years with generation + real-time price\n",
      "   Years: 2012-2024\n",
      "\n",
      "🔍 Checking monthly data completeness for REAL-TIME pipeline...\n",
      "\n",
      "   Monthly data availability (Gen + RT):\n",
      "   Jan: 12 years available\n",
      "   Feb: 12 years available\n",
      "   Mar: 13 years available\n",
      "   Apr: 13 years available\n",
      "   May: 13 years available\n",
      "   Jun: 13 years available\n",
      "   Jul: 13 years available\n",
      "   Aug: 13 years available\n",
      "   Sep: 13 years available\n",
      "   Oct: 13 years available\n",
      "   Nov: 13 years available\n",
      "   Dec: 13 years available\n",
      "\n",
      "🎲 Generating 100 REAL-TIME bootstrap selections...\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME BOOTSTRAP SELECTIONS\n",
      "========================================\n",
      "\n",
      "path_1:\n",
      "   Jan: 2020\n",
      "   Feb: 2014\n",
      "   Mar: 2022\n",
      "   Apr: 2013\n",
      "   May: 2021\n",
      "   Jun: 2018\n",
      "   ...\n",
      "\n",
      "path_2:\n",
      "   Jan: 2015\n",
      "   Feb: 2018\n",
      "   Mar: 2020\n",
      "   Apr: 2014\n",
      "   May: 2013\n",
      "   Jun: 2024\n",
      "   ...\n",
      "\n",
      "path_3:\n",
      "   Jan: 2015\n",
      "   Feb: 2014\n",
      "   Mar: 2012\n",
      "   Apr: 2023\n",
      "   May: 2012\n",
      "   Jun: 2020\n",
      "   ...\n",
      "\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Blue_Wing_Solar_Energy_Generator_bootstrap_selections_rt_20250716_131747.json\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Blue_Wing_Solar_Energy_Generator_bootstrap_selections_rt_latest.json (latest RT version)\n",
      "\n",
      "[3/7] Processing Lamesa_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing REAL-TIME bootstrap for: Lamesa_Solar\n",
      "============================================================\n",
      "\n",
      "📊 Analyzing REAL-TIME data availability for Lamesa_Solar...\n",
      "   Loading data...\n",
      "\n",
      "   📈 Generation data: 1980-2025 (46 years)\n",
      "   💰 REAL-TIME price data: 2016-2025 (10 years)\n",
      "\n",
      "   🔄 Overlapping years (Gen + RT price): 10 years\n",
      "      Years: 2016-2025\n",
      "      Using these 10 years for REAL-TIME bootstrap\n",
      "\n",
      "✅ Using 10 years with generation + real-time price\n",
      "   Years: 2016-2025\n",
      "\n",
      "🔍 Checking monthly data completeness for REAL-TIME pipeline...\n",
      "\n",
      "   Monthly data availability (Gen + RT):\n",
      "   Jan: 10 years available\n",
      "   Feb: 10 years available\n",
      "   Mar: 10 years available\n",
      "   Apr: 10 years available\n",
      "   May: 10 years available\n",
      "   Jun: 9 years available\n",
      "   Jul: 9 years available\n",
      "   Aug: 9 years available\n",
      "   Sep: 9 years available\n",
      "   Oct: 9 years available\n",
      "   Nov: 9 years available\n",
      "   Dec: 9 years available\n",
      "\n",
      "🎲 Generating 100 REAL-TIME bootstrap selections...\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME BOOTSTRAP SELECTIONS\n",
      "========================================\n",
      "\n",
      "path_1:\n",
      "   Jan: 2021\n",
      "   Feb: 2020\n",
      "   Mar: 2016\n",
      "   Apr: 2016\n",
      "   May: 2018\n",
      "   Jun: 2023\n",
      "   ...\n",
      "\n",
      "path_2:\n",
      "   Jan: 2024\n",
      "   Feb: 2020\n",
      "   Mar: 2019\n",
      "   Apr: 2016\n",
      "   May: 2020\n",
      "   Jun: 2017\n",
      "   ...\n",
      "\n",
      "path_3:\n",
      "   Jan: 2023\n",
      "   Feb: 2024\n",
      "   Mar: 2019\n",
      "   Apr: 2025\n",
      "   May: 2020\n",
      "   Jun: 2017\n",
      "   ...\n",
      "\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Lamesa_Solar_bootstrap_selections_rt_20250716_131750.json\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Lamesa_Solar_bootstrap_selections_rt_latest.json (latest RT version)\n",
      "\n",
      "[4/7] Processing Midway_Solar_Farm_III...\n",
      "\n",
      "============================================================\n",
      "Processing REAL-TIME bootstrap for: Midway_Solar_Farm_III\n",
      "============================================================\n",
      "\n",
      "📊 Analyzing REAL-TIME data availability for Midway_Solar_Farm_III...\n",
      "   Loading data...\n",
      "\n",
      "   📈 Generation data: 1980-2024 (45 years)\n",
      "   💰 REAL-TIME price data: 2012-2024 (13 years)\n",
      "\n",
      "   🔄 Overlapping years (Gen + RT price): 13 years\n",
      "      Years: 2012-2024\n",
      "      Using these 13 years for REAL-TIME bootstrap\n",
      "\n",
      "✅ Using 13 years with generation + real-time price\n",
      "   Years: 2012-2024\n",
      "\n",
      "🔍 Checking monthly data completeness for REAL-TIME pipeline...\n",
      "\n",
      "   Monthly data availability (Gen + RT):\n",
      "   Jan: 12 years available\n",
      "   Feb: 12 years available\n",
      "   Mar: 13 years available\n",
      "   Apr: 13 years available\n",
      "   May: 13 years available\n",
      "   Jun: 13 years available\n",
      "   Jul: 13 years available\n",
      "   Aug: 13 years available\n",
      "   Sep: 13 years available\n",
      "   Oct: 13 years available\n",
      "   Nov: 13 years available\n",
      "   Dec: 13 years available\n",
      "\n",
      "🎲 Generating 100 REAL-TIME bootstrap selections...\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME BOOTSTRAP SELECTIONS\n",
      "========================================\n",
      "\n",
      "path_1:\n",
      "   Jan: 2015\n",
      "   Feb: 2023\n",
      "   Mar: 2013\n",
      "   Apr: 2017\n",
      "   May: 2012\n",
      "   Jun: 2017\n",
      "   ...\n",
      "\n",
      "path_2:\n",
      "   Jan: 2023\n",
      "   Feb: 2022\n",
      "   Mar: 2023\n",
      "   Apr: 2023\n",
      "   May: 2014\n",
      "   Jun: 2013\n",
      "   ...\n",
      "\n",
      "path_3:\n",
      "   Jan: 2016\n",
      "   Feb: 2013\n",
      "   Mar: 2015\n",
      "   Apr: 2016\n",
      "   May: 2019\n",
      "   Jun: 2015\n",
      "   ...\n",
      "\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Midway_Solar_Farm_III_bootstrap_selections_rt_20250716_131754.json\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Midway_Solar_Farm_III_bootstrap_selections_rt_latest.json (latest RT version)\n",
      "\n",
      "[5/7] Processing Misae_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing REAL-TIME bootstrap for: Misae_Solar\n",
      "============================================================\n",
      "\n",
      "📊 Analyzing REAL-TIME data availability for Misae_Solar...\n",
      "   Loading data...\n",
      "\n",
      "   📈 Generation data: 1980-2024 (45 years)\n",
      "   💰 REAL-TIME price data: 2012-2024 (13 years)\n",
      "\n",
      "   🔄 Overlapping years (Gen + RT price): 13 years\n",
      "      Years: 2012-2024\n",
      "      Using these 13 years for REAL-TIME bootstrap\n",
      "\n",
      "✅ Using 13 years with generation + real-time price\n",
      "   Years: 2012-2024\n",
      "\n",
      "🔍 Checking monthly data completeness for REAL-TIME pipeline...\n",
      "\n",
      "   Monthly data availability (Gen + RT):\n",
      "   Jan: 12 years available\n",
      "   Feb: 12 years available\n",
      "   Mar: 13 years available\n",
      "   Apr: 13 years available\n",
      "   May: 13 years available\n",
      "   Jun: 13 years available\n",
      "   Jul: 13 years available\n",
      "   Aug: 13 years available\n",
      "   Sep: 13 years available\n",
      "   Oct: 13 years available\n",
      "   Nov: 13 years available\n",
      "   Dec: 13 years available\n",
      "\n",
      "🎲 Generating 100 REAL-TIME bootstrap selections...\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME BOOTSTRAP SELECTIONS\n",
      "========================================\n",
      "\n",
      "path_1:\n",
      "   Jan: 2024\n",
      "   Feb: 2021\n",
      "   Mar: 2018\n",
      "   Apr: 2019\n",
      "   May: 2016\n",
      "   Jun: 2023\n",
      "   ...\n",
      "\n",
      "path_2:\n",
      "   Jan: 2022\n",
      "   Feb: 2021\n",
      "   Mar: 2016\n",
      "   Apr: 2021\n",
      "   May: 2016\n",
      "   Jun: 2021\n",
      "   ...\n",
      "\n",
      "path_3:\n",
      "   Jan: 2024\n",
      "   Feb: 2024\n",
      "   Mar: 2019\n",
      "   Apr: 2013\n",
      "   May: 2023\n",
      "   Jun: 2012\n",
      "   ...\n",
      "\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Misae_Solar_bootstrap_selections_rt_20250716_131757.json\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Misae_Solar_bootstrap_selections_rt_latest.json (latest RT version)\n",
      "\n",
      "[6/7] Processing Mount_Signal_Solar_Farm_II...\n",
      "\n",
      "============================================================\n",
      "Processing REAL-TIME bootstrap for: Mount_Signal_Solar_Farm_II\n",
      "============================================================\n",
      "\n",
      "📊 Analyzing REAL-TIME data availability for Mount_Signal_Solar_Farm_II...\n",
      "   Loading data...\n",
      "\n",
      "   📈 Generation data: 1980-2024 (45 years)\n",
      "   💰 REAL-TIME price data: 2012-2024 (13 years)\n",
      "\n",
      "   🔄 Overlapping years (Gen + RT price): 13 years\n",
      "      Years: 2012-2024\n",
      "      Using these 13 years for REAL-TIME bootstrap\n",
      "\n",
      "✅ Using 13 years with generation + real-time price\n",
      "   Years: 2012-2024\n",
      "\n",
      "🔍 Checking monthly data completeness for REAL-TIME pipeline...\n",
      "\n",
      "   Monthly data availability (Gen + RT):\n",
      "   Jan: 12 years available\n",
      "   Feb: 12 years available\n",
      "   Mar: 13 years available\n",
      "   Apr: 13 years available\n",
      "   May: 13 years available\n",
      "   Jun: 13 years available\n",
      "   Jul: 13 years available\n",
      "   Aug: 13 years available\n",
      "   Sep: 13 years available\n",
      "   Oct: 13 years available\n",
      "   Nov: 13 years available\n",
      "   Dec: 13 years available\n",
      "\n",
      "🎲 Generating 100 REAL-TIME bootstrap selections...\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME BOOTSTRAP SELECTIONS\n",
      "========================================\n",
      "\n",
      "path_1:\n",
      "   Jan: 2016\n",
      "   Feb: 2023\n",
      "   Mar: 2015\n",
      "   Apr: 2018\n",
      "   May: 2016\n",
      "   Jun: 2017\n",
      "   ...\n",
      "\n",
      "path_2:\n",
      "   Jan: 2016\n",
      "   Feb: 2018\n",
      "   Mar: 2018\n",
      "   Apr: 2021\n",
      "   May: 2019\n",
      "   Jun: 2022\n",
      "   ...\n",
      "\n",
      "path_3:\n",
      "   Jan: 2017\n",
      "   Feb: 2021\n",
      "   Mar: 2020\n",
      "   Apr: 2024\n",
      "   May: 2012\n",
      "   Jun: 2023\n",
      "   ...\n",
      "\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Mount_Signal_Solar_Farm_II_bootstrap_selections_rt_20250716_131800.json\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\Mount_Signal_Solar_Farm_II_bootstrap_selections_rt_latest.json (latest RT version)\n",
      "\n",
      "[7/7] Processing RE_Mustang_LLC...\n",
      "\n",
      "============================================================\n",
      "Processing REAL-TIME bootstrap for: RE_Mustang_LLC\n",
      "============================================================\n",
      "\n",
      "📊 Analyzing REAL-TIME data availability for RE_Mustang_LLC...\n",
      "   Loading data...\n",
      "\n",
      "   📈 Generation data: 1980-2024 (45 years)\n",
      "   💰 REAL-TIME price data: 2012-2024 (13 years)\n",
      "\n",
      "   🔄 Overlapping years (Gen + RT price): 13 years\n",
      "      Years: 2012-2024\n",
      "      Using these 13 years for REAL-TIME bootstrap\n",
      "\n",
      "✅ Using 13 years with generation + real-time price\n",
      "   Years: 2012-2024\n",
      "\n",
      "🔍 Checking monthly data completeness for REAL-TIME pipeline...\n",
      "\n",
      "   Monthly data availability (Gen + RT):\n",
      "   Jan: 12 years available\n",
      "   Feb: 12 years available\n",
      "   Mar: 13 years available\n",
      "   Apr: 13 years available\n",
      "   May: 13 years available\n",
      "   Jun: 13 years available\n",
      "   Jul: 13 years available\n",
      "   Aug: 13 years available\n",
      "   Sep: 13 years available\n",
      "   Oct: 13 years available\n",
      "   Nov: 13 years available\n",
      "   Dec: 13 years available\n",
      "\n",
      "🎲 Generating 100 REAL-TIME bootstrap selections...\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME BOOTSTRAP SELECTIONS\n",
      "========================================\n",
      "\n",
      "path_1:\n",
      "   Jan: 2022\n",
      "   Feb: 2017\n",
      "   Mar: 2022\n",
      "   Apr: 2012\n",
      "   May: 2020\n",
      "   Jun: 2016\n",
      "   ...\n",
      "\n",
      "path_2:\n",
      "   Jan: 2022\n",
      "   Feb: 2017\n",
      "   Mar: 2017\n",
      "   Apr: 2019\n",
      "   May: 2013\n",
      "   Jun: 2024\n",
      "   ...\n",
      "\n",
      "path_3:\n",
      "   Jan: 2019\n",
      "   Feb: 2023\n",
      "   Mar: 2024\n",
      "   Apr: 2022\n",
      "   May: 2020\n",
      "   Jun: 2020\n",
      "   ...\n",
      "\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\RE_Mustang_LLC_bootstrap_selections_rt_20250716_131804.json\n",
      "💾 Saved: Renewable Portfolio LLC\\bootstrap_selections_rt\\RE_Mustang_LLC_bootstrap_selections_rt_latest.json (latest RT version)\n",
      "\n",
      "============================================================\n",
      "✨ REAL-TIME BOOTSTRAP GENERATION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "📊 Summary:\n",
      "   ✅ Successfully processed: 7 sites\n",
      "\n",
      "📁 REAL-TIME bootstrap selections saved in:\n",
      "   Renewable Portfolio LLC/bootstrap_selections_rt/\n",
      "\n",
      "📌 Next steps for REAL-TIME pipeline:\n",
      "   1. Run Phase 1a: Generation data preparation\n",
      "   2. Run Phase 1b: REAL-TIME price data preparation\n",
      "   3. Run Phase 1c: Real-Time Revenue Calculation\n",
      "   4. Run Phase 2: Calculate distributions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BootstrapSelectionGenerator:\n",
    "    \"\"\"\n",
    "    Phase 0: Generate bootstrap selections for synthetic paths\n",
    "    Unified implementation for both DAY-AHEAD and REAL-TIME pipelines\n",
    "    Uses Generation + Price overlap years based on pipeline type\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline_type='da'):\n",
    "        \"\"\"\n",
    "        Initialize the bootstrap generator\n",
    "        \n",
    "        Args:\n",
    "            pipeline_type (str): 'da' for day-ahead or 'rt' for real-time\n",
    "        \"\"\"\n",
    "        # Validate pipeline type\n",
    "        if pipeline_type not in ['da', 'rt']:\n",
    "            raise ValueError(\"pipeline_type must be 'da' or 'rt'\")\n",
    "        \n",
    "        self.pipeline_type = pipeline_type\n",
    "        \n",
    "        # Define paths\n",
    "        self.data_path = Path('aamani_data')\n",
    "        self.output_path = Path('Renewable Portfolio LLC')\n",
    "        \n",
    "        # Set pipeline-specific configurations\n",
    "        if pipeline_type == 'da':\n",
    "            self.bootstrap_folder = self.output_path / 'bootstrap_selections_da'\n",
    "            self.price_column_primary = 'price_da'\n",
    "            self.pipeline_name = \"DAY-AHEAD\"\n",
    "            self.pipeline_name_short = \"DA\"\n",
    "        else:  # rt\n",
    "            self.bootstrap_folder = self.output_path / 'bootstrap_selections_rt'\n",
    "            self.price_column_primary = 'price_rt'\n",
    "            self.pipeline_name = \"REAL-TIME\"\n",
    "            self.pipeline_name_short = \"RT\"\n",
    "        \n",
    "        self.bootstrap_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get available combined files\n",
    "        self.available_files = list(self.data_path.glob('*_generation_price_combined.csv'))\n",
    "        self.available_sites = [f.stem.replace('_generation_price_combined', '') for f in self.available_files]\n",
    "        \n",
    "        # Number of synthetic paths to generate\n",
    "        self.n_synthetic_paths = 10  # Default\n",
    "        \n",
    "        # Month names for display\n",
    "        self.month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        \n",
    "        # For RT, we need to track which price column to use for each site\n",
    "        self.site_price_map = {}\n",
    "    \n",
    "    def get_site_selection(self):\n",
    "        \"\"\"\n",
    "        Interactive site selection with option for all sites\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{self.pipeline_name} BOOTSTRAP SELECTION GENERATOR - SITE SELECTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.available_sites:\n",
    "            print(\"❌ No combined generation-price files found in aamani_data!\")\n",
    "            return None\n",
    "        \n",
    "        # Filter sites that have the appropriate price data\n",
    "        print(f\"\\n🔍 Checking sites for {self.pipeline_name.lower()} price data...\")\n",
    "        sites_with_price = []\n",
    "        \n",
    "        for site in self.available_sites:\n",
    "            file_path = self.data_path / f\"{site}_generation_price_combined.csv\"\n",
    "            print(f\"   Checking {site}...\", end='')\n",
    "            \n",
    "            try:\n",
    "                # Check if appropriate price column exists\n",
    "                df_header = pd.read_csv(file_path, nrows=5)\n",
    "                \n",
    "                if self.pipeline_type == 'da':\n",
    "                    # For DA, only check price_da\n",
    "                    if 'price_da' not in df_header.columns:\n",
    "                        print(\" ✗ (no price_da column)\")\n",
    "                        continue\n",
    "                    price_col_to_check = 'price_da'\n",
    "                else:  # rt\n",
    "                    # For RT, check price_rt first, then price\n",
    "                    if 'price_rt' in df_header.columns:\n",
    "                        price_col_to_check = 'price_rt'\n",
    "                    elif 'price' in df_header.columns:\n",
    "                        price_col_to_check = 'price'\n",
    "                        print(f\" (using 'price' column for RT)\", end='')\n",
    "                    else:\n",
    "                        print(\" ✗ (no price_rt or price column)\")\n",
    "                        continue\n",
    "                \n",
    "                # Check if there's actual price data\n",
    "                has_price_data = False\n",
    "                chunk_size = 10000\n",
    "                for chunk in pd.read_csv(file_path, chunksize=chunk_size, usecols=['year', price_col_to_check]):\n",
    "                    if chunk[price_col_to_check].notna().any():\n",
    "                        has_price_data = True\n",
    "                        first_year = chunk[chunk[price_col_to_check].notna()]['year'].min()\n",
    "                        print(f\" ✓ ({self.pipeline_name_short} prices found, starting {int(first_year)})\")\n",
    "                        break\n",
    "                \n",
    "                if has_price_data:\n",
    "                    sites_with_price.append(site)\n",
    "                    if self.pipeline_type == 'rt':\n",
    "                        self.site_price_map[site] = price_col_to_check\n",
    "                else:\n",
    "                    print(f\" ✗ ({price_col_to_check} column exists but no data)\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\" ✗ (error: {str(e)})\")\n",
    "        \n",
    "        if not sites_with_price:\n",
    "            print(f\"\\n❌ No sites with {self.pipeline_name.lower()} price data found!\")\n",
    "            if self.pipeline_type == 'da':\n",
    "                print(\"   Note: Checked for 'price_da' column\")\n",
    "            else:\n",
    "                print(\"   Note: Checked for both 'price_rt' and 'price' columns\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n✅ Found {len(sites_with_price)} sites with {self.pipeline_name.lower()} price data\")\n",
    "        print(\"\\nAvailable options:\")\n",
    "        print(f\"0. ALL SITES (Generate selections for all sites with {self.pipeline_name_short} prices)\")\n",
    "        for i, site in enumerate(sites_with_price):\n",
    "            print(f\"{i+1}. {site}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selection = input(\"\\n📊 Select option number (0 for all sites): \").strip()\n",
    "                if selection == '0':\n",
    "                    return 'ALL_SITES', sites_with_price\n",
    "                else:\n",
    "                    idx = int(selection) - 1\n",
    "                    if 0 <= idx < len(sites_with_price):\n",
    "                        return sites_with_price[idx], sites_with_price\n",
    "                    else:\n",
    "                        print(\"❌ Invalid selection!\")\n",
    "            except:\n",
    "                print(\"❌ Please enter a valid number!\")\n",
    "    \n",
    "    def analyze_data_availability(self, site_name):\n",
    "        \"\"\"\n",
    "        Analyze which years have both generation and price data\n",
    "        \"\"\"\n",
    "        print(f\"\\n📊 Analyzing {self.pipeline_name} data availability for {site_name}...\")\n",
    "        \n",
    "        # Load the combined file\n",
    "        file_path = self.data_path / f\"{site_name}_generation_price_combined.csv\"\n",
    "        \n",
    "        print(\"   Loading data...\")\n",
    "        \n",
    "        try:\n",
    "            # Determine which price column to use\n",
    "            if self.pipeline_type == 'da':\n",
    "                price_column = 'price_da'\n",
    "            else:  # rt\n",
    "                price_column = self.site_price_map.get(site_name, 'price_rt')\n",
    "            \n",
    "            # Check if price column exists\n",
    "            df_header = pd.read_csv(file_path, nrows=1)\n",
    "            if price_column not in df_header.columns:\n",
    "                print(f\"   ⚠️  {self.pipeline_name} price column '{price_column}' not found!\")\n",
    "                return None\n",
    "            \n",
    "            # Read only necessary columns\n",
    "            cols_to_read = ['year', 'month', 'generation_mw', price_column]\n",
    "            df = pd.read_csv(file_path, usecols=cols_to_read)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Error reading file: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "        # Find years with generation data\n",
    "        gen_years = set(int(year) for year in df[df['generation_mw'].notna()]['year'].unique())\n",
    "        \n",
    "        # Find years with price data\n",
    "        price_years = set(int(year) for year in df[df[price_column].notna()]['year'].unique())\n",
    "        \n",
    "        # Report findings\n",
    "        if gen_years:\n",
    "            print(f\"\\n   📈 Generation data: {min(gen_years)}-{max(gen_years)} ({len(gen_years)} years)\")\n",
    "        else:\n",
    "            print(\"\\n   ⚠️  No generation data found!\")\n",
    "            \n",
    "        if price_years:\n",
    "            print(f\"   💰 {self.pipeline_name} price data: {min(price_years)}-{max(price_years)} ({len(price_years)} years)\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  No {self.pipeline_name.lower()} price data found!\")\n",
    "            return None\n",
    "        \n",
    "        # Find overlapping years\n",
    "        overlap_years = gen_years & price_years\n",
    "        \n",
    "        print(f\"\\n   🔄 Overlapping years (Gen + {self.pipeline_name_short} price): {len(overlap_years)} years\")\n",
    "        if overlap_years:\n",
    "            overlap_list = sorted(list(overlap_years))\n",
    "            print(f\"      Years: {overlap_list[0]}-{overlap_list[-1]}\")\n",
    "            print(f\"      Using these {len(overlap_years)} years for {self.pipeline_name} bootstrap\")\n",
    "        \n",
    "        return overlap_years\n",
    "    \n",
    "    def check_monthly_completeness(self, site_name, years_to_use):\n",
    "        \"\"\"\n",
    "        Check which year-month combinations have complete data\n",
    "        \"\"\"\n",
    "        print(f\"\\n🔍 Checking monthly data completeness for {self.pipeline_name} pipeline...\")\n",
    "        \n",
    "        file_path = self.data_path / f\"{site_name}_generation_price_combined.csv\"\n",
    "        \n",
    "        try:\n",
    "            # Determine which price column to use\n",
    "            if self.pipeline_type == 'da':\n",
    "                price_column = 'price_da'\n",
    "            else:  # rt\n",
    "                price_column = self.site_price_map.get(site_name, 'price_rt')\n",
    "            \n",
    "            # Read only the necessary columns and overlapping years\n",
    "            cols_to_read = ['year', 'month', 'generation_mw', price_column]\n",
    "            df = pd.read_csv(file_path, usecols=cols_to_read)\n",
    "            df = df[df['year'].isin(years_to_use)]\n",
    "            \n",
    "            # Check completeness for each year-month\n",
    "            complete_months = {}\n",
    "            \n",
    "            for month in range(1, 13):\n",
    "                complete_months[month] = []\n",
    "                \n",
    "                for year in sorted(years_to_use):\n",
    "                    month_data = df[(df['year'] == year) & (df['month'] == month)]\n",
    "                    \n",
    "                    if len(month_data) > 0:\n",
    "                        # Check if both generation and price data exist\n",
    "                        has_gen = month_data['generation_mw'].notna().any()\n",
    "                        has_price = month_data[price_column].notna().any()\n",
    "                        \n",
    "                        if has_gen and has_price:\n",
    "                            complete_months[month].append(int(year))\n",
    "            \n",
    "            # Report findings\n",
    "            print(f\"\\n   Monthly data availability (Gen + {self.pipeline_name_short}):\")\n",
    "            for month in range(1, 13):\n",
    "                years_available = len(complete_months[month])\n",
    "                print(f\"   {self.month_names[month]:3s}: {years_available} years available\")\n",
    "            \n",
    "            return complete_months\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n   ⚠️  Error checking monthly completeness: {str(e)}\")\n",
    "            return {month: [] for month in range(1, 13)}\n",
    "    \n",
    "    def generate_bootstrap_selections(self, complete_months, n_paths):\n",
    "        \"\"\"\n",
    "        Generate bootstrap selections using monthly blocks\n",
    "        \"\"\"\n",
    "        print(f\"\\n🎲 Generating {n_paths} {self.pipeline_name} bootstrap selections...\")\n",
    "        \n",
    "        selections = {}\n",
    "        \n",
    "        for path_num in range(1, n_paths + 1):\n",
    "            path_selection = {}\n",
    "            \n",
    "            for month in range(1, 13):\n",
    "                available_years = complete_months[month]\n",
    "                \n",
    "                if available_years:\n",
    "                    # Randomly select a year for this month\n",
    "                    selected_year = np.random.choice(available_years)\n",
    "                    path_selection[self.month_names[month]] = int(selected_year)\n",
    "                else:\n",
    "                    # No data available for this month\n",
    "                    path_selection[self.month_names[month]] = None\n",
    "                    print(f\"   ⚠️  Warning: No {self.pipeline_name_short} data available for {self.month_names[month]}\")\n",
    "            \n",
    "            selections[f'path_{path_num}'] = path_selection\n",
    "        \n",
    "        return selections\n",
    "    \n",
    "    def save_selections(self, selections, site_name, metadata):\n",
    "        \"\"\"\n",
    "        Save bootstrap selections to JSON file\n",
    "        \"\"\"\n",
    "        # Create filename with timestamp\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f\"{site_name}_bootstrap_selections_{self.pipeline_type}_{timestamp}.json\"\n",
    "        filepath = self.bootstrap_folder / filename\n",
    "        \n",
    "        # Prepare output data\n",
    "        output = {\n",
    "            'pipeline_type': 'day_ahead' if self.pipeline_type == 'da' else 'real_time',\n",
    "            'site_name': site_name,\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'n_paths': len(selections),\n",
    "            'metadata': metadata,\n",
    "            'selections': selections\n",
    "        }\n",
    "        \n",
    "        # Save to JSON\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(output, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n💾 Saved: {filepath}\")\n",
    "        \n",
    "        # Also save a \"latest\" version for easy access\n",
    "        latest_filepath = self.bootstrap_folder / f\"{site_name}_bootstrap_selections_{self.pipeline_type}_latest.json\"\n",
    "        with open(latest_filepath, 'w') as f:\n",
    "            json.dump(output, f, indent=2)\n",
    "        \n",
    "        print(f\"💾 Saved: {latest_filepath} (latest {self.pipeline_name_short} version)\")\n",
    "        \n",
    "        return filepath\n",
    "    \n",
    "    def print_sample_selections(self, selections):\n",
    "        \"\"\"\n",
    "        Print a sample of the selections for verification\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(f\"SAMPLE {self.pipeline_name} BOOTSTRAP SELECTIONS\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # Show first 3 paths\n",
    "        for path_name in list(selections.keys())[:3]:\n",
    "            print(f\"\\n{path_name}:\")\n",
    "            path_data = selections[path_name]\n",
    "            \n",
    "            # Show first 6 months\n",
    "            for month in range(1, 7):\n",
    "                month_name = self.month_names[month]\n",
    "                year = path_data.get(month_name, 'N/A')\n",
    "                print(f\"   {month_name}: {year}\")\n",
    "            print(\"   ...\")\n",
    "    \n",
    "    def process_single_site(self, site_name):\n",
    "        \"\"\"\n",
    "        Process bootstrap generation for a single site\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing {self.pipeline_name} bootstrap for: {site_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Analyze data availability\n",
    "            overlap_years = self.analyze_data_availability(site_name)\n",
    "            \n",
    "            if not overlap_years or len(overlap_years) < 5:\n",
    "                print(f\"\\n❌ Insufficient overlapping years for {self.pipeline_name} (need at least 5)\")\n",
    "                return False\n",
    "            \n",
    "            years_list = sorted(list(overlap_years))\n",
    "            print(f\"\\n✅ Using {len(overlap_years)} years with generation + {self.pipeline_name.lower()} price\")\n",
    "            print(f\"   Years: {years_list[0]}-{years_list[-1]}\")\n",
    "            \n",
    "            # Check monthly completeness\n",
    "            complete_months = self.check_monthly_completeness(site_name, overlap_years)\n",
    "            \n",
    "            # Generate bootstrap selections\n",
    "            selections = self.generate_bootstrap_selections(complete_months, self.n_synthetic_paths)\n",
    "            \n",
    "            # Print sample\n",
    "            self.print_sample_selections(selections)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = {\n",
    "                'years_used': [int(year) for year in years_list],\n",
    "                'n_years': len(years_list),\n",
    "                'price_type': self.pipeline_type,\n",
    "                'year_range': f\"{years_list[0]}-{years_list[-1]}\"\n",
    "            }\n",
    "            \n",
    "            # Add price column info for RT\n",
    "            if self.pipeline_type == 'rt':\n",
    "                metadata['price_column'] = self.site_price_map.get(site_name, 'price_rt')\n",
    "            \n",
    "            # Save selections\n",
    "            self.save_selections(selections, site_name, metadata)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Error processing {site_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    def run_generator(self):\n",
    "        \"\"\"\n",
    "        Main function to run the bootstrap selection generator\n",
    "        \"\"\"\n",
    "        print(f\"\\n🎯 {self.pipeline_name} Bootstrap Selection Generator - Phase 0-{self.pipeline_name_short}\")\n",
    "        print(f\"   (Generates monthly block selections for {self.pipeline_name_short} price synthetic paths)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get site selection\n",
    "        site_selection = self.get_site_selection()\n",
    "        if not site_selection:\n",
    "            print(\"\\n💡 Troubleshooting tips:\")\n",
    "            if self.pipeline_type == 'da':\n",
    "                print(\"   1. Ensure your files have 'price_da' column\")\n",
    "                print(\"   2. Check that DA prices have actual values (not just empty column)\")\n",
    "                print(\"   3. DA prices typically start around 2010-2015 in most markets\")\n",
    "            else:  # rt\n",
    "                print(\"   1. Ensure your files have 'price_rt' or 'price' column\")\n",
    "                print(\"   2. Check that RT prices have actual values (not just empty column)\")\n",
    "                print(\"   3. RT prices typically start around 2015-2020 in most markets\")\n",
    "            print(\"   4. File names should match pattern: *_generation_price_combined.csv\")\n",
    "            return\n",
    "        \n",
    "        selection_type, available_sites = site_selection\n",
    "        \n",
    "        # Ask for number of synthetic paths\n",
    "        while True:\n",
    "            try:\n",
    "                n_paths = input(f\"\\n🎲 Number of synthetic paths to generate (default={self.n_synthetic_paths}): \").strip()\n",
    "                if n_paths == '':\n",
    "                    break\n",
    "                else:\n",
    "                    self.n_synthetic_paths = int(n_paths)\n",
    "                    if self.n_synthetic_paths > 0:\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"❌ Please enter a positive number!\")\n",
    "            except:\n",
    "                print(\"❌ Please enter a valid number!\")\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        seed = input(\"\\n🌱 Random seed (press Enter for random): \").strip()\n",
    "        if seed:\n",
    "            np.random.seed(int(seed))\n",
    "            print(f\"   Using seed: {seed}\")\n",
    "        else:\n",
    "            random_seed = np.random.randint(0, 100000)\n",
    "            np.random.seed(random_seed)\n",
    "            print(f\"   Using random seed: {random_seed}\")\n",
    "        \n",
    "        # Process based on selection\n",
    "        if selection_type == 'ALL_SITES':\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"🚀 PROCESSING ALL SITES FOR {self.pipeline_name}\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            for i, site_name in enumerate(available_sites, 1):\n",
    "                print(f\"\\n[{i}/{len(available_sites)}] Processing {site_name}...\")\n",
    "                \n",
    "                if self.process_single_site(site_name):\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"✨ {self.pipeline_name} BOOTSTRAP GENERATION COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\n📊 Summary:\")\n",
    "            print(f\"   ✅ Successfully processed: {successful} sites\")\n",
    "            if failed > 0:\n",
    "                print(f\"   ❌ Failed/Skipped: {failed} sites\")\n",
    "            \n",
    "            print(f\"\\n📁 {self.pipeline_name} bootstrap selections saved in:\")\n",
    "            print(f\"   Renewable Portfolio LLC/bootstrap_selections_{self.pipeline_type}/\")\n",
    "            \n",
    "        else:\n",
    "            # Process single site\n",
    "            if self.process_single_site(selection_type):\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(f\"✨ {self.pipeline_name} BOOTSTRAP GENERATION COMPLETE!\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\n{self.pipeline_name} bootstrap selections created for {selection_type}\")\n",
    "                print(f\"Number of paths: {self.n_synthetic_paths}\")\n",
    "                \n",
    "                print(f\"\\n📁 Files saved in:\")\n",
    "                print(f\"   Renewable Portfolio LLC/bootstrap_selections_{self.pipeline_type}/\")\n",
    "                print(f\"   - {selection_type}_bootstrap_selections_{self.pipeline_type}_[timestamp].json\")\n",
    "                print(f\"   - {selection_type}_bootstrap_selections_{self.pipeline_type}_latest.json\")\n",
    "        \n",
    "        print(f\"\\n📌 Next steps for {self.pipeline_name} pipeline:\")\n",
    "        print(f\"   1. Run Phase 1a: Generation data preparation\")\n",
    "        print(f\"   2. Run Phase 1b: {self.pipeline_name} price data preparation\")\n",
    "        if self.pipeline_type == 'da':\n",
    "            print(f\"   3. Run Phase 1c: Day-Ahead Revenue Calculation\")\n",
    "            print(f\"   4. Run Phase 2: Calculate distributions\")\n",
    "        else:\n",
    "            print(f\"   3. Run Phase 1c: Real-Time Revenue Calculation\")\n",
    "            print(f\"   4. Run Phase 2: Calculate distributions\")\n",
    "        \n",
    "        # Ask if user wants to generate for another site\n",
    "        another = input(f\"\\n🔄 Generate {self.pipeline_name} bootstrap selections for another site? (y/n): \").strip().lower()\n",
    "        if another == 'y':\n",
    "            self.run_generator()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask user which pipeline to run\n",
    "    print(\"\\n🌟 Bootstrap Selection Generator\")\n",
    "    print(\"Select pipeline type:\")\n",
    "    print(\"1. Day-Ahead (DA)\")\n",
    "    print(\"2. Real-Time (RT)\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
    "        if choice == '1':\n",
    "            generator = BootstrapSelectionGenerator(pipeline_type='da')\n",
    "            break\n",
    "        elif choice == '2':\n",
    "            generator = BootstrapSelectionGenerator(pipeline_type='rt')\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Invalid choice! Please enter 1 or 2.\")\n",
    "    \n",
    "    generator.run_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f457a",
   "metadata": {},
   "source": [
    "# Phase 1a: Single generation preparation (used by both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a508737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌟 Generation Data Preparation\n",
      "This will create SHARED generation data for both DA and RT pipelines\n",
      "The system will automatically use whichever bootstrap is available\n",
      "(DA bootstrap is preferred if both exist)\n",
      "\n",
      "🌟 Generation Data Preparation - Phase 1a\n",
      "   (Shared for both DA and RT pipelines)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "GENERATION DATA PREPARATION - SITE SELECTION\n",
      "(Shared for both DA and RT pipelines)\n",
      "============================================================\n",
      "\n",
      "✅ Found bootstrap selections for 7 sites\n",
      "\n",
      "Available sites:\n",
      "   • Albemarle_Beach_Solar (bootstrap available: DA, RT)\n",
      "   • Blue_Wing_Solar_Energy_Generator (bootstrap available: DA, RT)\n",
      "   • Lamesa_Solar (bootstrap available: DA, RT)\n",
      "   • Midway_Solar_Farm_III (bootstrap available: DA, RT)\n",
      "   • Misae_Solar (bootstrap available: DA, RT)\n",
      "   • Mount_Signal_Solar_Farm_II (bootstrap available: DA, RT)\n",
      "   • RE_Mustang_LLC (bootstrap available: DA, RT)\n",
      "\n",
      "Options:\n",
      "0. ALL SITES (Process all sites with bootstrap selections)\n",
      "1. Albemarle_Beach_Solar\n",
      "2. Blue_Wing_Solar_Energy_Generator\n",
      "3. Lamesa_Solar\n",
      "4. Midway_Solar_Farm_III\n",
      "5. Misae_Solar\n",
      "6. Mount_Signal_Solar_Farm_II\n",
      "7. RE_Mustang_LLC\n",
      "============================================================\n",
      "\n",
      "📅 Auto-detected period: Jul to Jun (12 months)\n",
      "   Starting from current month: Jul\n",
      "\n",
      "============================================================\n",
      "🚀 PROCESSING ALL SITES WITH BOOTSTRAP SELECTIONS\n",
      "============================================================\n",
      "\n",
      "[1/7] Processing Albemarle_Beach_Solar...\n",
      "\n",
      "📁 Loading bootstrap selections from: Albemarle_Beach_Solar_bootstrap_selections_da_latest.json\n",
      "   Using DAY-AHEAD bootstrap for generation\n",
      "   ✓ Loaded 100 path selections\n",
      "   ✓ Years used: 2012-2025 (14 years)\n",
      "   ✓ Bootstrap type: DAY-AHEAD\n",
      "\n",
      "============================================================\n",
      "Processing: Albemarle_Beach_Solar\n",
      "Using DAY-AHEAD bootstrap for generation data\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: aamani_data\\Albemarle_Beach_Solar_generation_price_combined.csv\n",
      "\n",
      "📊 Data summary:\n",
      "   All years available: 1980 to 2025 (46 years)\n",
      "   Bootstrap overlap years: 2012 to 2025 (14 years)\n",
      "   Total data points: 398,213\n",
      "   Months included: Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from bootstrap selections...\n",
      "   Creating path_1... ✓\n",
      "   Creating path_2... ✓\n",
      "   Creating path_3... ✓\n",
      "   Creating path_4... ✓\n",
      "   Creating path_5... ✓\n",
      "   Creating path_6... ✓\n",
      "   Creating path_7... ✓\n",
      "   Creating path_8... ✓\n",
      "   Creating path_9... ✓\n",
      "   Creating path_10... ✓\n",
      "   Creating path_11... ✓\n",
      "   Creating path_12... ✓\n",
      "   Creating path_13... ✓\n",
      "   Creating path_14... ✓\n",
      "   Creating path_15... ✓\n",
      "   Creating path_16... ✓\n",
      "   Creating path_17... ✓\n",
      "   Creating path_18... ✓\n",
      "   Creating path_19... ✓\n",
      "   Creating path_20... ✓\n",
      "   Creating path_21... ✓\n",
      "   Creating path_22... ✓\n",
      "   Creating path_23... ✓\n",
      "   Creating path_24... ✓\n",
      "   Creating path_25... ✓\n",
      "   Creating path_26... ✓\n",
      "   Creating path_27... ✓\n",
      "   Creating path_28... ✓\n",
      "   Creating path_29... ✓\n",
      "   Creating path_30... ✓\n",
      "   Creating path_31... ✓\n",
      "   Creating path_32... ✓\n",
      "   Creating path_33... ✓\n",
      "   Creating path_34... ✓\n",
      "   Creating path_35... ✓\n",
      "   Creating path_36... ✓\n",
      "   Creating path_37... ✓\n",
      "   Creating path_38... ✓\n",
      "   Creating path_39... ✓\n",
      "   Creating path_40... ✓\n",
      "   Creating path_41... ✓\n",
      "   Creating path_42... ✓\n",
      "   Creating path_43... ✓\n",
      "   Creating path_44... ✓\n",
      "   Creating path_45... ✓\n",
      "   Creating path_46... ✓\n",
      "   Creating path_47... ✓\n",
      "   Creating path_48... ✓\n",
      "   Creating path_49... ✓\n",
      "   Creating path_50... ✓\n",
      "   Creating path_51... ✓\n",
      "   Creating path_52... ✓\n",
      "   Creating path_53... ✓\n",
      "   Creating path_54... ✓\n",
      "   Creating path_55... ✓\n",
      "   Creating path_56... ✓\n",
      "   Creating path_57... ✓\n",
      "   Creating path_58... ✓\n",
      "   Creating path_59... ✓\n",
      "   Creating path_60... ✓\n",
      "   Creating path_61... ✓\n",
      "   Creating path_62... ✓\n",
      "   Creating path_63... ✓\n",
      "   Creating path_64... ✓\n",
      "   Creating path_65... ✓\n",
      "   Creating path_66... ✓\n",
      "   Creating path_67... ✓\n",
      "   Creating path_68... ✓\n",
      "   Creating path_69... ✓\n",
      "   Creating path_70... ✓\n",
      "   Creating path_71... ✓\n",
      "   Creating path_72... ✓\n",
      "   Creating path_73... ✓\n",
      "   Creating path_74... ✓\n",
      "   Creating path_75... ✓\n",
      "   Creating path_76... ✓\n",
      "   Creating path_77... ✓\n",
      "   Creating path_78... ✓\n",
      "   Creating path_79... ✓\n",
      "   Creating path_80... ✓\n",
      "   Creating path_81... ✓\n",
      "   Creating path_82... ✓\n",
      "   Creating path_83... ✓\n",
      "   Creating path_84... ✓\n",
      "   Creating path_85... ✓\n",
      "   Creating path_86... ✓\n",
      "   Creating path_87... ✓\n",
      "   Creating path_88... ✓\n",
      "   Creating path_89... ✓\n",
      "   Creating path_90... ✓\n",
      "   Creating path_91... ✓\n",
      "   Creating path_92... ✓\n",
      "   Creating path_93... ✓\n",
      "   Creating path_94... ✓\n",
      "   Creating path_95... ✓\n",
      "   Creating path_96... ✓\n",
      "   Creating path_97... ✓\n",
      "   Creating path_98... ✓\n",
      "   Creating path_99... ✓\n",
      "   Creating path_100... ✓\n",
      "\n",
      "   ✓ Successfully created 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 14 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 14 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 14 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (with weather)...\n",
      "   ✓ Found 13 weather variables in data\n",
      "   ✓ Created historical data:\n",
      "      - Hourly: 398213 records (with 13 weather variables)\n",
      "      - Daily: 16588 records (with 11 weather variables)\n",
      "      - Monthly: 545 records (with 11 weather variables)\n",
      "   ℹ️  Weather aggregation:\n",
      "      - Averaged: temperature_2m, relative_humidity_2m, dew_point_2m, cloud_cover, surface_pressure, wind_speed_100m, wind_speed_10m, shortwave_radiation, diffuse_radiation, direct_normal_irradiance\n",
      "      - Summed: precipitation\n",
      "      - Skipped in daily/monthly: wind_direction_100m, wind_direction_10m\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (with synthetic paths)...\n",
      "   ✓ Albemarle_Beach_Solar_generation_hourly_timeseries.csv\n",
      "   ✓ Albemarle_Beach_Solar_generation_daily_timeseries.csv\n",
      "   ✓ Albemarle_Beach_Solar_generation_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (continuous format with weather)...\n",
      "   ✓ Albemarle_Beach_Solar_generation_hourly_historical.csv\n",
      "   ✓ Albemarle_Beach_Solar_generation_daily_historical.csv\n",
      "   ✓ Albemarle_Beach_Solar_generation_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Generation/forecast/timeseries/\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Generation/historical/\n",
      "\n",
      "📌 Note: Generation data is SHARED between DA and RT pipelines\n",
      "   This run used DAY-AHEAD bootstrap selections\n",
      "   Historical files include weather data where available\n",
      "   ✓ Saved metadata: generation_metadata.json\n",
      "\n",
      "[2/7] Processing Blue_Wing_Solar_Energy_Generator...\n",
      "\n",
      "📁 Loading bootstrap selections from: Blue_Wing_Solar_Energy_Generator_bootstrap_selections_da_latest.json\n",
      "   Using DAY-AHEAD bootstrap for generation\n",
      "   ✓ Loaded 100 path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Bootstrap type: DAY-AHEAD\n",
      "\n",
      "============================================================\n",
      "Processing: Blue_Wing_Solar_Energy_Generator\n",
      "Using DAY-AHEAD bootstrap for generation data\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: aamani_data\\Blue_Wing_Solar_Energy_Generator_generation_price_combined.csv\n",
      "\n",
      "📊 Data summary:\n",
      "   All years available: 1980 to 2024 (45 years)\n",
      "   Bootstrap overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 394,589\n",
      "   Months included: Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from bootstrap selections...\n",
      "   Creating path_1... ✓\n",
      "   Creating path_2... ✓\n",
      "   Creating path_3... ✓\n",
      "   Creating path_4... ✓\n",
      "   Creating path_5... ✓\n",
      "   Creating path_6... ✓\n",
      "   Creating path_7... ✓\n",
      "   Creating path_8... ✓\n",
      "   Creating path_9... ✓\n",
      "   Creating path_10... ✓\n",
      "   Creating path_11... ✓\n",
      "   Creating path_12... ✓\n",
      "   Creating path_13... ✓\n",
      "   Creating path_14... ✓\n",
      "   Creating path_15... ✓\n",
      "   Creating path_16... ✓\n",
      "   Creating path_17... ✓\n",
      "   Creating path_18... ✓\n",
      "   Creating path_19... ✓\n",
      "   Creating path_20... ✓\n",
      "   Creating path_21... ✓\n",
      "   Creating path_22... ✓\n",
      "   Creating path_23... ✓\n",
      "   Creating path_24... ✓\n",
      "   Creating path_25... ✓\n",
      "   Creating path_26... ✓\n",
      "   Creating path_27... ✓\n",
      "   Creating path_28... ✓\n",
      "   Creating path_29... ✓\n",
      "   Creating path_30... ✓\n",
      "   Creating path_31... ✓\n",
      "   Creating path_32... ✓\n",
      "   Creating path_33... ✓\n",
      "   Creating path_34... ✓\n",
      "   Creating path_35... ✓\n",
      "   Creating path_36... ✓\n",
      "   Creating path_37... ✓\n",
      "   Creating path_38... ✓\n",
      "   Creating path_39... ✓\n",
      "   Creating path_40... ✓\n",
      "   Creating path_41... ✓\n",
      "   Creating path_42... ✓\n",
      "   Creating path_43... ✓\n",
      "   Creating path_44... ✓\n",
      "   Creating path_45... ✓\n",
      "   Creating path_46... ✓\n",
      "   Creating path_47... ✓\n",
      "   Creating path_48... ✓\n",
      "   Creating path_49... ✓\n",
      "   Creating path_50... ✓\n",
      "   Creating path_51... ✓\n",
      "   Creating path_52... ✓\n",
      "   Creating path_53... ✓\n",
      "   Creating path_54... ✓\n",
      "   Creating path_55... ✓\n",
      "   Creating path_56... ✓\n",
      "   Creating path_57... ✓\n",
      "   Creating path_58... ✓\n",
      "   Creating path_59... ✓\n",
      "   Creating path_60... ✓\n",
      "   Creating path_61... ✓\n",
      "   Creating path_62... ✓\n",
      "   Creating path_63... ✓\n",
      "   Creating path_64... ✓\n",
      "   Creating path_65... ✓\n",
      "   Creating path_66... ✓\n",
      "   Creating path_67... ✓\n",
      "   Creating path_68... ✓\n",
      "   Creating path_69... ✓\n",
      "   Creating path_70... ✓\n",
      "   Creating path_71... ✓\n",
      "   Creating path_72... ✓\n",
      "   Creating path_73... ✓\n",
      "   Creating path_74... ✓\n",
      "   Creating path_75... ✓\n",
      "   Creating path_76... ✓\n",
      "   Creating path_77... ✓\n",
      "   Creating path_78... ✓\n",
      "   Creating path_79... ✓\n",
      "   Creating path_80... ✓\n",
      "   Creating path_81... ✓\n",
      "   Creating path_82... ✓\n",
      "   Creating path_83... ✓\n",
      "   Creating path_84... ✓\n",
      "   Creating path_85... ✓\n",
      "   Creating path_86... ✓\n",
      "   Creating path_87... ✓\n",
      "   Creating path_88... ✓\n",
      "   Creating path_89... ✓\n",
      "   Creating path_90... ✓\n",
      "   Creating path_91... ✓\n",
      "   Creating path_92... ✓\n",
      "   Creating path_93... ✓\n",
      "   Creating path_94... ✓\n",
      "   Creating path_95... ✓\n",
      "   Creating path_96... ✓\n",
      "   Creating path_97... ✓\n",
      "   Creating path_98... ✓\n",
      "   Creating path_99... ✓\n",
      "   Creating path_100... ✓\n",
      "\n",
      "   ✓ Successfully created 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (with weather)...\n",
      "   ✓ Found 13 weather variables in data\n",
      "   ✓ Created historical data:\n",
      "      - Hourly: 394589 records (with 13 weather variables)\n",
      "      - Daily: 16437 records (with 11 weather variables)\n",
      "      - Monthly: 540 records (with 11 weather variables)\n",
      "   ℹ️  Weather aggregation:\n",
      "      - Averaged: temperature_2m, relative_humidity_2m, dew_point_2m, cloud_cover, surface_pressure, wind_speed_100m, wind_speed_10m, shortwave_radiation, diffuse_radiation, direct_normal_irradiance\n",
      "      - Summed: precipitation\n",
      "      - Skipped in daily/monthly: wind_direction_100m, wind_direction_10m\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (with synthetic paths)...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_hourly_timeseries.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_daily_timeseries.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (continuous format with weather)...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_hourly_historical.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_daily_historical.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Generation/forecast/timeseries/\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Generation/historical/\n",
      "\n",
      "📌 Note: Generation data is SHARED between DA and RT pipelines\n",
      "   This run used DAY-AHEAD bootstrap selections\n",
      "   Historical files include weather data where available\n",
      "   ✓ Saved metadata: generation_metadata.json\n",
      "\n",
      "[3/7] Processing Lamesa_Solar...\n",
      "\n",
      "📁 Loading bootstrap selections from: Lamesa_Solar_bootstrap_selections_da_latest.json\n",
      "   Using DAY-AHEAD bootstrap for generation\n",
      "   ✓ Loaded 100 path selections\n",
      "   ✓ Years used: 2016-2025 (10 years)\n",
      "   ✓ Bootstrap type: DAY-AHEAD\n",
      "\n",
      "============================================================\n",
      "Processing: Lamesa_Solar\n",
      "Using DAY-AHEAD bootstrap for generation data\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: aamani_data\\Lamesa_Solar_generation_price_combined.csv\n",
      "\n",
      "📊 Data summary:\n",
      "   All years available: 1980 to 2025 (46 years)\n",
      "   Bootstrap overlap years: 2016 to 2025 (10 years)\n",
      "   Total data points: 398,209\n",
      "   Months included: Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from bootstrap selections...\n",
      "   Creating path_1... ✓\n",
      "   Creating path_2... ✓\n",
      "   Creating path_3... ✓\n",
      "   Creating path_4... ✓\n",
      "   Creating path_5... ✓\n",
      "   Creating path_6... ✓\n",
      "   Creating path_7... ✓\n",
      "   Creating path_8... ✓\n",
      "   Creating path_9... ✓\n",
      "   Creating path_10... ✓\n",
      "   Creating path_11... ✓\n",
      "   Creating path_12... ✓\n",
      "   Creating path_13... ✓\n",
      "   Creating path_14... ✓\n",
      "   Creating path_15... ✓\n",
      "   Creating path_16... ✓\n",
      "   Creating path_17... ✓\n",
      "   Creating path_18... ✓\n",
      "   Creating path_19... ✓\n",
      "   Creating path_20... ✓\n",
      "   Creating path_21... ✓\n",
      "   Creating path_22... ✓\n",
      "   Creating path_23... ✓\n",
      "   Creating path_24... ✓\n",
      "   Creating path_25... ✓\n",
      "   Creating path_26... ✓\n",
      "   Creating path_27... ✓\n",
      "   Creating path_28... ✓\n",
      "   Creating path_29... ✓\n",
      "   Creating path_30... ✓\n",
      "   Creating path_31... ✓\n",
      "   Creating path_32... ✓\n",
      "   Creating path_33... ✓\n",
      "   Creating path_34... ✓\n",
      "   Creating path_35... ✓\n",
      "   Creating path_36... ✓\n",
      "   Creating path_37... ✓\n",
      "   Creating path_38... ✓\n",
      "   Creating path_39... ✓\n",
      "   Creating path_40... ✓\n",
      "   Creating path_41... ✓\n",
      "   Creating path_42... ✓\n",
      "   Creating path_43... ✓\n",
      "   Creating path_44... ✓\n",
      "   Creating path_45... ✓\n",
      "   Creating path_46... ✓\n",
      "   Creating path_47... ✓\n",
      "   Creating path_48... ✓\n",
      "   Creating path_49... ✓\n",
      "   Creating path_50... ✓\n",
      "   Creating path_51... ✓\n",
      "   Creating path_52... ✓\n",
      "   Creating path_53... ✓\n",
      "   Creating path_54... ✓\n",
      "   Creating path_55... ✓\n",
      "   Creating path_56... ✓\n",
      "   Creating path_57... ✓\n",
      "   Creating path_58... ✓\n",
      "   Creating path_59... ✓\n",
      "   Creating path_60... ✓\n",
      "   Creating path_61... ✓\n",
      "   Creating path_62... ✓\n",
      "   Creating path_63... ✓\n",
      "   Creating path_64... ✓\n",
      "   Creating path_65... ✓\n",
      "   Creating path_66... ✓\n",
      "   Creating path_67... ✓\n",
      "   Creating path_68... ✓\n",
      "   Creating path_69... ✓\n",
      "   Creating path_70... ✓\n",
      "   Creating path_71... ✓\n",
      "   Creating path_72... ✓\n",
      "   Creating path_73... ✓\n",
      "   Creating path_74... ✓\n",
      "   Creating path_75... ✓\n",
      "   Creating path_76... ✓\n",
      "   Creating path_77... ✓\n",
      "   Creating path_78... ✓\n",
      "   Creating path_79... ✓\n",
      "   Creating path_80... ✓\n",
      "   Creating path_81... ✓\n",
      "   Creating path_82... ✓\n",
      "   Creating path_83... ✓\n",
      "   Creating path_84... ✓\n",
      "   Creating path_85... ✓\n",
      "   Creating path_86... ✓\n",
      "   Creating path_87... ✓\n",
      "   Creating path_88... ✓\n",
      "   Creating path_89... ✓\n",
      "   Creating path_90... ✓\n",
      "   Creating path_91... ✓\n",
      "   Creating path_92... ✓\n",
      "   Creating path_93... ✓\n",
      "   Creating path_94... ✓\n",
      "   Creating path_95... ✓\n",
      "   Creating path_96... ✓\n",
      "   Creating path_97... ✓\n",
      "   Creating path_98... ✓\n",
      "   Creating path_99... ✓\n",
      "   Creating path_100... ✓\n",
      "\n",
      "   ✓ Successfully created 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 10 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 10 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 10 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (with weather)...\n",
      "   ✓ Found 13 weather variables in data\n",
      "   ✓ Created historical data:\n",
      "      - Hourly: 398209 records (with 13 weather variables)\n",
      "      - Daily: 16588 records (with 11 weather variables)\n",
      "      - Monthly: 545 records (with 11 weather variables)\n",
      "   ℹ️  Weather aggregation:\n",
      "      - Averaged: temperature_2m, relative_humidity_2m, dew_point_2m, cloud_cover, surface_pressure, wind_speed_100m, wind_speed_10m, shortwave_radiation, diffuse_radiation, direct_normal_irradiance\n",
      "      - Summed: precipitation\n",
      "      - Skipped in daily/monthly: wind_direction_100m, wind_direction_10m\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (with synthetic paths)...\n",
      "   ✓ Lamesa_Solar_generation_hourly_timeseries.csv\n",
      "   ✓ Lamesa_Solar_generation_daily_timeseries.csv\n",
      "   ✓ Lamesa_Solar_generation_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (continuous format with weather)...\n",
      "   ✓ Lamesa_Solar_generation_hourly_historical.csv\n",
      "   ✓ Lamesa_Solar_generation_daily_historical.csv\n",
      "   ✓ Lamesa_Solar_generation_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Generation/forecast/timeseries/\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Generation/historical/\n",
      "\n",
      "📌 Note: Generation data is SHARED between DA and RT pipelines\n",
      "   This run used DAY-AHEAD bootstrap selections\n",
      "   Historical files include weather data where available\n",
      "   ✓ Saved metadata: generation_metadata.json\n",
      "\n",
      "[4/7] Processing Midway_Solar_Farm_III...\n",
      "\n",
      "📁 Loading bootstrap selections from: Midway_Solar_Farm_III_bootstrap_selections_da_latest.json\n",
      "   Using DAY-AHEAD bootstrap for generation\n",
      "   ✓ Loaded 100 path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Bootstrap type: DAY-AHEAD\n",
      "\n",
      "============================================================\n",
      "Processing: Midway_Solar_Farm_III\n",
      "Using DAY-AHEAD bootstrap for generation data\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: aamani_data\\Midway_Solar_Farm_III_generation_price_combined.csv\n",
      "\n",
      "📊 Data summary:\n",
      "   All years available: 1980 to 2024 (45 years)\n",
      "   Bootstrap overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 394,589\n",
      "   Months included: Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from bootstrap selections...\n",
      "   Creating path_1... ✓\n",
      "   Creating path_2... ✓\n",
      "   Creating path_3... ✓\n",
      "   Creating path_4... ✓\n",
      "   Creating path_5... ✓\n",
      "   Creating path_6... ✓\n",
      "   Creating path_7... ✓\n",
      "   Creating path_8... ✓\n",
      "   Creating path_9... ✓\n",
      "   Creating path_10... ✓\n",
      "   Creating path_11... ✓\n",
      "   Creating path_12... ✓\n",
      "   Creating path_13... ✓\n",
      "   Creating path_14... ✓\n",
      "   Creating path_15... ✓\n",
      "   Creating path_16... ✓\n",
      "   Creating path_17... ✓\n",
      "   Creating path_18... ✓\n",
      "   Creating path_19... ✓\n",
      "   Creating path_20... ✓\n",
      "   Creating path_21... ✓\n",
      "   Creating path_22... ✓\n",
      "   Creating path_23... ✓\n",
      "   Creating path_24... ✓\n",
      "   Creating path_25... ✓\n",
      "   Creating path_26... ✓\n",
      "   Creating path_27... ✓\n",
      "   Creating path_28... ✓\n",
      "   Creating path_29... ✓\n",
      "   Creating path_30... ✓\n",
      "   Creating path_31... ✓\n",
      "   Creating path_32... ✓\n",
      "   Creating path_33... ✓\n",
      "   Creating path_34... ✓\n",
      "   Creating path_35... ✓\n",
      "   Creating path_36... ✓\n",
      "   Creating path_37... ✓\n",
      "   Creating path_38... ✓\n",
      "   Creating path_39... ✓\n",
      "   Creating path_40... ✓\n",
      "   Creating path_41... ✓\n",
      "   Creating path_42... ✓\n",
      "   Creating path_43... ✓\n",
      "   Creating path_44... ✓\n",
      "   Creating path_45... ✓\n",
      "   Creating path_46... ✓\n",
      "   Creating path_47... ✓\n",
      "   Creating path_48... ✓\n",
      "   Creating path_49... ✓\n",
      "   Creating path_50... ✓\n",
      "   Creating path_51... ✓\n",
      "   Creating path_52... ✓\n",
      "   Creating path_53... ✓\n",
      "   Creating path_54... ✓\n",
      "   Creating path_55... ✓\n",
      "   Creating path_56... ✓\n",
      "   Creating path_57... ✓\n",
      "   Creating path_58... ✓\n",
      "   Creating path_59... ✓\n",
      "   Creating path_60... ✓\n",
      "   Creating path_61... ✓\n",
      "   Creating path_62... ✓\n",
      "   Creating path_63... ✓\n",
      "   Creating path_64... ✓\n",
      "   Creating path_65... ✓\n",
      "   Creating path_66... ✓\n",
      "   Creating path_67... ✓\n",
      "   Creating path_68... ✓\n",
      "   Creating path_69... ✓\n",
      "   Creating path_70... ✓\n",
      "   Creating path_71... ✓\n",
      "   Creating path_72... ✓\n",
      "   Creating path_73... ✓\n",
      "   Creating path_74... ✓\n",
      "   Creating path_75... ✓\n",
      "   Creating path_76... ✓\n",
      "   Creating path_77... ✓\n",
      "   Creating path_78... ✓\n",
      "   Creating path_79... ✓\n",
      "   Creating path_80... ✓\n",
      "   Creating path_81... ✓\n",
      "   Creating path_82... ✓\n",
      "   Creating path_83... ✓\n",
      "   Creating path_84... ✓\n",
      "   Creating path_85... ✓\n",
      "   Creating path_86... ✓\n",
      "   Creating path_87... ✓\n",
      "   Creating path_88... ✓\n",
      "   Creating path_89... ✓\n",
      "   Creating path_90... ✓\n",
      "   Creating path_91... ✓\n",
      "   Creating path_92... ✓\n",
      "   Creating path_93... ✓\n",
      "   Creating path_94... ✓\n",
      "   Creating path_95... ✓\n",
      "   Creating path_96... ✓\n",
      "   Creating path_97... ✓\n",
      "   Creating path_98... ✓\n",
      "   Creating path_99... ✓\n",
      "   Creating path_100... ✓\n",
      "\n",
      "   ✓ Successfully created 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (with weather)...\n",
      "   ✓ Found 13 weather variables in data\n",
      "   ✓ Created historical data:\n",
      "      - Hourly: 394589 records (with 13 weather variables)\n",
      "      - Daily: 16437 records (with 11 weather variables)\n",
      "      - Monthly: 540 records (with 11 weather variables)\n",
      "   ℹ️  Weather aggregation:\n",
      "      - Averaged: temperature_2m, relative_humidity_2m, dew_point_2m, cloud_cover, surface_pressure, wind_speed_100m, wind_speed_10m, shortwave_radiation, diffuse_radiation, direct_normal_irradiance\n",
      "      - Summed: precipitation\n",
      "      - Skipped in daily/monthly: wind_direction_100m, wind_direction_10m\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (with synthetic paths)...\n",
      "   ✓ Midway_Solar_Farm_III_generation_hourly_timeseries.csv\n",
      "   ✓ Midway_Solar_Farm_III_generation_daily_timeseries.csv\n",
      "   ✓ Midway_Solar_Farm_III_generation_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (continuous format with weather)...\n",
      "   ✓ Midway_Solar_Farm_III_generation_hourly_historical.csv\n",
      "   ✓ Midway_Solar_Farm_III_generation_daily_historical.csv\n",
      "   ✓ Midway_Solar_Farm_III_generation_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Generation/forecast/timeseries/\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Generation/historical/\n",
      "\n",
      "📌 Note: Generation data is SHARED between DA and RT pipelines\n",
      "   This run used DAY-AHEAD bootstrap selections\n",
      "   Historical files include weather data where available\n",
      "   ✓ Saved metadata: generation_metadata.json\n",
      "\n",
      "[5/7] Processing Misae_Solar...\n",
      "\n",
      "📁 Loading bootstrap selections from: Misae_Solar_bootstrap_selections_da_latest.json\n",
      "   Using DAY-AHEAD bootstrap for generation\n",
      "   ✓ Loaded 100 path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Bootstrap type: DAY-AHEAD\n",
      "\n",
      "============================================================\n",
      "Processing: Misae_Solar\n",
      "Using DAY-AHEAD bootstrap for generation data\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: aamani_data\\Misae_Solar_generation_price_combined.csv\n",
      "\n",
      "📊 Data summary:\n",
      "   All years available: 1980 to 2024 (45 years)\n",
      "   Bootstrap overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 394,589\n",
      "   Months included: Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from bootstrap selections...\n",
      "   Creating path_1... ✓\n",
      "   Creating path_2... ✓\n",
      "   Creating path_3... ✓\n",
      "   Creating path_4... ✓\n",
      "   Creating path_5... ✓\n",
      "   Creating path_6... ✓\n",
      "   Creating path_7... ✓\n",
      "   Creating path_8... ✓\n",
      "   Creating path_9... ✓\n",
      "   Creating path_10... ✓\n",
      "   Creating path_11... ✓\n",
      "   Creating path_12... ✓\n",
      "   Creating path_13... ✓\n",
      "   Creating path_14... ✓\n",
      "   Creating path_15... ✓\n",
      "   Creating path_16... ✓\n",
      "   Creating path_17... ✓\n",
      "   Creating path_18... ✓\n",
      "   Creating path_19... ✓\n",
      "   Creating path_20... ✓\n",
      "   Creating path_21... ✓\n",
      "   Creating path_22... ✓\n",
      "   Creating path_23... ✓\n",
      "   Creating path_24... ✓\n",
      "   Creating path_25... ✓\n",
      "   Creating path_26... ✓\n",
      "   Creating path_27... ✓\n",
      "   Creating path_28... ✓\n",
      "   Creating path_29... ✓\n",
      "   Creating path_30... ✓\n",
      "   Creating path_31... ✓\n",
      "   Creating path_32... ✓\n",
      "   Creating path_33... ✓\n",
      "   Creating path_34... ✓\n",
      "   Creating path_35... ✓\n",
      "   Creating path_36... ✓\n",
      "   Creating path_37... ✓\n",
      "   Creating path_38... ✓\n",
      "   Creating path_39... ✓\n",
      "   Creating path_40... ✓\n",
      "   Creating path_41... ✓\n",
      "   Creating path_42... ✓\n",
      "   Creating path_43... ✓\n",
      "   Creating path_44... ✓\n",
      "   Creating path_45... ✓\n",
      "   Creating path_46... ✓\n",
      "   Creating path_47... ✓\n",
      "   Creating path_48... ✓\n",
      "   Creating path_49... ✓\n",
      "   Creating path_50... ✓\n",
      "   Creating path_51... ✓\n",
      "   Creating path_52... ✓\n",
      "   Creating path_53... ✓\n",
      "   Creating path_54... ✓\n",
      "   Creating path_55... ✓\n",
      "   Creating path_56... ✓\n",
      "   Creating path_57... ✓\n",
      "   Creating path_58... ✓\n",
      "   Creating path_59... ✓\n",
      "   Creating path_60... ✓\n",
      "   Creating path_61... ✓\n",
      "   Creating path_62... ✓\n",
      "   Creating path_63... ✓\n",
      "   Creating path_64... ✓\n",
      "   Creating path_65... ✓\n",
      "   Creating path_66... ✓\n",
      "   Creating path_67... ✓\n",
      "   Creating path_68... ✓\n",
      "   Creating path_69... ✓\n",
      "   Creating path_70... ✓\n",
      "   Creating path_71... ✓\n",
      "   Creating path_72... ✓\n",
      "   Creating path_73... ✓\n",
      "   Creating path_74... ✓\n",
      "   Creating path_75... ✓\n",
      "   Creating path_76... ✓\n",
      "   Creating path_77... ✓\n",
      "   Creating path_78... ✓\n",
      "   Creating path_79... ✓\n",
      "   Creating path_80... ✓\n",
      "   Creating path_81... ✓\n",
      "   Creating path_82... ✓\n",
      "   Creating path_83... ✓\n",
      "   Creating path_84... ✓\n",
      "   Creating path_85... ✓\n",
      "   Creating path_86... ✓\n",
      "   Creating path_87... ✓\n",
      "   Creating path_88... ✓\n",
      "   Creating path_89... ✓\n",
      "   Creating path_90... ✓\n",
      "   Creating path_91... ✓\n",
      "   Creating path_92... ✓\n",
      "   Creating path_93... ✓\n",
      "   Creating path_94... ✓\n",
      "   Creating path_95... ✓\n",
      "   Creating path_96... ✓\n",
      "   Creating path_97... ✓\n",
      "   Creating path_98... ✓\n",
      "   Creating path_99... ✓\n",
      "   Creating path_100... ✓\n",
      "\n",
      "   ✓ Successfully created 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (with weather)...\n",
      "   ✓ Found 13 weather variables in data\n",
      "   ✓ Created historical data:\n",
      "      - Hourly: 394589 records (with 13 weather variables)\n",
      "      - Daily: 16437 records (with 11 weather variables)\n",
      "      - Monthly: 540 records (with 11 weather variables)\n",
      "   ℹ️  Weather aggregation:\n",
      "      - Averaged: temperature_2m, relative_humidity_2m, dew_point_2m, cloud_cover, surface_pressure, wind_speed_100m, wind_speed_10m, shortwave_radiation, diffuse_radiation, direct_normal_irradiance\n",
      "      - Summed: precipitation\n",
      "      - Skipped in daily/monthly: wind_direction_100m, wind_direction_10m\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (with synthetic paths)...\n",
      "   ✓ Misae_Solar_generation_hourly_timeseries.csv\n",
      "   ✓ Misae_Solar_generation_daily_timeseries.csv\n",
      "   ✓ Misae_Solar_generation_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (continuous format with weather)...\n",
      "   ✓ Misae_Solar_generation_hourly_historical.csv\n",
      "   ✓ Misae_Solar_generation_daily_historical.csv\n",
      "   ✓ Misae_Solar_generation_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Generation/forecast/timeseries/\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Generation/historical/\n",
      "\n",
      "📌 Note: Generation data is SHARED between DA and RT pipelines\n",
      "   This run used DAY-AHEAD bootstrap selections\n",
      "   Historical files include weather data where available\n",
      "   ✓ Saved metadata: generation_metadata.json\n",
      "\n",
      "[6/7] Processing Mount_Signal_Solar_Farm_II...\n",
      "\n",
      "📁 Loading bootstrap selections from: Mount_Signal_Solar_Farm_II_bootstrap_selections_da_latest.json\n",
      "   Using DAY-AHEAD bootstrap for generation\n",
      "   ✓ Loaded 100 path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Bootstrap type: DAY-AHEAD\n",
      "\n",
      "============================================================\n",
      "Processing: Mount_Signal_Solar_Farm_II\n",
      "Using DAY-AHEAD bootstrap for generation data\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: aamani_data\\Mount_Signal_Solar_Farm_II_generation_price_combined.csv\n",
      "\n",
      "📊 Data summary:\n",
      "   All years available: 1980 to 2024 (45 years)\n",
      "   Bootstrap overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 394,589\n",
      "   Months included: Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from bootstrap selections...\n",
      "   Creating path_1... ✓\n",
      "   Creating path_2... ✓\n",
      "   Creating path_3... ✓\n",
      "   Creating path_4... ✓\n",
      "   Creating path_5... ✓\n",
      "   Creating path_6... ✓\n",
      "   Creating path_7... ✓\n",
      "   Creating path_8... ✓\n",
      "   Creating path_9... ✓\n",
      "   Creating path_10... ✓\n",
      "   Creating path_11... ✓\n",
      "   Creating path_12... ✓\n",
      "   Creating path_13... ✓\n",
      "   Creating path_14... ✓\n",
      "   Creating path_15... ✓\n",
      "   Creating path_16... ✓\n",
      "   Creating path_17... ✓\n",
      "   Creating path_18... ✓\n",
      "   Creating path_19... ✓\n",
      "   Creating path_20... ✓\n",
      "   Creating path_21... ✓\n",
      "   Creating path_22... ✓\n",
      "   Creating path_23... ✓\n",
      "   Creating path_24... ✓\n",
      "   Creating path_25... ✓\n",
      "   Creating path_26... ✓\n",
      "   Creating path_27... ✓\n",
      "   Creating path_28... ✓\n",
      "   Creating path_29... ✓\n",
      "   Creating path_30... ✓\n",
      "   Creating path_31... ✓\n",
      "   Creating path_32... ✓\n",
      "   Creating path_33... ✓\n",
      "   Creating path_34... ✓\n",
      "   Creating path_35... ✓\n",
      "   Creating path_36... ✓\n",
      "   Creating path_37... ✓\n",
      "   Creating path_38... ✓\n",
      "   Creating path_39... ✓\n",
      "   Creating path_40... ✓\n",
      "   Creating path_41... ✓\n",
      "   Creating path_42... ✓\n",
      "   Creating path_43... ✓\n",
      "   Creating path_44... ✓\n",
      "   Creating path_45... ✓\n",
      "   Creating path_46... ✓\n",
      "   Creating path_47... ✓\n",
      "   Creating path_48... ✓\n",
      "   Creating path_49... ✓\n",
      "   Creating path_50... ✓\n",
      "   Creating path_51... ✓\n",
      "   Creating path_52... ✓\n",
      "   Creating path_53... ✓\n",
      "   Creating path_54... ✓\n",
      "   Creating path_55... ✓\n",
      "   Creating path_56... ✓\n",
      "   Creating path_57... ✓\n",
      "   Creating path_58... ✓\n",
      "   Creating path_59... ✓\n",
      "   Creating path_60... ✓\n",
      "   Creating path_61... ✓\n",
      "   Creating path_62... ✓\n",
      "   Creating path_63... ✓\n",
      "   Creating path_64... ✓\n",
      "   Creating path_65... ✓\n",
      "   Creating path_66... ✓\n",
      "   Creating path_67... ✓\n",
      "   Creating path_68... ✓\n",
      "   Creating path_69... ✓\n",
      "   Creating path_70... ✓\n",
      "   Creating path_71... ✓\n",
      "   Creating path_72... ✓\n",
      "   Creating path_73... ✓\n",
      "   Creating path_74... ✓\n",
      "   Creating path_75... ✓\n",
      "   Creating path_76... ✓\n",
      "   Creating path_77... ✓\n",
      "   Creating path_78... ✓\n",
      "   Creating path_79... ✓\n",
      "   Creating path_80... ✓\n",
      "   Creating path_81... ✓\n",
      "   Creating path_82... ✓\n",
      "   Creating path_83... ✓\n",
      "   Creating path_84... ✓\n",
      "   Creating path_85... ✓\n",
      "   Creating path_86... ✓\n",
      "   Creating path_87... ✓\n",
      "   Creating path_88... ✓\n",
      "   Creating path_89... ✓\n",
      "   Creating path_90... ✓\n",
      "   Creating path_91... ✓\n",
      "   Creating path_92... ✓\n",
      "   Creating path_93... ✓\n",
      "   Creating path_94... ✓\n",
      "   Creating path_95... ✓\n",
      "   Creating path_96... ✓\n",
      "   Creating path_97... ✓\n",
      "   Creating path_98... ✓\n",
      "   Creating path_99... ✓\n",
      "   Creating path_100... ✓\n",
      "\n",
      "   ✓ Successfully created 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (with weather)...\n",
      "   ✓ Found 13 weather variables in data\n",
      "   ✓ Created historical data:\n",
      "      - Hourly: 394589 records (with 13 weather variables)\n",
      "      - Daily: 16437 records (with 11 weather variables)\n",
      "      - Monthly: 540 records (with 11 weather variables)\n",
      "   ℹ️  Weather aggregation:\n",
      "      - Averaged: temperature_2m, relative_humidity_2m, dew_point_2m, cloud_cover, surface_pressure, wind_speed_100m, wind_speed_10m, shortwave_radiation, diffuse_radiation, direct_normal_irradiance\n",
      "      - Summed: precipitation\n",
      "      - Skipped in daily/monthly: wind_direction_100m, wind_direction_10m\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (with synthetic paths)...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_hourly_timeseries.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_daily_timeseries.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (continuous format with weather)...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_hourly_historical.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_daily_historical.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Generation/forecast/timeseries/\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Generation/historical/\n",
      "\n",
      "📌 Note: Generation data is SHARED between DA and RT pipelines\n",
      "   This run used DAY-AHEAD bootstrap selections\n",
      "   Historical files include weather data where available\n",
      "   ✓ Saved metadata: generation_metadata.json\n",
      "\n",
      "[7/7] Processing RE_Mustang_LLC...\n",
      "\n",
      "📁 Loading bootstrap selections from: RE_Mustang_LLC_bootstrap_selections_da_latest.json\n",
      "   Using DAY-AHEAD bootstrap for generation\n",
      "   ✓ Loaded 100 path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Bootstrap type: DAY-AHEAD\n",
      "\n",
      "============================================================\n",
      "Processing: RE_Mustang_LLC\n",
      "Using DAY-AHEAD bootstrap for generation data\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: aamani_data\\RE_Mustang_LLC_generation_price_combined.csv\n",
      "\n",
      "📊 Data summary:\n",
      "   All years available: 1980 to 2024 (45 years)\n",
      "   Bootstrap overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 394,589\n",
      "   Months included: Jul, Aug, Sep, Oct, Nov, Dec, Jan, Feb, Mar, Apr, May, Jun\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from bootstrap selections...\n",
      "   Creating path_1... ✓\n",
      "   Creating path_2... ✓\n",
      "   Creating path_3... ✓\n",
      "   Creating path_4... ✓\n",
      "   Creating path_5... ✓\n",
      "   Creating path_6... ✓\n",
      "   Creating path_7... ✓\n",
      "   Creating path_8... ✓\n",
      "   Creating path_9... ✓\n",
      "   Creating path_10... ✓\n",
      "   Creating path_11... ✓\n",
      "   Creating path_12... ✓\n",
      "   Creating path_13... ✓\n",
      "   Creating path_14... ✓\n",
      "   Creating path_15... ✓\n",
      "   Creating path_16... ✓\n",
      "   Creating path_17... ✓\n",
      "   Creating path_18... ✓\n",
      "   Creating path_19... ✓\n",
      "   Creating path_20... ✓\n",
      "   Creating path_21... ✓\n",
      "   Creating path_22... ✓\n",
      "   Creating path_23... ✓\n",
      "   Creating path_24... ✓\n",
      "   Creating path_25... ✓\n",
      "   Creating path_26... ✓\n",
      "   Creating path_27... ✓\n",
      "   Creating path_28... ✓\n",
      "   Creating path_29... ✓\n",
      "   Creating path_30... ✓\n",
      "   Creating path_31... ✓\n",
      "   Creating path_32... ✓\n",
      "   Creating path_33... ✓\n",
      "   Creating path_34... ✓\n",
      "   Creating path_35... ✓\n",
      "   Creating path_36... ✓\n",
      "   Creating path_37... ✓\n",
      "   Creating path_38... ✓\n",
      "   Creating path_39... ✓\n",
      "   Creating path_40... ✓\n",
      "   Creating path_41... ✓\n",
      "   Creating path_42... ✓\n",
      "   Creating path_43... ✓\n",
      "   Creating path_44... ✓\n",
      "   Creating path_45... ✓\n",
      "   Creating path_46... ✓\n",
      "   Creating path_47... ✓\n",
      "   Creating path_48... ✓\n",
      "   Creating path_49... ✓\n",
      "   Creating path_50... ✓\n",
      "   Creating path_51... ✓\n",
      "   Creating path_52... ✓\n",
      "   Creating path_53... ✓\n",
      "   Creating path_54... ✓\n",
      "   Creating path_55... ✓\n",
      "   Creating path_56... ✓\n",
      "   Creating path_57... ✓\n",
      "   Creating path_58... ✓\n",
      "   Creating path_59... ✓\n",
      "   Creating path_60... ✓\n",
      "   Creating path_61... ✓\n",
      "   Creating path_62... ✓\n",
      "   Creating path_63... ✓\n",
      "   Creating path_64... ✓\n",
      "   Creating path_65... ✓\n",
      "   Creating path_66... ✓\n",
      "   Creating path_67... ✓\n",
      "   Creating path_68... ✓\n",
      "   Creating path_69... ✓\n",
      "   Creating path_70... ✓\n",
      "   Creating path_71... ✓\n",
      "   Creating path_72... ✓\n",
      "   Creating path_73... ✓\n",
      "   Creating path_74... ✓\n",
      "   Creating path_75... ✓\n",
      "   Creating path_76... ✓\n",
      "   Creating path_77... ✓\n",
      "   Creating path_78... ✓\n",
      "   Creating path_79... ✓\n",
      "   Creating path_80... ✓\n",
      "   Creating path_81... ✓\n",
      "   Creating path_82... ✓\n",
      "   Creating path_83... ✓\n",
      "   Creating path_84... ✓\n",
      "   Creating path_85... ✓\n",
      "   Creating path_86... ✓\n",
      "   Creating path_87... ✓\n",
      "   Creating path_88... ✓\n",
      "   Creating path_89... ✓\n",
      "   Creating path_90... ✓\n",
      "   Creating path_91... ✓\n",
      "   Creating path_92... ✓\n",
      "   Creating path_93... ✓\n",
      "   Creating path_94... ✓\n",
      "   Creating path_95... ✓\n",
      "   Creating path_96... ✓\n",
      "   Creating path_97... ✓\n",
      "   Creating path_98... ✓\n",
      "   Creating path_99... ✓\n",
      "   Creating path_100... ✓\n",
      "\n",
      "   ✓ Successfully created 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY timeseries with synthetic paths...\n",
      "   ✓ Created timeseries with 13 historical years (overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (with weather)...\n",
      "   ✓ Found 13 weather variables in data\n",
      "   ✓ Created historical data:\n",
      "      - Hourly: 394589 records (with 13 weather variables)\n",
      "      - Daily: 16437 records (with 11 weather variables)\n",
      "      - Monthly: 540 records (with 11 weather variables)\n",
      "   ℹ️  Weather aggregation:\n",
      "      - Averaged: temperature_2m, relative_humidity_2m, dew_point_2m, cloud_cover, surface_pressure, wind_speed_100m, wind_speed_10m, shortwave_radiation, diffuse_radiation, direct_normal_irradiance\n",
      "      - Summed: precipitation\n",
      "      - Skipped in daily/monthly: wind_direction_100m, wind_direction_10m\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (with synthetic paths)...\n",
      "   ✓ RE_Mustang_LLC_generation_hourly_timeseries.csv\n",
      "   ✓ RE_Mustang_LLC_generation_daily_timeseries.csv\n",
      "   ✓ RE_Mustang_LLC_generation_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (continuous format with weather)...\n",
      "   ✓ RE_Mustang_LLC_generation_hourly_historical.csv\n",
      "   ✓ RE_Mustang_LLC_generation_daily_historical.csv\n",
      "   ✓ RE_Mustang_LLC_generation_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Generation/forecast/timeseries/\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Generation/historical/\n",
      "\n",
      "📌 Note: Generation data is SHARED between DA and RT pipelines\n",
      "   This run used DAY-AHEAD bootstrap selections\n",
      "   Historical files include weather data where available\n",
      "   ✓ Saved metadata: generation_metadata.json\n",
      "\n",
      "============================================================\n",
      "✨ PHASE 1a COMPLETE!\n",
      "============================================================\n",
      "\n",
      "📊 Summary:\n",
      "   ✅ Successfully processed: 7 sites\n",
      "\n",
      "📁 Files saved:\n",
      "   • Generation/forecast/timeseries/ - Historical years + synthetic paths\n",
      "   • Generation/historical/ - Continuous format data WITH WEATHER\n",
      "\n",
      "📌 Generation data is SHARED between DA and RT pipelines\n",
      "   Next step: Run Phase 1b for price data preparation (DA and/or RT)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class GenerationDataPreparation:\n",
    "    \"\"\"\n",
    "    Phase 1a: Create historical data and timeseries (with synthetic paths)\n",
    "    SHARED implementation for both DA and RT pipelines\n",
    "    Since overlapping years are similar, generation data is common to both\n",
    "    Will use whichever bootstrap exists (DA or RT), preferring DA if both exist\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the generation data preparation\n",
    "        No pipeline_type needed - generation is shared!\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define paths\n",
    "        self.data_path = Path('aamani_data')\n",
    "        self.base_output_path = Path('Renewable Portfolio LLC')\n",
    "        \n",
    "        # Bootstrap paths - will check both\n",
    "        self.bootstrap_path_da = self.base_output_path / 'bootstrap_selections_da'\n",
    "        self.bootstrap_path_rt = self.base_output_path / 'bootstrap_selections_rt'\n",
    "        \n",
    "        # Will be set when loading bootstrap\n",
    "        self.bootstrap_type = None  # 'da' or 'rt'\n",
    "        self.pipeline_name = None\n",
    "        self.pipeline_name_short = None\n",
    "        \n",
    "        # Get available combined files\n",
    "        self.available_files = list(self.data_path.glob('*_generation_price_combined.csv'))\n",
    "        self.available_sites = [f.stem.replace('_generation_price_combined', '') for f in self.available_files]\n",
    "        \n",
    "        # Bootstrap selections will be loaded per site\n",
    "        self.bootstrap_selections = None\n",
    "        self.n_synthetic_paths = None\n",
    "        self.bootstrap_metadata = None\n",
    "        \n",
    "        # Month names for labeling\n",
    "        self.month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        self.month_names_full = ['', 'January', 'February', 'March', 'April', 'May', 'June',\n",
    "                                'July', 'August', 'September', 'October', 'November', 'December']\n",
    "        \n",
    "        # Define weather columns that should be averaged (not summed)\n",
    "        self.weather_cols_avg = [\n",
    "            'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'cloud_cover',\n",
    "            'surface_pressure', 'wind_speed_100m', 'wind_speed_10m',\n",
    "            'shortwave_radiation', 'diffuse_radiation', 'direct_normal_irradiance'\n",
    "        ]\n",
    "        \n",
    "        # Define weather columns that should be summed\n",
    "        self.weather_cols_sum = ['precipitation']\n",
    "        \n",
    "        # Wind direction columns to skip in daily/monthly aggregations\n",
    "        self.weather_cols_skip = ['wind_direction_100m', 'wind_direction_10m']\n",
    "    \n",
    "    def get_site_selection(self):\n",
    "        \"\"\"\n",
    "        Interactive site selection with option for all sites\n",
    "        Checks for either DA or RT bootstrap selections\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"GENERATION DATA PREPARATION - SITE SELECTION\")\n",
    "        print(\"(Shared for both DA and RT pipelines)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.available_sites:\n",
    "            print(\"❌ No combined generation-price files found in aamani_data!\")\n",
    "            return None\n",
    "        \n",
    "        # Check which sites have bootstrap selections (either DA or RT)\n",
    "        sites_with_bootstrap = []\n",
    "        bootstrap_info = {}  # Track which bootstrap types are available per site\n",
    "        \n",
    "        for site in self.available_sites:\n",
    "            has_da = (self.bootstrap_path_da / f\"{site}_bootstrap_selections_da_latest.json\").exists()\n",
    "            has_rt = (self.bootstrap_path_rt / f\"{site}_bootstrap_selections_rt_latest.json\").exists()\n",
    "            \n",
    "            if has_da or has_rt:\n",
    "                sites_with_bootstrap.append(site)\n",
    "                bootstrap_info[site] = {'da': has_da, 'rt': has_rt}\n",
    "        \n",
    "        if not sites_with_bootstrap:\n",
    "            print(\"❌ No bootstrap selections found! Please run Phase 0 (either DA or RT) first.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n✅ Found bootstrap selections for {len(sites_with_bootstrap)} sites\")\n",
    "        print(\"\\nAvailable sites:\")\n",
    "        for site in sites_with_bootstrap:\n",
    "            available_types = []\n",
    "            if bootstrap_info[site]['da']:\n",
    "                available_types.append('DA')\n",
    "            if bootstrap_info[site]['rt']:\n",
    "                available_types.append('RT')\n",
    "            print(f\"   • {site} (bootstrap available: {', '.join(available_types)})\")\n",
    "        \n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"0. ALL SITES (Process all sites with bootstrap selections)\")\n",
    "        for i, site in enumerate(sites_with_bootstrap):\n",
    "            print(f\"{i+1}. {site}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selection = input(\"\\n📊 Select option number (0 for all sites): \").strip()\n",
    "                if selection == '0':\n",
    "                    return 'ALL_SITES', sites_with_bootstrap, bootstrap_info\n",
    "                else:\n",
    "                    idx = int(selection) - 1\n",
    "                    if 0 <= idx < len(sites_with_bootstrap):\n",
    "                        selected_site = sites_with_bootstrap[idx]\n",
    "                        return selected_site, [selected_site], bootstrap_info\n",
    "                    else:\n",
    "                        print(\"❌ Invalid selection!\")\n",
    "            except:\n",
    "                print(\"❌ Please enter a valid number!\")\n",
    "    \n",
    "    def load_bootstrap_selections(self, site_name, bootstrap_info):\n",
    "        \"\"\"\n",
    "        Load bootstrap selections for a specific site\n",
    "        Automatically detects which type to use (prefers DA if both exist)\n",
    "        \"\"\"\n",
    "        # Determine which bootstrap to use\n",
    "        has_da = bootstrap_info[site_name]['da']\n",
    "        has_rt = bootstrap_info[site_name]['rt']\n",
    "        \n",
    "        if has_da:\n",
    "            # Prefer DA if available\n",
    "            bootstrap_file = self.bootstrap_path_da / f\"{site_name}_bootstrap_selections_da_latest.json\"\n",
    "            self.bootstrap_type = 'da'\n",
    "            self.pipeline_name = \"DAY-AHEAD\"\n",
    "            self.pipeline_name_short = \"DA\"\n",
    "        elif has_rt:\n",
    "            # Use RT if DA not available\n",
    "            bootstrap_file = self.bootstrap_path_rt / f\"{site_name}_bootstrap_selections_rt_latest.json\"\n",
    "            self.bootstrap_type = 'rt'\n",
    "            self.pipeline_name = \"REAL-TIME\"\n",
    "            self.pipeline_name_short = \"RT\"\n",
    "        else:\n",
    "            print(f\"❌ No bootstrap selections found for {site_name}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"\\n📁 Loading bootstrap selections from: {bootstrap_file.name}\")\n",
    "        print(f\"   Using {self.pipeline_name} bootstrap for generation\")\n",
    "        \n",
    "        with open(bootstrap_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        self.bootstrap_selections = data['selections']\n",
    "        self.n_synthetic_paths = data['n_paths']\n",
    "        self.bootstrap_metadata = data['metadata']\n",
    "        \n",
    "        print(f\"   ✓ Loaded {self.n_synthetic_paths} path selections\")\n",
    "        print(f\"   ✓ Years used: {self.bootstrap_metadata['year_range']} ({self.bootstrap_metadata['n_years']} years)\")\n",
    "        print(f\"   ✓ Bootstrap type: {self.pipeline_name}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def get_automatic_month_range(self):\n",
    "        \"\"\"\n",
    "        Automatically determine month range: current month to 11 months later\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        start_month = current_month\n",
    "        if start_month == 1:\n",
    "            end_month = 12\n",
    "        else:\n",
    "            end_month = start_month - 1\n",
    "        \n",
    "        print(f\"\\n📅 Auto-detected period: {self.month_names[start_month]} to {self.month_names[end_month]} (12 months)\")\n",
    "        print(f\"   Starting from current month: {self.month_names[current_month]}\")\n",
    "        \n",
    "        return start_month, end_month\n",
    "    \n",
    "    def get_months_in_range(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Get list of months in range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        if start_month <= end_month:\n",
    "            return list(range(start_month, end_month + 1))\n",
    "        else:\n",
    "            return list(range(start_month, 13)) + list(range(1, end_month + 1))\n",
    "    \n",
    "    def filter_data_for_months(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Filter dataframe for month range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return df[df['month'].isin(months_in_range)].copy()\n",
    "    \n",
    "    def create_month_order_map(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create a mapping for sorting months in the specified order\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return {month: idx for idx, month in enumerate(months_in_range)}\n",
    "    \n",
    "    def generate_synthetic_paths_from_bootstrap(self, df):\n",
    "        \"\"\"\n",
    "        Generate synthetic paths using bootstrap selections\n",
    "        \"\"\"\n",
    "        print(f\"\\n🎲 Generating {self.n_synthetic_paths} synthetic paths from bootstrap selections...\")\n",
    "        \n",
    "        synthetic_data = {}\n",
    "        \n",
    "        for path_name, path_selection in self.bootstrap_selections.items():\n",
    "            print(f\"   Creating {path_name}...\", end='')\n",
    "            path_data = []\n",
    "            \n",
    "            # For each month in the selection\n",
    "            for month_name, selected_year in path_selection.items():\n",
    "                if selected_year is None:\n",
    "                    print(f\"\\n   ⚠️  Warning: No selection for {month_name} in {path_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Get month number\n",
    "                month_num = self.month_names.index(month_name)\n",
    "                \n",
    "                # Get all data for this year-month combination\n",
    "                month_data = df[(df['year'] == selected_year) & (df['month'] == month_num)]\n",
    "                \n",
    "                if len(month_data) > 0:\n",
    "                    path_data.append(month_data.copy())\n",
    "                else:\n",
    "                    print(f\"\\n   ⚠️  Warning: No data found for {month_name} {selected_year}\")\n",
    "            \n",
    "            # Combine all months for this path\n",
    "            if path_data:\n",
    "                path_df = pd.concat(path_data, ignore_index=True)\n",
    "                synthetic_data[path_name] = path_df\n",
    "                print(f\" ✓\")\n",
    "            else:\n",
    "                print(f\" ✗ (No data)\")\n",
    "        \n",
    "        print(f\"\\n   ✓ Successfully created {len(synthetic_data)} synthetic paths\")\n",
    "        \n",
    "        return synthetic_data\n",
    "    \n",
    "    def create_hourly_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create hourly timeseries including both historical years and synthetic paths\n",
    "        \"\"\"\n",
    "        print(f\"\\n⏰ Creating HOURLY timeseries with synthetic paths...\")\n",
    "        \n",
    "        df_work = df_filtered.copy()\n",
    "        df_work['month_order'] = df_work['month'].map(month_order_map)\n",
    "        \n",
    "        # Create pivot for historical data\n",
    "        pivot_df = df_work.pivot_table(\n",
    "            index=['month', 'day', 'hour', 'month_order'],\n",
    "            columns='year',\n",
    "            values='generation_mw',\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            # Filter path data for the month range\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            # Aggregate by month-day-hour\n",
    "            path_grouped = path_filtered.groupby(['month', 'day', 'hour'])['generation_mw'].mean()\n",
    "            \n",
    "            # Add to pivot dataframe\n",
    "            pivot_df[path_name] = pivot_df.apply(\n",
    "                lambda row: path_grouped.get((int(row['month']), int(row['day']), int(row['hour'])), np.nan),\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        pivot_df['datetime_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d} {int(row['hour']):02d}:00\",\n",
    "            axis=1\n",
    "        )\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns: metadata, historical years, then paths\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int)])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['datetime_label', 'month', 'day', 'hour'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        # Only include years that were part of the overlap\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols_filtered = [col for col in year_cols if col in overlap_years]\n",
    "        \n",
    "        print(f\"   ✓ Created timeseries with {len(year_cols_filtered)} historical years (overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_daily_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create daily timeseries including both historical years and synthetic paths\n",
    "        \"\"\"\n",
    "        print(f\"\\n📅 Creating DAILY timeseries with synthetic paths...\")\n",
    "        \n",
    "        # Aggregate to daily\n",
    "        df_daily = df_filtered.groupby(['year', 'month', 'day'])['generation_mw'].sum().reset_index()\n",
    "        df_daily.rename(columns={'generation_mw': 'daily_generation_mwh'}, inplace=True)\n",
    "        df_daily['month_order'] = df_daily['month'].map(month_order_map)\n",
    "        \n",
    "        # Create pivot for historical data\n",
    "        pivot_df = df_daily.pivot_table(\n",
    "            index=['month', 'day', 'month_order'],\n",
    "            columns='year',\n",
    "            values='daily_generation_mwh',\n",
    "            aggfunc='sum'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            # Filter path data for the month range\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            # Aggregate to daily\n",
    "            path_daily = path_filtered.groupby(['month', 'day'])['generation_mw'].sum()\n",
    "            \n",
    "            # Add to pivot dataframe\n",
    "            pivot_df[path_name] = pivot_df.apply(\n",
    "                lambda row: path_daily.get((int(row['month']), int(row['day'])), np.nan),\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day']).reset_index(drop=True)\n",
    "        pivot_df['date_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d}\",\n",
    "            axis=1\n",
    "        )\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int)])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['date_label', 'month', 'day'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        # Only include years that were part of the overlap\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols_filtered = [col for col in year_cols if col in overlap_years]\n",
    "        \n",
    "        print(f\"   ✓ Created timeseries with {len(year_cols_filtered)} historical years (overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_monthly_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create monthly timeseries including both historical years and synthetic paths\n",
    "        \"\"\"\n",
    "        print(f\"\\n📊 Creating MONTHLY timeseries with synthetic paths...\")\n",
    "        \n",
    "        # Aggregate to monthly\n",
    "        df_monthly = df_filtered.groupby(['year', 'month'])['generation_mw'].sum().reset_index()\n",
    "        df_monthly.rename(columns={'generation_mw': 'monthly_generation_mwh'}, inplace=True)\n",
    "        df_monthly['month_order'] = df_monthly['month'].map(month_order_map)\n",
    "        \n",
    "        # Create pivot for historical data\n",
    "        pivot_df = df_monthly.pivot_table(\n",
    "            index=['month', 'month_order'],\n",
    "            columns='year',\n",
    "            values='monthly_generation_mwh',\n",
    "            aggfunc='sum'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            # Filter path data for the month range\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            # Aggregate to monthly\n",
    "            path_monthly = path_filtered.groupby('month')['generation_mw'].sum()\n",
    "            \n",
    "            # Add to pivot dataframe\n",
    "            pivot_df[path_name] = pivot_df['month'].apply(\n",
    "                lambda month: path_monthly.get(int(month), np.nan)\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order']).reset_index(drop=True)\n",
    "        pivot_df['month_name'] = pivot_df['month'].apply(lambda x: self.month_names_full[int(x)])\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int)])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['month_name', 'month'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        # Only include years that were part of the overlap\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols_filtered = [col for col in year_cols if col in overlap_years]\n",
    "        \n",
    "        print(f\"   ✓ Created timeseries with {len(year_cols_filtered)} historical years (overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_historical_continuous_data(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create historical data in continuous (long) format WITH WEATHER DATA\n",
    "        \"\"\"\n",
    "        print(\"\\n📜 Creating historical continuous data (with weather)...\")\n",
    "        \n",
    "        # Filter for month range\n",
    "        df_filtered = self.filter_data_for_months(df, start_month, end_month)\n",
    "        \n",
    "        # Identify which weather columns are present in the data\n",
    "        all_weather_cols = self.weather_cols_avg + self.weather_cols_sum + self.weather_cols_skip\n",
    "        available_weather_cols = [col for col in all_weather_cols if col in df_filtered.columns]\n",
    "        \n",
    "        if available_weather_cols:\n",
    "            print(f\"   ✓ Found {len(available_weather_cols)} weather variables in data\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  No weather variables found in data\")\n",
    "        \n",
    "        # HOURLY HISTORICAL - include all weather columns as-is\n",
    "        hourly_cols = ['datetime', 'year', 'month', 'day', 'hour', 'generation_mw']\n",
    "        hourly_cols.extend(available_weather_cols)  # Add all available weather columns\n",
    "        \n",
    "        hourly_hist = df_filtered[hourly_cols].copy()\n",
    "        hourly_hist = hourly_hist.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        # DAILY HISTORICAL - aggregate weather appropriately\n",
    "        daily_agg_dict = {\n",
    "            'generation_mw': 'sum',\n",
    "            'datetime': 'first'\n",
    "        }\n",
    "        \n",
    "        # Add weather aggregations\n",
    "        for col in available_weather_cols:\n",
    "            if col in self.weather_cols_avg:\n",
    "                daily_agg_dict[col] = 'mean'\n",
    "            elif col in self.weather_cols_sum:\n",
    "                daily_agg_dict[col] = 'sum'\n",
    "            # Skip wind direction columns for daily aggregation\n",
    "        \n",
    "        daily_hist = df_filtered.groupby(['year', 'month', 'day']).agg(daily_agg_dict).reset_index()\n",
    "        daily_hist['date'] = daily_hist['datetime'].dt.date\n",
    "        \n",
    "        # Reorder columns\n",
    "        daily_cols = ['date', 'year', 'month', 'day', 'generation_mw']\n",
    "        daily_cols.extend([col for col in available_weather_cols if col not in self.weather_cols_skip])\n",
    "        daily_hist = daily_hist[daily_cols]\n",
    "        daily_hist.rename(columns={'generation_mw': 'daily_generation_mwh'}, inplace=True)\n",
    "        daily_hist = daily_hist.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        # MONTHLY HISTORICAL - aggregate weather appropriately\n",
    "        monthly_agg_dict = {'generation_mw': 'sum'}\n",
    "        \n",
    "        # Add weather aggregations\n",
    "        for col in available_weather_cols:\n",
    "            if col in self.weather_cols_avg:\n",
    "                monthly_agg_dict[col] = 'mean'\n",
    "            elif col in self.weather_cols_sum:\n",
    "                monthly_agg_dict[col] = 'sum'\n",
    "            # Skip wind direction columns for monthly aggregation\n",
    "        \n",
    "        monthly_hist = df_filtered.groupby(['year', 'month']).agg(monthly_agg_dict).reset_index()\n",
    "        monthly_hist['month_year'] = monthly_hist.apply(\n",
    "            lambda row: f\"{row['year']}-{int(row['month']):02d}\", axis=1\n",
    "        )\n",
    "        monthly_hist.rename(columns={'generation_mw': 'monthly_generation_mwh'}, inplace=True)\n",
    "        \n",
    "        # Reorder columns\n",
    "        monthly_cols = ['month_year', 'year', 'month', 'monthly_generation_mwh']\n",
    "        monthly_cols.extend([col for col in available_weather_cols if col not in self.weather_cols_skip])\n",
    "        monthly_hist = monthly_hist[monthly_cols]\n",
    "        monthly_hist = monthly_hist.sort_values(['year', 'month']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   ✓ Created historical data:\")\n",
    "        print(f\"      - Hourly: {len(hourly_hist)} records (with {len([c for c in available_weather_cols if c in hourly_hist.columns])} weather variables)\")\n",
    "        print(f\"      - Daily: {len(daily_hist)} records (with {len([c for c in available_weather_cols if c in daily_hist.columns and c not in self.weather_cols_skip])} weather variables)\")\n",
    "        print(f\"      - Monthly: {len(monthly_hist)} records (with {len([c for c in available_weather_cols if c in monthly_hist.columns and c not in self.weather_cols_skip])} weather variables)\")\n",
    "        \n",
    "        if available_weather_cols:\n",
    "            print(f\"   ℹ️  Weather aggregation:\")\n",
    "            print(f\"      - Averaged: {', '.join([c for c in self.weather_cols_avg if c in available_weather_cols])}\")\n",
    "            if any(c in available_weather_cols for c in self.weather_cols_sum):\n",
    "                print(f\"      - Summed: {', '.join([c for c in self.weather_cols_sum if c in available_weather_cols])}\")\n",
    "            if any(c in available_weather_cols for c in self.weather_cols_skip):\n",
    "                print(f\"      - Skipped in daily/monthly: {', '.join([c for c in self.weather_cols_skip if c in available_weather_cols])}\")\n",
    "        \n",
    "        return hourly_hist, daily_hist, monthly_hist\n",
    "    \n",
    "    def save_all_results(self, hourly_ts, daily_ts, monthly_ts,\n",
    "                        hourly_hist, daily_hist, monthly_hist, site_name):\n",
    "        \"\"\"\n",
    "        Save timeseries and historical files in Generation folder\n",
    "        NOTE: SHARED folder for both DA and RT pipelines\n",
    "        \"\"\"\n",
    "        # Create folder structure with Generation subfolder\n",
    "        generation_path = self.base_output_path / site_name / 'Generation'\n",
    "        forecast_path = generation_path / 'forecast'\n",
    "        timeseries_path = forecast_path / 'timeseries'\n",
    "        historical_path = generation_path / 'historical'\n",
    "        \n",
    "        timeseries_path.mkdir(parents=True, exist_ok=True)\n",
    "        historical_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save timeseries files\n",
    "        print(f\"\\n📈 Saving TIMESERIES files (with synthetic paths)...\")\n",
    "        \n",
    "        # Format and save timeseries files\n",
    "        for ts_df, ts_name, ts_file in [\n",
    "            (hourly_ts, \"hourly\", f\"{site_name}_generation_hourly_timeseries.csv\"),\n",
    "            (daily_ts, \"daily\", f\"{site_name}_generation_daily_timeseries.csv\"),\n",
    "            (monthly_ts, \"monthly\", f\"{site_name}_generation_monthly_timeseries.csv\")\n",
    "        ]:\n",
    "            ts_save = ts_df.copy()\n",
    "            # Format numeric columns\n",
    "            numeric_cols = [col for col in ts_save.columns if isinstance(col, int) or (isinstance(col, str) and col.startswith('path_'))]\n",
    "            for col in numeric_cols:\n",
    "                ts_save[col] = ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.3f}')\n",
    "            ts_save.to_csv(timeseries_path / ts_file, index=False)\n",
    "            print(f\"   ✓ {ts_file}\")\n",
    "        \n",
    "        # Save historical files\n",
    "        print(\"\\n📜 Saving HISTORICAL files (continuous format with weather)...\")\n",
    "        \n",
    "        # Hourly historical\n",
    "        hourly_hist_file = f\"{site_name}_generation_hourly_historical.csv\"\n",
    "        hourly_hist.to_csv(historical_path / hourly_hist_file, index=False, float_format='%.3f')\n",
    "        print(f\"   ✓ {hourly_hist_file}\")\n",
    "        \n",
    "        # Daily historical\n",
    "        daily_hist_file = f\"{site_name}_generation_daily_historical.csv\"\n",
    "        daily_hist.to_csv(historical_path / daily_hist_file, index=False, float_format='%.3f')\n",
    "        print(f\"   ✓ {daily_hist_file}\")\n",
    "        \n",
    "        # Monthly historical\n",
    "        monthly_hist_file = f\"{site_name}_generation_monthly_historical.csv\"\n",
    "        monthly_hist.to_csv(historical_path / monthly_hist_file, index=False, float_format='%.3f')\n",
    "        print(f\"   ✓ {monthly_hist_file}\")\n",
    "        \n",
    "        print(f\"\\n📁 All files saved in:\")\n",
    "        print(f\"   • Renewable Portfolio LLC/{site_name}/Generation/forecast/timeseries/\")\n",
    "        print(f\"   • Renewable Portfolio LLC/{site_name}/Generation/historical/\")\n",
    "        print(f\"\\n📌 Note: Generation data is SHARED between DA and RT pipelines\")\n",
    "        print(f\"   This run used {self.pipeline_name} bootstrap selections\")\n",
    "        print(f\"   Historical files include weather data where available\")\n",
    "        \n",
    "        # Save metadata about which bootstrap was used\n",
    "        metadata_file = generation_path / 'generation_metadata.json'\n",
    "        metadata = {\n",
    "            'last_updated': datetime.now().isoformat(),\n",
    "            'bootstrap_type': self.bootstrap_type,\n",
    "            'pipeline_name': self.pipeline_name,\n",
    "            'n_synthetic_paths': self.n_synthetic_paths,\n",
    "            'years_used': self.bootstrap_metadata['years_used'],\n",
    "            'year_range': self.bootstrap_metadata['year_range'],\n",
    "            'note': 'Generation data is shared between DA and RT pipelines'\n",
    "        }\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        print(f\"   ✓ Saved metadata: generation_metadata.json\")\n",
    "    \n",
    "    def process_single_site(self, site_name, start_month, end_month, bootstrap_info):\n",
    "        \"\"\"\n",
    "        Process a single site with given month range\n",
    "        \"\"\"\n",
    "        # Load bootstrap selections for this site\n",
    "        if not self.load_bootstrap_selections(site_name, bootstrap_info):\n",
    "            return False\n",
    "        \n",
    "        # Create month order mapping\n",
    "        month_order_map = self.create_month_order_map(start_month, end_month)\n",
    "        \n",
    "        # Load and prepare data\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {site_name}\")\n",
    "        print(f\"Using {self.pipeline_name} bootstrap for generation data\")\n",
    "        \n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        num_months = len(months_in_range)\n",
    "        \n",
    "        if start_month <= end_month:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} ({num_months} months)\")\n",
    "        else:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} (year-wrapping, {num_months} months)\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Load combined data\n",
    "        file_path = self.data_path / f\"{site_name}_generation_price_combined.csv\"\n",
    "        print(f\"\\n📁 Loading data from: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            \n",
    "            # Ensure numeric columns are integers\n",
    "            df['year'] = df['year'].astype(int)\n",
    "            df['month'] = df['month'].astype(int)\n",
    "            df['hour'] = df['hour'].astype(int)\n",
    "            df['day'] = df['datetime'].dt.day.astype(int)\n",
    "            \n",
    "            # Get full dataset (before filtering) for synthetic path generation\n",
    "            df_full = df.copy()\n",
    "            \n",
    "            # Filter for selected months\n",
    "            df_filtered = self.filter_data_for_months(df, start_month, end_month)\n",
    "            \n",
    "            # Data summary\n",
    "            years_available = sorted(df_filtered['year'].unique())\n",
    "            overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "            years_in_overlap = sorted([y for y in years_available if y in overlap_years])\n",
    "            \n",
    "            print(f\"\\n📊 Data summary:\")\n",
    "            print(f\"   All years available: {years_available[0]} to {years_available[-1]} ({len(years_available)} years)\")\n",
    "            print(f\"   Bootstrap overlap years: {years_in_overlap[0]} to {years_in_overlap[-1]} ({len(years_in_overlap)} years)\")\n",
    "            print(f\"   Total data points: {len(df_filtered):,}\")\n",
    "            print(f\"   Months included: {', '.join([self.month_names[m] for m in months_in_range])}\")\n",
    "            \n",
    "            # Generate synthetic paths using bootstrap selections\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"SYNTHETIC PATH GENERATION FROM BOOTSTRAP\")\n",
    "            print(\"-\"*40)\n",
    "            synthetic_paths = self.generate_synthetic_paths_from_bootstrap(df_full)\n",
    "            \n",
    "            # Create timeseries with synthetic paths\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"GENERATION TIMESERIES (HISTORICAL + SYNTHETIC)\")\n",
    "            print(\"-\"*40)\n",
    "            hourly_ts = self.create_hourly_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            daily_ts = self.create_daily_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            monthly_ts = self.create_monthly_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            \n",
    "            # Create historical continuous data\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"HISTORICAL DATA PREPARATION\")\n",
    "            print(\"-\"*40)\n",
    "            hourly_hist, daily_hist, monthly_hist = self.create_historical_continuous_data(df, start_month, end_month)\n",
    "            \n",
    "            # Save all results\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"SAVING RESULTS\")\n",
    "            print(\"-\"*40)\n",
    "            self.save_all_results(hourly_ts, daily_ts, monthly_ts,\n",
    "                                hourly_hist, daily_hist, monthly_hist,\n",
    "                                site_name)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Error processing {site_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    def run_preparation(self):\n",
    "        \"\"\"\n",
    "        Main function to run the generation data preparation\n",
    "        \"\"\"\n",
    "        print(\"\\n🌟 Generation Data Preparation - Phase 1a\")\n",
    "        print(\"   (Shared for both DA and RT pipelines)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get site selection\n",
    "        site_selection_result = self.get_site_selection()\n",
    "        if not site_selection_result:\n",
    "            return\n",
    "        \n",
    "        site_selection, sites_to_process, bootstrap_info = site_selection_result\n",
    "        \n",
    "        # Get automatic month range\n",
    "        start_month, end_month = self.get_automatic_month_range()\n",
    "        \n",
    "        # Process based on selection\n",
    "        if site_selection == 'ALL_SITES':\n",
    "            # Process all sites\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"🚀 PROCESSING ALL SITES WITH BOOTSTRAP SELECTIONS\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            for i, site_name in enumerate(sites_to_process, 1):\n",
    "                print(f\"\\n[{i}/{len(sites_to_process)}] Processing {site_name}...\")\n",
    "                \n",
    "                if self.process_single_site(site_name, start_month, end_month, bootstrap_info):\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"✨ PHASE 1a COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\n📊 Summary:\")\n",
    "            print(f\"   ✅ Successfully processed: {successful} sites\")\n",
    "            if failed > 0:\n",
    "                print(f\"   ❌ Failed: {failed} sites\")\n",
    "            \n",
    "            print(f\"\\n📁 Files saved:\")\n",
    "            print(f\"   • Generation/forecast/timeseries/ - Historical years + synthetic paths\")\n",
    "            print(f\"   • Generation/historical/ - Continuous format data WITH WEATHER\")\n",
    "            print(f\"\\n📌 Generation data is SHARED between DA and RT pipelines\")\n",
    "            print(f\"   Next step: Run Phase 1b for price data preparation (DA and/or RT)\")\n",
    "            \n",
    "        else:\n",
    "            # Process single site\n",
    "            if self.process_single_site(site_selection, start_month, end_month, bootstrap_info):\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"✨ PHASE 1a COMPLETE!\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\nData prepared for {site_selection}\")\n",
    "                print(f\"12-month period: {self.month_names[start_month]} to {self.month_names[end_month]}\")\n",
    "                print(f\"Bootstrap used: {self.pipeline_name}\")\n",
    "                print(f\"Synthetic paths: {self.n_synthetic_paths}\")\n",
    "                \n",
    "                print(f\"\\n📁 Files saved in:\")\n",
    "                print(f\"   • Renewable Portfolio LLC/{site_selection}/Generation/forecast/timeseries/\")\n",
    "                print(f\"   • Renewable Portfolio LLC/{site_selection}/Generation/historical/ (with weather)\")\n",
    "                \n",
    "                print(f\"\\n📌 Generation data is SHARED between DA and RT pipelines\")\n",
    "                print(f\"   Next step: Run Phase 1b for price data preparation (DA and/or RT)\")\n",
    "        \n",
    "        # Ask if user wants to prepare another site\n",
    "        another = input(\"\\n🔄 Prepare generation data for another site? (y/n): \").strip().lower()\n",
    "        if another == 'y':\n",
    "            self.run_preparation()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n🌟 Generation Data Preparation\")\n",
    "    print(\"This will create SHARED generation data for both DA and RT pipelines\")\n",
    "    print(\"The system will automatically use whichever bootstrap is available\")\n",
    "    print(\"(DA bootstrap is preferred if both exist)\")\n",
    "    \n",
    "    prep = GenerationDataPreparation()\n",
    "    prep.run_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b3d06",
   "metadata": {},
   "source": [
    "# Phase 1b: Unified price preparation (handles both DA and RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f6a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💰 Price Data Preparation\n",
      "Select pipeline type:\n",
      "1. Day-Ahead (DA)\n",
      "2. Real-Time (RT)\n",
      "\n",
      "💰 REAL-TIME Price Data Preparation - Phase 1b\n",
      "   (Using REAL-TIME Bootstrap Selections)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "REAL-TIME PRICE DATA PREPARATION - SITE SELECTION\n",
      "============================================================\n",
      "\n",
      "✅ Found REAL-TIME bootstrap selections for 7 sites\n",
      "\n",
      "Available options:\n",
      "0. ALL SITES (Process all sites with RT bootstrap selections)\n",
      "1. Albemarle_Beach_Solar\n",
      "2. Blue_Wing_Solar_Energy_Generator\n",
      "3. Lamesa_Solar\n",
      "4. Midway_Solar_Farm_III\n",
      "5. Misae_Solar\n",
      "6. Mount_Signal_Solar_Farm_II\n",
      "7. RE_Mustang_LLC\n",
      "============================================================\n",
      "\n",
      "📅 Auto-detected period: Jul to Jun (12 months)\n",
      "   Starting from current month: Jul\n",
      "\n",
      "============================================================\n",
      "🚀 PROCESSING ALL SITES - REAL-TIME Prices\n",
      "============================================================\n",
      "\n",
      "[1/7] Processing Albemarle_Beach_Solar...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Albemarle_Beach_Solar_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2025 (14 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Albemarle_Beach_Solar (REAL-TIME Price Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Albemarle_Beach_Solar_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering REAL-TIME price data...\n",
      "   Total rows: 398,213\n",
      "   Rows with valid REAL-TIME prices: 116,154\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME prices...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME price data):\n",
      "   All years available: 2012 to 2025 (14 years)\n",
      "   RT overlap years: 2012 to 2025 (14 years)\n",
      "   Total data points: 116,154\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from REAL-TIME bootstrap selections...\n",
      "   Creating path_1 (RT)... ✓\n",
      "   Creating path_2 (RT)... ✓\n",
      "   Creating path_3 (RT)... ✓\n",
      "   Creating path_4 (RT)... ✓\n",
      "   Creating path_5 (RT)... ✓\n",
      "   Creating path_6 (RT)... ✓\n",
      "   Creating path_7 (RT)... ✓\n",
      "   Creating path_8 (RT)... ✓\n",
      "   Creating path_9 (RT)... ✓\n",
      "   Creating path_10 (RT)... ✓\n",
      "   Creating path_11 (RT)... ✓\n",
      "   Creating path_12 (RT)... ✓\n",
      "   Creating path_13 (RT)... ✓\n",
      "   Creating path_14 (RT)... ✓\n",
      "   Creating path_15 (RT)... ✓\n",
      "   Creating path_16 (RT)... ✓\n",
      "   Creating path_17 (RT)... ✓\n",
      "   Creating path_18 (RT)... ✓\n",
      "   Creating path_19 (RT)... ✓\n",
      "   Creating path_20 (RT)... ✓\n",
      "   Creating path_21 (RT)... ✓\n",
      "   Creating path_22 (RT)... ✓\n",
      "   Creating path_23 (RT)... ✓\n",
      "   Creating path_24 (RT)... ✓\n",
      "   Creating path_25 (RT)... ✓\n",
      "   Creating path_26 (RT)... ✓\n",
      "   Creating path_27 (RT)... ✓\n",
      "   Creating path_28 (RT)... ✓\n",
      "   Creating path_29 (RT)... ✓\n",
      "   Creating path_30 (RT)... ✓\n",
      "   Creating path_31 (RT)... ✓\n",
      "   Creating path_32 (RT)... ✓\n",
      "   Creating path_33 (RT)... ✓\n",
      "   Creating path_34 (RT)... ✓\n",
      "   Creating path_35 (RT)... ✓\n",
      "   Creating path_36 (RT)... ✓\n",
      "   Creating path_37 (RT)... ✓\n",
      "   Creating path_38 (RT)... ✓\n",
      "   Creating path_39 (RT)... ✓\n",
      "   Creating path_40 (RT)... ✓\n",
      "   Creating path_41 (RT)... ✓\n",
      "   Creating path_42 (RT)... ✓\n",
      "   Creating path_43 (RT)... ✓\n",
      "   Creating path_44 (RT)... ✓\n",
      "   Creating path_45 (RT)... ✓\n",
      "   Creating path_46 (RT)... ✓\n",
      "   Creating path_47 (RT)... ✓\n",
      "   Creating path_48 (RT)... ✓\n",
      "   Creating path_49 (RT)... ✓\n",
      "   Creating path_50 (RT)... ✓\n",
      "   Creating path_51 (RT)... ✓\n",
      "   Creating path_52 (RT)... ✓\n",
      "   Creating path_53 (RT)... ✓\n",
      "   Creating path_54 (RT)... ✓\n",
      "   Creating path_55 (RT)... ✓\n",
      "   Creating path_56 (RT)... ✓\n",
      "   Creating path_57 (RT)... ✓\n",
      "   Creating path_58 (RT)... ✓\n",
      "   Creating path_59 (RT)... ✓\n",
      "   Creating path_60 (RT)... ✓\n",
      "   Creating path_61 (RT)... ✓\n",
      "   Creating path_62 (RT)... ✓\n",
      "   Creating path_63 (RT)... ✓\n",
      "   Creating path_64 (RT)... ✓\n",
      "   Creating path_65 (RT)... ✓\n",
      "   Creating path_66 (RT)... ✓\n",
      "   Creating path_67 (RT)... ✓\n",
      "   Creating path_68 (RT)... ✓\n",
      "   Creating path_69 (RT)... ✓\n",
      "   Creating path_70 (RT)... ✓\n",
      "   Creating path_71 (RT)... ✓\n",
      "   Creating path_72 (RT)... ✓\n",
      "   Creating path_73 (RT)... ✓\n",
      "   Creating path_74 (RT)... ✓\n",
      "   Creating path_75 (RT)... ✓\n",
      "   Creating path_76 (RT)... ✓\n",
      "   Creating path_77 (RT)... ✓\n",
      "   Creating path_78 (RT)... ✓\n",
      "   Creating path_79 (RT)... ✓\n",
      "   Creating path_80 (RT)... ✓\n",
      "   Creating path_81 (RT)... ✓\n",
      "   Creating path_82 (RT)... ✓\n",
      "   Creating path_83 (RT)... ✓\n",
      "   Creating path_84 (RT)... ✓\n",
      "   Creating path_85 (RT)... ✓\n",
      "   Creating path_86 (RT)... ✓\n",
      "   Creating path_87 (RT)... ✓\n",
      "   Creating path_88 (RT)... ✓\n",
      "   Creating path_89 (RT)... ✓\n",
      "   Creating path_90 (RT)... ✓\n",
      "   Creating path_91 (RT)... ✓\n",
      "   Creating path_92 (RT)... ✓\n",
      "   Creating path_93 (RT)... ✓\n",
      "   Creating path_94 (RT)... ✓\n",
      "   Creating path_95 (RT)... ✓\n",
      "   Creating path_96 (RT)... ✓\n",
      "   Creating path_97 (RT)... ✓\n",
      "   Creating path_98 (RT)... ✓\n",
      "   Creating path_99 (RT)... ✓\n",
      "   Creating path_100 (RT)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME synthetic paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME PRICE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME price timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 14 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 14 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 14 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME VALUES)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME prices)...\n",
      "   ✓ Created historical data (original REAL-TIME values):\n",
      "      - Hourly: 116154 records\n",
      "      - Daily: 4840 records (generation-weighted)\n",
      "      - Monthly: 159 records (generation-weighted)\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME prices)...\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_hourly_timeseries.csv\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_daily_timeseries.csv\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME prices)...\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_hourly_historical.csv\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_daily_historical.csv\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Price_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Price_rt/historical/ (original)\n",
      "\n",
      "📌 Note: These files use REAL-TIME bootstrap selections and compressed RT prices\n",
      "\n",
      "[2/7] Processing Blue_Wing_Solar_Energy_Generator...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Blue_Wing_Solar_Energy_Generator_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Blue_Wing_Solar_Energy_Generator (REAL-TIME Price Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Blue_Wing_Solar_Energy_Generator_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering REAL-TIME price data...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid REAL-TIME prices: 112,261\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME prices...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME price data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,261\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from REAL-TIME bootstrap selections...\n",
      "   Creating path_1 (RT)... ✓\n",
      "   Creating path_2 (RT)... ✓\n",
      "   Creating path_3 (RT)... ✓\n",
      "   Creating path_4 (RT)... ✓\n",
      "   Creating path_5 (RT)... ✓\n",
      "   Creating path_6 (RT)... ✓\n",
      "   Creating path_7 (RT)... ✓\n",
      "   Creating path_8 (RT)... ✓\n",
      "   Creating path_9 (RT)... ✓\n",
      "   Creating path_10 (RT)... ✓\n",
      "   Creating path_11 (RT)... ✓\n",
      "   Creating path_12 (RT)... ✓\n",
      "   Creating path_13 (RT)... ✓\n",
      "   Creating path_14 (RT)... ✓\n",
      "   Creating path_15 (RT)... ✓\n",
      "   Creating path_16 (RT)... ✓\n",
      "   Creating path_17 (RT)... ✓\n",
      "   Creating path_18 (RT)... ✓\n",
      "   Creating path_19 (RT)... ✓\n",
      "   Creating path_20 (RT)... ✓\n",
      "   Creating path_21 (RT)... ✓\n",
      "   Creating path_22 (RT)... ✓\n",
      "   Creating path_23 (RT)... ✓\n",
      "   Creating path_24 (RT)... ✓\n",
      "   Creating path_25 (RT)... ✓\n",
      "   Creating path_26 (RT)... ✓\n",
      "   Creating path_27 (RT)... ✓\n",
      "   Creating path_28 (RT)... ✓\n",
      "   Creating path_29 (RT)... ✓\n",
      "   Creating path_30 (RT)... ✓\n",
      "   Creating path_31 (RT)... ✓\n",
      "   Creating path_32 (RT)... ✓\n",
      "   Creating path_33 (RT)... ✓\n",
      "   Creating path_34 (RT)... ✓\n",
      "   Creating path_35 (RT)... ✓\n",
      "   Creating path_36 (RT)... ✓\n",
      "   Creating path_37 (RT)... ✓\n",
      "   Creating path_38 (RT)... ✓\n",
      "   Creating path_39 (RT)... ✓\n",
      "   Creating path_40 (RT)... ✓\n",
      "   Creating path_41 (RT)... ✓\n",
      "   Creating path_42 (RT)... ✓\n",
      "   Creating path_43 (RT)... ✓\n",
      "   Creating path_44 (RT)... ✓\n",
      "   Creating path_45 (RT)... ✓\n",
      "   Creating path_46 (RT)... ✓\n",
      "   Creating path_47 (RT)... ✓\n",
      "   Creating path_48 (RT)... ✓\n",
      "   Creating path_49 (RT)... ✓\n",
      "   Creating path_50 (RT)... ✓\n",
      "   Creating path_51 (RT)... ✓\n",
      "   Creating path_52 (RT)... ✓\n",
      "   Creating path_53 (RT)... ✓\n",
      "   Creating path_54 (RT)... ✓\n",
      "   Creating path_55 (RT)... ✓\n",
      "   Creating path_56 (RT)... ✓\n",
      "   Creating path_57 (RT)... ✓\n",
      "   Creating path_58 (RT)... ✓\n",
      "   Creating path_59 (RT)... ✓\n",
      "   Creating path_60 (RT)... ✓\n",
      "   Creating path_61 (RT)... ✓\n",
      "   Creating path_62 (RT)... ✓\n",
      "   Creating path_63 (RT)... ✓\n",
      "   Creating path_64 (RT)... ✓\n",
      "   Creating path_65 (RT)... ✓\n",
      "   Creating path_66 (RT)... ✓\n",
      "   Creating path_67 (RT)... ✓\n",
      "   Creating path_68 (RT)... ✓\n",
      "   Creating path_69 (RT)... ✓\n",
      "   Creating path_70 (RT)... ✓\n",
      "   Creating path_71 (RT)... ✓\n",
      "   Creating path_72 (RT)... ✓\n",
      "   Creating path_73 (RT)... ✓\n",
      "   Creating path_74 (RT)... ✓\n",
      "   Creating path_75 (RT)... ✓\n",
      "   Creating path_76 (RT)... ✓\n",
      "   Creating path_77 (RT)... ✓\n",
      "   Creating path_78 (RT)... ✓\n",
      "   Creating path_79 (RT)... ✓\n",
      "   Creating path_80 (RT)... ✓\n",
      "   Creating path_81 (RT)... ✓\n",
      "   Creating path_82 (RT)... ✓\n",
      "   Creating path_83 (RT)... ✓\n",
      "   Creating path_84 (RT)... ✓\n",
      "   Creating path_85 (RT)... ✓\n",
      "   Creating path_86 (RT)... ✓\n",
      "   Creating path_87 (RT)... ✓\n",
      "   Creating path_88 (RT)... ✓\n",
      "   Creating path_89 (RT)... ✓\n",
      "   Creating path_90 (RT)... ✓\n",
      "   Creating path_91 (RT)... ✓\n",
      "   Creating path_92 (RT)... ✓\n",
      "   Creating path_93 (RT)... ✓\n",
      "   Creating path_94 (RT)... ✓\n",
      "   Creating path_95 (RT)... ✓\n",
      "   Creating path_96 (RT)... ✓\n",
      "   Creating path_97 (RT)... ✓\n",
      "   Creating path_98 (RT)... ✓\n",
      "   Creating path_99 (RT)... ✓\n",
      "   Creating path_100 (RT)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME synthetic paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME PRICE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME price timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME VALUES)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME prices)...\n",
      "   ✓ Created historical data (original REAL-TIME values):\n",
      "      - Hourly: 112261 records\n",
      "      - Daily: 4685 records (generation-weighted)\n",
      "      - Monthly: 154 records (generation-weighted)\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME prices)...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_hourly_timeseries.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_daily_timeseries.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME prices)...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_hourly_historical.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_daily_historical.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_rt/historical/ (original)\n",
      "\n",
      "📌 Note: These files use REAL-TIME bootstrap selections and compressed RT prices\n",
      "\n",
      "[3/7] Processing Lamesa_Solar...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Lamesa_Solar_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2016-2025 (10 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Lamesa_Solar (REAL-TIME Price Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Lamesa_Solar_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering REAL-TIME price data...\n",
      "   Total rows: 398,209\n",
      "   Rows with valid REAL-TIME prices: 82,244\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME prices...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME price data):\n",
      "   All years available: 2016 to 2025 (10 years)\n",
      "   RT overlap years: 2016 to 2025 (10 years)\n",
      "   Total data points: 82,244\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from REAL-TIME bootstrap selections...\n",
      "   Creating path_1 (RT)... ✓\n",
      "   Creating path_2 (RT)... ✓\n",
      "   Creating path_3 (RT)... ✓\n",
      "   Creating path_4 (RT)... ✓\n",
      "   Creating path_5 (RT)... ✓\n",
      "   Creating path_6 (RT)... ✓\n",
      "   Creating path_7 (RT)... ✓\n",
      "   Creating path_8 (RT)... ✓\n",
      "   Creating path_9 (RT)... ✓\n",
      "   Creating path_10 (RT)... ✓\n",
      "   Creating path_11 (RT)... ✓\n",
      "   Creating path_12 (RT)... ✓\n",
      "   Creating path_13 (RT)... ✓\n",
      "   Creating path_14 (RT)... ✓\n",
      "   Creating path_15 (RT)... ✓\n",
      "   Creating path_16 (RT)... ✓\n",
      "   Creating path_17 (RT)... ✓\n",
      "   Creating path_18 (RT)... ✓\n",
      "   Creating path_19 (RT)... ✓\n",
      "   Creating path_20 (RT)... ✓\n",
      "   Creating path_21 (RT)... ✓\n",
      "   Creating path_22 (RT)... ✓\n",
      "   Creating path_23 (RT)... ✓\n",
      "   Creating path_24 (RT)... ✓\n",
      "   Creating path_25 (RT)... ✓\n",
      "   Creating path_26 (RT)... ✓\n",
      "   Creating path_27 (RT)... ✓\n",
      "   Creating path_28 (RT)... ✓\n",
      "   Creating path_29 (RT)... ✓\n",
      "   Creating path_30 (RT)... ✓\n",
      "   Creating path_31 (RT)... ✓\n",
      "   Creating path_32 (RT)... ✓\n",
      "   Creating path_33 (RT)... ✓\n",
      "   Creating path_34 (RT)... ✓\n",
      "   Creating path_35 (RT)... ✓\n",
      "   Creating path_36 (RT)... ✓\n",
      "   Creating path_37 (RT)... ✓\n",
      "   Creating path_38 (RT)... ✓\n",
      "   Creating path_39 (RT)... ✓\n",
      "   Creating path_40 (RT)... ✓\n",
      "   Creating path_41 (RT)... ✓\n",
      "   Creating path_42 (RT)... ✓\n",
      "   Creating path_43 (RT)... ✓\n",
      "   Creating path_44 (RT)... ✓\n",
      "   Creating path_45 (RT)... ✓\n",
      "   Creating path_46 (RT)... ✓\n",
      "   Creating path_47 (RT)... ✓\n",
      "   Creating path_48 (RT)... ✓\n",
      "   Creating path_49 (RT)... ✓\n",
      "   Creating path_50 (RT)... ✓\n",
      "   Creating path_51 (RT)... ✓\n",
      "   Creating path_52 (RT)... ✓\n",
      "   Creating path_53 (RT)... ✓\n",
      "   Creating path_54 (RT)... ✓\n",
      "   Creating path_55 (RT)... ✓\n",
      "   Creating path_56 (RT)... ✓\n",
      "   Creating path_57 (RT)... ✓\n",
      "   Creating path_58 (RT)... ✓\n",
      "   Creating path_59 (RT)... ✓\n",
      "   Creating path_60 (RT)... ✓\n",
      "   Creating path_61 (RT)... ✓\n",
      "   Creating path_62 (RT)... ✓\n",
      "   Creating path_63 (RT)... ✓\n",
      "   Creating path_64 (RT)... ✓\n",
      "   Creating path_65 (RT)... ✓\n",
      "   Creating path_66 (RT)... ✓\n",
      "   Creating path_67 (RT)... ✓\n",
      "   Creating path_68 (RT)... ✓\n",
      "   Creating path_69 (RT)... ✓\n",
      "   Creating path_70 (RT)... ✓\n",
      "   Creating path_71 (RT)... ✓\n",
      "   Creating path_72 (RT)... ✓\n",
      "   Creating path_73 (RT)... ✓\n",
      "   Creating path_74 (RT)... ✓\n",
      "   Creating path_75 (RT)... ✓\n",
      "   Creating path_76 (RT)... ✓\n",
      "   Creating path_77 (RT)... ✓\n",
      "   Creating path_78 (RT)... ✓\n",
      "   Creating path_79 (RT)... ✓\n",
      "   Creating path_80 (RT)... ✓\n",
      "   Creating path_81 (RT)... ✓\n",
      "   Creating path_82 (RT)... ✓\n",
      "   Creating path_83 (RT)... ✓\n",
      "   Creating path_84 (RT)... ✓\n",
      "   Creating path_85 (RT)... ✓\n",
      "   Creating path_86 (RT)... ✓\n",
      "   Creating path_87 (RT)... ✓\n",
      "   Creating path_88 (RT)... ✓\n",
      "   Creating path_89 (RT)... ✓\n",
      "   Creating path_90 (RT)... ✓\n",
      "   Creating path_91 (RT)... ✓\n",
      "   Creating path_92 (RT)... ✓\n",
      "   Creating path_93 (RT)... ✓\n",
      "   Creating path_94 (RT)... ✓\n",
      "   Creating path_95 (RT)... ✓\n",
      "   Creating path_96 (RT)... ✓\n",
      "   Creating path_97 (RT)... ✓\n",
      "   Creating path_98 (RT)... ✓\n",
      "   Creating path_99 (RT)... ✓\n",
      "   Creating path_100 (RT)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME synthetic paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME PRICE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME price timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 10 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 10 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 10 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME VALUES)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME prices)...\n",
      "   ✓ Created historical data (original REAL-TIME values):\n",
      "      - Hourly: 82244 records\n",
      "      - Daily: 3435 records (generation-weighted)\n",
      "      - Monthly: 113 records (generation-weighted)\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME prices)...\n",
      "   ✓ Lamesa_Solar_price_rt_hourly_timeseries.csv\n",
      "   ✓ Lamesa_Solar_price_rt_daily_timeseries.csv\n",
      "   ✓ Lamesa_Solar_price_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME prices)...\n",
      "   ✓ Lamesa_Solar_price_rt_hourly_historical.csv\n",
      "   ✓ Lamesa_Solar_price_rt_daily_historical.csv\n",
      "   ✓ Lamesa_Solar_price_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Price_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Price_rt/historical/ (original)\n",
      "\n",
      "📌 Note: These files use REAL-TIME bootstrap selections and compressed RT prices\n",
      "\n",
      "[4/7] Processing Midway_Solar_Farm_III...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Midway_Solar_Farm_III_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Midway_Solar_Farm_III (REAL-TIME Price Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Midway_Solar_Farm_III_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering REAL-TIME price data...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid REAL-TIME prices: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME prices...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME price data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from REAL-TIME bootstrap selections...\n",
      "   Creating path_1 (RT)... ✓\n",
      "   Creating path_2 (RT)... ✓\n",
      "   Creating path_3 (RT)... ✓\n",
      "   Creating path_4 (RT)... ✓\n",
      "   Creating path_5 (RT)... ✓\n",
      "   Creating path_6 (RT)... ✓\n",
      "   Creating path_7 (RT)... ✓\n",
      "   Creating path_8 (RT)... ✓\n",
      "   Creating path_9 (RT)... ✓\n",
      "   Creating path_10 (RT)... ✓\n",
      "   Creating path_11 (RT)... ✓\n",
      "   Creating path_12 (RT)... ✓\n",
      "   Creating path_13 (RT)... ✓\n",
      "   Creating path_14 (RT)... ✓\n",
      "   Creating path_15 (RT)... ✓\n",
      "   Creating path_16 (RT)... ✓\n",
      "   Creating path_17 (RT)... ✓\n",
      "   Creating path_18 (RT)... ✓\n",
      "   Creating path_19 (RT)... ✓\n",
      "   Creating path_20 (RT)... ✓\n",
      "   Creating path_21 (RT)... ✓\n",
      "   Creating path_22 (RT)... ✓\n",
      "   Creating path_23 (RT)... ✓\n",
      "   Creating path_24 (RT)... ✓\n",
      "   Creating path_25 (RT)... ✓\n",
      "   Creating path_26 (RT)... ✓\n",
      "   Creating path_27 (RT)... ✓\n",
      "   Creating path_28 (RT)... ✓\n",
      "   Creating path_29 (RT)... ✓\n",
      "   Creating path_30 (RT)... ✓\n",
      "   Creating path_31 (RT)... ✓\n",
      "   Creating path_32 (RT)... ✓\n",
      "   Creating path_33 (RT)... ✓\n",
      "   Creating path_34 (RT)... ✓\n",
      "   Creating path_35 (RT)... ✓\n",
      "   Creating path_36 (RT)... ✓\n",
      "   Creating path_37 (RT)... ✓\n",
      "   Creating path_38 (RT)... ✓\n",
      "   Creating path_39 (RT)... ✓\n",
      "   Creating path_40 (RT)... ✓\n",
      "   Creating path_41 (RT)... ✓\n",
      "   Creating path_42 (RT)... ✓\n",
      "   Creating path_43 (RT)... ✓\n",
      "   Creating path_44 (RT)... ✓\n",
      "   Creating path_45 (RT)... ✓\n",
      "   Creating path_46 (RT)... ✓\n",
      "   Creating path_47 (RT)... ✓\n",
      "   Creating path_48 (RT)... ✓\n",
      "   Creating path_49 (RT)... ✓\n",
      "   Creating path_50 (RT)... ✓\n",
      "   Creating path_51 (RT)... ✓\n",
      "   Creating path_52 (RT)... ✓\n",
      "   Creating path_53 (RT)... ✓\n",
      "   Creating path_54 (RT)... ✓\n",
      "   Creating path_55 (RT)... ✓\n",
      "   Creating path_56 (RT)... ✓\n",
      "   Creating path_57 (RT)... ✓\n",
      "   Creating path_58 (RT)... ✓\n",
      "   Creating path_59 (RT)... ✓\n",
      "   Creating path_60 (RT)... ✓\n",
      "   Creating path_61 (RT)... ✓\n",
      "   Creating path_62 (RT)... ✓\n",
      "   Creating path_63 (RT)... ✓\n",
      "   Creating path_64 (RT)... ✓\n",
      "   Creating path_65 (RT)... ✓\n",
      "   Creating path_66 (RT)... ✓\n",
      "   Creating path_67 (RT)... ✓\n",
      "   Creating path_68 (RT)... ✓\n",
      "   Creating path_69 (RT)... ✓\n",
      "   Creating path_70 (RT)... ✓\n",
      "   Creating path_71 (RT)... ✓\n",
      "   Creating path_72 (RT)... ✓\n",
      "   Creating path_73 (RT)... ✓\n",
      "   Creating path_74 (RT)... ✓\n",
      "   Creating path_75 (RT)... ✓\n",
      "   Creating path_76 (RT)... ✓\n",
      "   Creating path_77 (RT)... ✓\n",
      "   Creating path_78 (RT)... ✓\n",
      "   Creating path_79 (RT)... ✓\n",
      "   Creating path_80 (RT)... ✓\n",
      "   Creating path_81 (RT)... ✓\n",
      "   Creating path_82 (RT)... ✓\n",
      "   Creating path_83 (RT)... ✓\n",
      "   Creating path_84 (RT)... ✓\n",
      "   Creating path_85 (RT)... ✓\n",
      "   Creating path_86 (RT)... ✓\n",
      "   Creating path_87 (RT)... ✓\n",
      "   Creating path_88 (RT)... ✓\n",
      "   Creating path_89 (RT)... ✓\n",
      "   Creating path_90 (RT)... ✓\n",
      "   Creating path_91 (RT)... ✓\n",
      "   Creating path_92 (RT)... ✓\n",
      "   Creating path_93 (RT)... ✓\n",
      "   Creating path_94 (RT)... ✓\n",
      "   Creating path_95 (RT)... ✓\n",
      "   Creating path_96 (RT)... ✓\n",
      "   Creating path_97 (RT)... ✓\n",
      "   Creating path_98 (RT)... ✓\n",
      "   Creating path_99 (RT)... ✓\n",
      "   Creating path_100 (RT)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME synthetic paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME PRICE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME price timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME VALUES)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME prices)...\n",
      "   ✓ Created historical data (original REAL-TIME values):\n",
      "      - Hourly: 112546 records\n",
      "      - Daily: 4689 records (generation-weighted)\n",
      "      - Monthly: 154 records (generation-weighted)\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME prices)...\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_hourly_timeseries.csv\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_daily_timeseries.csv\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME prices)...\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_hourly_historical.csv\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_daily_historical.csv\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_rt/historical/ (original)\n",
      "\n",
      "📌 Note: These files use REAL-TIME bootstrap selections and compressed RT prices\n",
      "\n",
      "[5/7] Processing Misae_Solar...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Misae_Solar_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Misae_Solar (REAL-TIME Price Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Misae_Solar_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering REAL-TIME price data...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid REAL-TIME prices: 112,244\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME prices...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME price data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,244\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from REAL-TIME bootstrap selections...\n",
      "   Creating path_1 (RT)... ✓\n",
      "   Creating path_2 (RT)... ✓\n",
      "   Creating path_3 (RT)... ✓\n",
      "   Creating path_4 (RT)... ✓\n",
      "   Creating path_5 (RT)... ✓\n",
      "   Creating path_6 (RT)... ✓\n",
      "   Creating path_7 (RT)... ✓\n",
      "   Creating path_8 (RT)... ✓\n",
      "   Creating path_9 (RT)... ✓\n",
      "   Creating path_10 (RT)... ✓\n",
      "   Creating path_11 (RT)... ✓\n",
      "   Creating path_12 (RT)... ✓\n",
      "   Creating path_13 (RT)... ✓\n",
      "   Creating path_14 (RT)... ✓\n",
      "   Creating path_15 (RT)... ✓\n",
      "   Creating path_16 (RT)... ✓\n",
      "   Creating path_17 (RT)... ✓\n",
      "   Creating path_18 (RT)... ✓\n",
      "   Creating path_19 (RT)... ✓\n",
      "   Creating path_20 (RT)... ✓\n",
      "   Creating path_21 (RT)... ✓\n",
      "   Creating path_22 (RT)... ✓\n",
      "   Creating path_23 (RT)... ✓\n",
      "   Creating path_24 (RT)... ✓\n",
      "   Creating path_25 (RT)... ✓\n",
      "   Creating path_26 (RT)... ✓\n",
      "   Creating path_27 (RT)... ✓\n",
      "   Creating path_28 (RT)... ✓\n",
      "   Creating path_29 (RT)... ✓\n",
      "   Creating path_30 (RT)... ✓\n",
      "   Creating path_31 (RT)... ✓\n",
      "   Creating path_32 (RT)... ✓\n",
      "   Creating path_33 (RT)... ✓\n",
      "   Creating path_34 (RT)... ✓\n",
      "   Creating path_35 (RT)... ✓\n",
      "   Creating path_36 (RT)... ✓\n",
      "   Creating path_37 (RT)... ✓\n",
      "   Creating path_38 (RT)... ✓\n",
      "   Creating path_39 (RT)... ✓\n",
      "   Creating path_40 (RT)... ✓\n",
      "   Creating path_41 (RT)... ✓\n",
      "   Creating path_42 (RT)... ✓\n",
      "   Creating path_43 (RT)... ✓\n",
      "   Creating path_44 (RT)... ✓\n",
      "   Creating path_45 (RT)... ✓\n",
      "   Creating path_46 (RT)... ✓\n",
      "   Creating path_47 (RT)... ✓\n",
      "   Creating path_48 (RT)... ✓\n",
      "   Creating path_49 (RT)... ✓\n",
      "   Creating path_50 (RT)... ✓\n",
      "   Creating path_51 (RT)... ✓\n",
      "   Creating path_52 (RT)... ✓\n",
      "   Creating path_53 (RT)... ✓\n",
      "   Creating path_54 (RT)... ✓\n",
      "   Creating path_55 (RT)... ✓\n",
      "   Creating path_56 (RT)... ✓\n",
      "   Creating path_57 (RT)... ✓\n",
      "   Creating path_58 (RT)... ✓\n",
      "   Creating path_59 (RT)... ✓\n",
      "   Creating path_60 (RT)... ✓\n",
      "   Creating path_61 (RT)... ✓\n",
      "   Creating path_62 (RT)... ✓\n",
      "   Creating path_63 (RT)... ✓\n",
      "   Creating path_64 (RT)... ✓\n",
      "   Creating path_65 (RT)... ✓\n",
      "   Creating path_66 (RT)... ✓\n",
      "   Creating path_67 (RT)... ✓\n",
      "   Creating path_68 (RT)... ✓\n",
      "   Creating path_69 (RT)... ✓\n",
      "   Creating path_70 (RT)... ✓\n",
      "   Creating path_71 (RT)... ✓\n",
      "   Creating path_72 (RT)... ✓\n",
      "   Creating path_73 (RT)... ✓\n",
      "   Creating path_74 (RT)... ✓\n",
      "   Creating path_75 (RT)... ✓\n",
      "   Creating path_76 (RT)... ✓\n",
      "   Creating path_77 (RT)... ✓\n",
      "   Creating path_78 (RT)... ✓\n",
      "   Creating path_79 (RT)... ✓\n",
      "   Creating path_80 (RT)... ✓\n",
      "   Creating path_81 (RT)... ✓\n",
      "   Creating path_82 (RT)... ✓\n",
      "   Creating path_83 (RT)... ✓\n",
      "   Creating path_84 (RT)... ✓\n",
      "   Creating path_85 (RT)... ✓\n",
      "   Creating path_86 (RT)... ✓\n",
      "   Creating path_87 (RT)... ✓\n",
      "   Creating path_88 (RT)... ✓\n",
      "   Creating path_89 (RT)... ✓\n",
      "   Creating path_90 (RT)... ✓\n",
      "   Creating path_91 (RT)... ✓\n",
      "   Creating path_92 (RT)... ✓\n",
      "   Creating path_93 (RT)... ✓\n",
      "   Creating path_94 (RT)... ✓\n",
      "   Creating path_95 (RT)... ✓\n",
      "   Creating path_96 (RT)... ✓\n",
      "   Creating path_97 (RT)... ✓\n",
      "   Creating path_98 (RT)... ✓\n",
      "   Creating path_99 (RT)... ✓\n",
      "   Creating path_100 (RT)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME synthetic paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME PRICE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME price timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME VALUES)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME prices)...\n",
      "   ✓ Created historical data (original REAL-TIME values):\n",
      "      - Hourly: 112244 records\n",
      "      - Daily: 4685 records (generation-weighted)\n",
      "      - Monthly: 154 records (generation-weighted)\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME prices)...\n",
      "   ✓ Misae_Solar_price_rt_hourly_timeseries.csv\n",
      "   ✓ Misae_Solar_price_rt_daily_timeseries.csv\n",
      "   ✓ Misae_Solar_price_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME prices)...\n",
      "   ✓ Misae_Solar_price_rt_hourly_historical.csv\n",
      "   ✓ Misae_Solar_price_rt_daily_historical.csv\n",
      "   ✓ Misae_Solar_price_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Price_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Price_rt/historical/ (original)\n",
      "\n",
      "📌 Note: These files use REAL-TIME bootstrap selections and compressed RT prices\n",
      "\n",
      "[6/7] Processing Mount_Signal_Solar_Farm_II...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Mount_Signal_Solar_Farm_II_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Mount_Signal_Solar_Farm_II (REAL-TIME Price Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Mount_Signal_Solar_Farm_II_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering REAL-TIME price data...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid REAL-TIME prices: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME prices...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME price data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from REAL-TIME bootstrap selections...\n",
      "   Creating path_1 (RT)... ✓\n",
      "   Creating path_2 (RT)... ✓\n",
      "   Creating path_3 (RT)... ✓\n",
      "   Creating path_4 (RT)... ✓\n",
      "   Creating path_5 (RT)... ✓\n",
      "   Creating path_6 (RT)... ✓\n",
      "   Creating path_7 (RT)... ✓\n",
      "   Creating path_8 (RT)... ✓\n",
      "   Creating path_9 (RT)... ✓\n",
      "   Creating path_10 (RT)... ✓\n",
      "   Creating path_11 (RT)... ✓\n",
      "   Creating path_12 (RT)... ✓\n",
      "   Creating path_13 (RT)... ✓\n",
      "   Creating path_14 (RT)... ✓\n",
      "   Creating path_15 (RT)... ✓\n",
      "   Creating path_16 (RT)... ✓\n",
      "   Creating path_17 (RT)... ✓\n",
      "   Creating path_18 (RT)... ✓\n",
      "   Creating path_19 (RT)... ✓\n",
      "   Creating path_20 (RT)... ✓\n",
      "   Creating path_21 (RT)... ✓\n",
      "   Creating path_22 (RT)... ✓\n",
      "   Creating path_23 (RT)... ✓\n",
      "   Creating path_24 (RT)... ✓\n",
      "   Creating path_25 (RT)... ✓\n",
      "   Creating path_26 (RT)... ✓\n",
      "   Creating path_27 (RT)... ✓\n",
      "   Creating path_28 (RT)... ✓\n",
      "   Creating path_29 (RT)... ✓\n",
      "   Creating path_30 (RT)... ✓\n",
      "   Creating path_31 (RT)... ✓\n",
      "   Creating path_32 (RT)... ✓\n",
      "   Creating path_33 (RT)... ✓\n",
      "   Creating path_34 (RT)... ✓\n",
      "   Creating path_35 (RT)... ✓\n",
      "   Creating path_36 (RT)... ✓\n",
      "   Creating path_37 (RT)... ✓\n",
      "   Creating path_38 (RT)... ✓\n",
      "   Creating path_39 (RT)... ✓\n",
      "   Creating path_40 (RT)... ✓\n",
      "   Creating path_41 (RT)... ✓\n",
      "   Creating path_42 (RT)... ✓\n",
      "   Creating path_43 (RT)... ✓\n",
      "   Creating path_44 (RT)... ✓\n",
      "   Creating path_45 (RT)... ✓\n",
      "   Creating path_46 (RT)... ✓\n",
      "   Creating path_47 (RT)... ✓\n",
      "   Creating path_48 (RT)... ✓\n",
      "   Creating path_49 (RT)... ✓\n",
      "   Creating path_50 (RT)... ✓\n",
      "   Creating path_51 (RT)... ✓\n",
      "   Creating path_52 (RT)... ✓\n",
      "   Creating path_53 (RT)... ✓\n",
      "   Creating path_54 (RT)... ✓\n",
      "   Creating path_55 (RT)... ✓\n",
      "   Creating path_56 (RT)... ✓\n",
      "   Creating path_57 (RT)... ✓\n",
      "   Creating path_58 (RT)... ✓\n",
      "   Creating path_59 (RT)... ✓\n",
      "   Creating path_60 (RT)... ✓\n",
      "   Creating path_61 (RT)... ✓\n",
      "   Creating path_62 (RT)... ✓\n",
      "   Creating path_63 (RT)... ✓\n",
      "   Creating path_64 (RT)... ✓\n",
      "   Creating path_65 (RT)... ✓\n",
      "   Creating path_66 (RT)... ✓\n",
      "   Creating path_67 (RT)... ✓\n",
      "   Creating path_68 (RT)... ✓\n",
      "   Creating path_69 (RT)... ✓\n",
      "   Creating path_70 (RT)... ✓\n",
      "   Creating path_71 (RT)... ✓\n",
      "   Creating path_72 (RT)... ✓\n",
      "   Creating path_73 (RT)... ✓\n",
      "   Creating path_74 (RT)... ✓\n",
      "   Creating path_75 (RT)... ✓\n",
      "   Creating path_76 (RT)... ✓\n",
      "   Creating path_77 (RT)... ✓\n",
      "   Creating path_78 (RT)... ✓\n",
      "   Creating path_79 (RT)... ✓\n",
      "   Creating path_80 (RT)... ✓\n",
      "   Creating path_81 (RT)... ✓\n",
      "   Creating path_82 (RT)... ✓\n",
      "   Creating path_83 (RT)... ✓\n",
      "   Creating path_84 (RT)... ✓\n",
      "   Creating path_85 (RT)... ✓\n",
      "   Creating path_86 (RT)... ✓\n",
      "   Creating path_87 (RT)... ✓\n",
      "   Creating path_88 (RT)... ✓\n",
      "   Creating path_89 (RT)... ✓\n",
      "   Creating path_90 (RT)... ✓\n",
      "   Creating path_91 (RT)... ✓\n",
      "   Creating path_92 (RT)... ✓\n",
      "   Creating path_93 (RT)... ✓\n",
      "   Creating path_94 (RT)... ✓\n",
      "   Creating path_95 (RT)... ✓\n",
      "   Creating path_96 (RT)... ✓\n",
      "   Creating path_97 (RT)... ✓\n",
      "   Creating path_98 (RT)... ✓\n",
      "   Creating path_99 (RT)... ✓\n",
      "   Creating path_100 (RT)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME synthetic paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME PRICE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME price timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME VALUES)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME prices)...\n",
      "   ✓ Created historical data (original REAL-TIME values):\n",
      "      - Hourly: 112546 records\n",
      "      - Daily: 4689 records (generation-weighted)\n",
      "      - Monthly: 154 records (generation-weighted)\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME prices)...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_hourly_timeseries.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_daily_timeseries.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME prices)...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_hourly_historical.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_daily_historical.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_rt/historical/ (original)\n",
      "\n",
      "📌 Note: These files use REAL-TIME bootstrap selections and compressed RT prices\n",
      "\n",
      "[7/7] Processing RE_Mustang_LLC...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: RE_Mustang_LLC_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: RE_Mustang_LLC (REAL-TIME Price Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: RE_Mustang_LLC_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering REAL-TIME price data...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid REAL-TIME prices: 112,530\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME prices...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME price data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,530\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic paths from REAL-TIME bootstrap selections...\n",
      "   Creating path_1 (RT)... ✓\n",
      "   Creating path_2 (RT)... ✓\n",
      "   Creating path_3 (RT)... ✓\n",
      "   Creating path_4 (RT)... ✓\n",
      "   Creating path_5 (RT)... ✓\n",
      "   Creating path_6 (RT)... ✓\n",
      "   Creating path_7 (RT)... ✓\n",
      "   Creating path_8 (RT)... ✓\n",
      "   Creating path_9 (RT)... ✓\n",
      "   Creating path_10 (RT)... ✓\n",
      "   Creating path_11 (RT)... ✓\n",
      "   Creating path_12 (RT)... ✓\n",
      "   Creating path_13 (RT)... ✓\n",
      "   Creating path_14 (RT)... ✓\n",
      "   Creating path_15 (RT)... ✓\n",
      "   Creating path_16 (RT)... ✓\n",
      "   Creating path_17 (RT)... ✓\n",
      "   Creating path_18 (RT)... ✓\n",
      "   Creating path_19 (RT)... ✓\n",
      "   Creating path_20 (RT)... ✓\n",
      "   Creating path_21 (RT)... ✓\n",
      "   Creating path_22 (RT)... ✓\n",
      "   Creating path_23 (RT)... ✓\n",
      "   Creating path_24 (RT)... ✓\n",
      "   Creating path_25 (RT)... ✓\n",
      "   Creating path_26 (RT)... ✓\n",
      "   Creating path_27 (RT)... ✓\n",
      "   Creating path_28 (RT)... ✓\n",
      "   Creating path_29 (RT)... ✓\n",
      "   Creating path_30 (RT)... ✓\n",
      "   Creating path_31 (RT)... ✓\n",
      "   Creating path_32 (RT)... ✓\n",
      "   Creating path_33 (RT)... ✓\n",
      "   Creating path_34 (RT)... ✓\n",
      "   Creating path_35 (RT)... ✓\n",
      "   Creating path_36 (RT)... ✓\n",
      "   Creating path_37 (RT)... ✓\n",
      "   Creating path_38 (RT)... ✓\n",
      "   Creating path_39 (RT)... ✓\n",
      "   Creating path_40 (RT)... ✓\n",
      "   Creating path_41 (RT)... ✓\n",
      "   Creating path_42 (RT)... ✓\n",
      "   Creating path_43 (RT)... ✓\n",
      "   Creating path_44 (RT)... ✓\n",
      "   Creating path_45 (RT)... ✓\n",
      "   Creating path_46 (RT)... ✓\n",
      "   Creating path_47 (RT)... ✓\n",
      "   Creating path_48 (RT)... ✓\n",
      "   Creating path_49 (RT)... ✓\n",
      "   Creating path_50 (RT)... ✓\n",
      "   Creating path_51 (RT)... ✓\n",
      "   Creating path_52 (RT)... ✓\n",
      "   Creating path_53 (RT)... ✓\n",
      "   Creating path_54 (RT)... ✓\n",
      "   Creating path_55 (RT)... ✓\n",
      "   Creating path_56 (RT)... ✓\n",
      "   Creating path_57 (RT)... ✓\n",
      "   Creating path_58 (RT)... ✓\n",
      "   Creating path_59 (RT)... ✓\n",
      "   Creating path_60 (RT)... ✓\n",
      "   Creating path_61 (RT)... ✓\n",
      "   Creating path_62 (RT)... ✓\n",
      "   Creating path_63 (RT)... ✓\n",
      "   Creating path_64 (RT)... ✓\n",
      "   Creating path_65 (RT)... ✓\n",
      "   Creating path_66 (RT)... ✓\n",
      "   Creating path_67 (RT)... ✓\n",
      "   Creating path_68 (RT)... ✓\n",
      "   Creating path_69 (RT)... ✓\n",
      "   Creating path_70 (RT)... ✓\n",
      "   Creating path_71 (RT)... ✓\n",
      "   Creating path_72 (RT)... ✓\n",
      "   Creating path_73 (RT)... ✓\n",
      "   Creating path_74 (RT)... ✓\n",
      "   Creating path_75 (RT)... ✓\n",
      "   Creating path_76 (RT)... ✓\n",
      "   Creating path_77 (RT)... ✓\n",
      "   Creating path_78 (RT)... ✓\n",
      "   Creating path_79 (RT)... ✓\n",
      "   Creating path_80 (RT)... ✓\n",
      "   Creating path_81 (RT)... ✓\n",
      "   Creating path_82 (RT)... ✓\n",
      "   Creating path_83 (RT)... ✓\n",
      "   Creating path_84 (RT)... ✓\n",
      "   Creating path_85 (RT)... ✓\n",
      "   Creating path_86 (RT)... ✓\n",
      "   Creating path_87 (RT)... ✓\n",
      "   Creating path_88 (RT)... ✓\n",
      "   Creating path_89 (RT)... ✓\n",
      "   Creating path_90 (RT)... ✓\n",
      "   Creating path_91 (RT)... ✓\n",
      "   Creating path_92 (RT)... ✓\n",
      "   Creating path_93 (RT)... ✓\n",
      "   Creating path_94 (RT)... ✓\n",
      "   Creating path_95 (RT)... ✓\n",
      "   Creating path_96 (RT)... ✓\n",
      "   Creating path_97 (RT)... ✓\n",
      "   Creating path_98 (RT)... ✓\n",
      "   Creating path_99 (RT)... ✓\n",
      "   Creating path_100 (RT)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME synthetic paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME PRICE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME price timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY generation-weighted REAL-TIME price timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME VALUES)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME prices)...\n",
      "   ✓ Created historical data (original REAL-TIME values):\n",
      "      - Hourly: 112530 records\n",
      "      - Daily: 4689 records (generation-weighted)\n",
      "      - Monthly: 154 records (generation-weighted)\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME prices)...\n",
      "   ✓ RE_Mustang_LLC_price_rt_hourly_timeseries.csv\n",
      "   ✓ RE_Mustang_LLC_price_rt_daily_timeseries.csv\n",
      "   ✓ RE_Mustang_LLC_price_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME prices)...\n",
      "   ✓ RE_Mustang_LLC_price_rt_hourly_historical.csv\n",
      "   ✓ RE_Mustang_LLC_price_rt_daily_historical.csv\n",
      "   ✓ RE_Mustang_LLC_price_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Price_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Price_rt/historical/ (original)\n",
      "\n",
      "📌 Note: These files use REAL-TIME bootstrap selections and compressed RT prices\n",
      "\n",
      "============================================================\n",
      "✨ PHASE 1b COMPLETE!\n",
      "============================================================\n",
      "\n",
      "📊 Summary:\n",
      "   ✅ Successfully processed: 7 sites\n",
      "\n",
      "📁 Files saved:\n",
      "   • Price_rt/forecast/timeseries/ - Compressed REAL-TIME prices + synthetic paths\n",
      "   • Price_rt/historical/ - Original REAL-TIME price values\n",
      "\n",
      "📌 Next step: Run Phase 1c for real-time revenue data preparation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PriceDataPreparation:\n",
    "    \"\"\"\n",
    "    Phase 1b: Create price historical data and timeseries (with synthetic paths)\n",
    "    Unified implementation for both DAY-AHEAD and REAL-TIME pipelines\n",
    "    Uses bootstrap selections from Phase 0\n",
    "    Applies compression for forecast files, keeps original for historical\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline_type='da'):\n",
    "        \"\"\"\n",
    "        Initialize the price data preparation\n",
    "        \n",
    "        Args:\n",
    "            pipeline_type (str): 'da' for day-ahead or 'rt' for real-time\n",
    "        \"\"\"\n",
    "        # Validate pipeline type\n",
    "        if pipeline_type not in ['da', 'rt']:\n",
    "            raise ValueError(\"pipeline_type must be 'da' or 'rt'\")\n",
    "        \n",
    "        self.pipeline_type = pipeline_type\n",
    "        \n",
    "        # Define paths\n",
    "        self.data_path = Path('aamani_data')\n",
    "        self.base_output_path = Path('Renewable Portfolio LLC')\n",
    "        \n",
    "        # Set pipeline-specific configurations\n",
    "        if pipeline_type == 'da':\n",
    "            self.bootstrap_path = self.base_output_path / 'bootstrap_selections_da'\n",
    "            self.price_column = 'price_da'\n",
    "            self.output_folder = 'Price_da'\n",
    "            self.file_prefix = 'price_da'\n",
    "            self.pipeline_name = \"DAY-AHEAD\"\n",
    "            self.pipeline_name_short = \"DA\"\n",
    "        else:  # rt\n",
    "            self.bootstrap_path = self.base_output_path / 'bootstrap_selections_rt'\n",
    "            self.price_column = 'price_rt'  # Default, may be overridden per site\n",
    "            self.output_folder = 'Price_rt'\n",
    "            self.file_prefix = 'price_rt'\n",
    "            self.pipeline_name = \"REAL-TIME\"\n",
    "            self.pipeline_name_short = \"RT\"\n",
    "        \n",
    "        # Get available combined files and create mapping\n",
    "        self.available_files = list(self.data_path.glob('*_generation_price_combined.csv'))\n",
    "        self.available_sites = []\n",
    "        self.site_file_map = {}  # Map clean site names to actual filenames\n",
    "        \n",
    "        for f in self.available_files:\n",
    "            # Store the full filename (without path)\n",
    "            full_filename = f.name\n",
    "            \n",
    "            # Extract site name by removing '_generation_price_combined.csv'\n",
    "            site_name = f.stem.replace('_generation_price_combined', '')\n",
    "            \n",
    "            # Clean up the site name by removing '_hourly' to avoid redundancy\n",
    "            clean_site_name = site_name.replace('_hourly', '')\n",
    "            \n",
    "            self.available_sites.append(clean_site_name)\n",
    "            # Map the clean name to the actual filename\n",
    "            self.site_file_map[clean_site_name] = full_filename\n",
    "        \n",
    "        # Bootstrap selections will be loaded per site\n",
    "        self.bootstrap_selections = None\n",
    "        self.n_synthetic_paths = None\n",
    "        self.bootstrap_metadata = None\n",
    "        \n",
    "        # Define compression thresholds (P15 and P85 for compression)\n",
    "        self.compression_lower = 15\n",
    "        self.compression_upper = 85\n",
    "        \n",
    "        # Month names for labeling\n",
    "        self.month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        self.month_names_full = ['', 'January', 'February', 'March', 'April', 'May', 'June',\n",
    "                                'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    def get_site_selection(self):\n",
    "        \"\"\"\n",
    "        Interactive site selection with bootstrap availability check\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{self.pipeline_name} PRICE DATA PREPARATION - SITE SELECTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.available_sites:\n",
    "            print(\"❌ No combined generation-price files found in aamani_data!\")\n",
    "            return None\n",
    "        \n",
    "        # Check which sites have bootstrap selections\n",
    "        sites_with_bootstrap = []\n",
    "        for site in self.available_sites:\n",
    "            bootstrap_file = self.bootstrap_path / f\"{site}_bootstrap_selections_{self.pipeline_type}_latest.json\"\n",
    "            if bootstrap_file.exists():\n",
    "                # Verify it's actually the correct bootstrap file\n",
    "                with open(bootstrap_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    expected_type = 'day_ahead' if self.pipeline_type == 'da' else 'real_time'\n",
    "                    if data.get('pipeline_type') == expected_type:\n",
    "                        sites_with_bootstrap.append(site)\n",
    "        \n",
    "        if not sites_with_bootstrap:\n",
    "            print(f\"❌ No {self.pipeline_name} bootstrap selections found!\")\n",
    "            print(f\"   Please run Phase 0 first.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n✅ Found {self.pipeline_name} bootstrap selections for {len(sites_with_bootstrap)} sites\")\n",
    "        \n",
    "        print(\"\\nAvailable options:\")\n",
    "        print(f\"0. ALL SITES (Process all sites with {self.pipeline_name_short} bootstrap selections)\")\n",
    "        for i, site in enumerate(sites_with_bootstrap):\n",
    "            print(f\"{i+1}. {site}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selection = input(\"\\n💰 Select option number (0 for all sites): \").strip()\n",
    "                if selection == '0':\n",
    "                    return 'ALL_SITES', sites_with_bootstrap\n",
    "                else:\n",
    "                    idx = int(selection) - 1\n",
    "                    if 0 <= idx < len(sites_with_bootstrap):\n",
    "                        return sites_with_bootstrap[idx], [sites_with_bootstrap[idx]]\n",
    "                    else:\n",
    "                        print(\"❌ Invalid selection!\")\n",
    "            except:\n",
    "                print(\"❌ Please enter a valid number!\")\n",
    "    \n",
    "    def load_bootstrap_selections(self, site_name):\n",
    "        \"\"\"\n",
    "        Load bootstrap selections for a specific site\n",
    "        \"\"\"\n",
    "        bootstrap_file = self.bootstrap_path / f\"{site_name}_bootstrap_selections_{self.pipeline_type}_latest.json\"\n",
    "        \n",
    "        if not bootstrap_file.exists():\n",
    "            print(f\"❌ {self.pipeline_name} bootstrap selections not found for {site_name}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"\\n📁 Loading {self.pipeline_name} bootstrap selections from: {bootstrap_file.name}\")\n",
    "        \n",
    "        with open(bootstrap_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Verify this is the correct bootstrap file\n",
    "        expected_type = 'day_ahead' if self.pipeline_type == 'da' else 'real_time'\n",
    "        if data.get('pipeline_type') != expected_type:\n",
    "            print(f\"❌ Error: Bootstrap file is not for {self.pipeline_name.lower()} pipeline!\")\n",
    "            return False\n",
    "        \n",
    "        self.bootstrap_selections = data['selections']\n",
    "        self.n_synthetic_paths = data['n_paths']\n",
    "        self.bootstrap_metadata = data['metadata']\n",
    "        \n",
    "        # For RT, get the actual price column used\n",
    "        if self.pipeline_type == 'rt' and 'price_column' in self.bootstrap_metadata:\n",
    "            self.price_column = self.bootstrap_metadata['price_column']\n",
    "        \n",
    "        print(f\"   ✓ Loaded {self.n_synthetic_paths} {self.pipeline_name} path selections\")\n",
    "        print(f\"   ✓ Years used: {self.bootstrap_metadata['year_range']} ({self.bootstrap_metadata['n_years']} years)\")\n",
    "        print(f\"   ✓ Price type: {self.pipeline_name}\")\n",
    "        if self.pipeline_type == 'rt':\n",
    "            print(f\"   ✓ Price column: {self.price_column}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def get_automatic_month_range(self):\n",
    "        \"\"\"\n",
    "        Automatically determine month range: current month to 11 months later\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        start_month = current_month\n",
    "        if start_month == 1:\n",
    "            end_month = 12\n",
    "        else:\n",
    "            end_month = start_month - 1\n",
    "        \n",
    "        print(f\"\\n📅 Auto-detected period: {self.month_names[start_month]} to {self.month_names[end_month]} (12 months)\")\n",
    "        print(f\"   Starting from current month: {self.month_names[current_month]}\")\n",
    "        \n",
    "        return start_month, end_month\n",
    "    \n",
    "    def get_months_in_range(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Get list of months in range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        if start_month <= end_month:\n",
    "            return list(range(start_month, end_month + 1))\n",
    "        else:\n",
    "            return list(range(start_month, 13)) + list(range(1, end_month + 1))\n",
    "    \n",
    "    def filter_data_for_months(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Filter dataframe for month range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return df[df['month'].isin(months_in_range)].copy()\n",
    "    \n",
    "    def create_month_order_map(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create a mapping for sorting months in the specified order\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return {month: idx for idx, month in enumerate(months_in_range)}\n",
    "    \n",
    "    def compress_outliers(self, values, lower_pct=15, upper_pct=85):\n",
    "        \"\"\"\n",
    "        Compress outliers using logarithmic compression\n",
    "        \"\"\"\n",
    "        # Calculate compression thresholds\n",
    "        P_lower = np.percentile(values, lower_pct)\n",
    "        P_upper = np.percentile(values, upper_pct)\n",
    "        \n",
    "        # Create compressed values array\n",
    "        compressed = np.copy(values)\n",
    "        \n",
    "        # Compress lower tail (negative extremes)\n",
    "        lower_mask = values < P_lower\n",
    "        if np.any(lower_mask):\n",
    "            offset = P_lower - values[lower_mask]\n",
    "            compressed[lower_mask] = P_lower - np.log1p(offset)\n",
    "        \n",
    "        # Compress upper tail (positive extremes)\n",
    "        upper_mask = values > P_upper\n",
    "        if np.any(upper_mask):\n",
    "            offset = values[upper_mask] - P_upper\n",
    "            compressed[upper_mask] = P_upper + np.log1p(offset)\n",
    "        \n",
    "        return compressed\n",
    "    \n",
    "    def calculate_compression_parameters(self, df):\n",
    "        \"\"\"\n",
    "        Calculate P15 and P85 for each month-day-hour slot across all years\n",
    "        \"\"\"\n",
    "        print(f\"\\n📊 Calculating compression parameters for {self.pipeline_name} prices...\")\n",
    "        \n",
    "        compression_params = {}\n",
    "        grouped = df.groupby(['month', 'day', 'hour'])\n",
    "        \n",
    "        for (month, day, hour), group in grouped:\n",
    "            if len(group) >= 5 and group[self.price_column].notna().sum() >= 5:\n",
    "                prices = group[self.price_column].dropna().values\n",
    "                P_lower = np.percentile(prices, self.compression_lower)\n",
    "                P_upper = np.percentile(prices, self.compression_upper)\n",
    "                compression_params[(month, day, hour)] = (P_lower, P_upper)\n",
    "        \n",
    "        print(f\"   ✓ Calculated compression parameters for {len(compression_params)} time slots\")\n",
    "        \n",
    "        return compression_params\n",
    "    \n",
    "    def apply_compression_to_dataframe(self, df, compression_params):\n",
    "        \"\"\"\n",
    "        Apply compression to an entire dataframe\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        def compress_value(row):\n",
    "            if pd.isna(row[self.price_column]):\n",
    "                return np.nan\n",
    "                \n",
    "            key = (row['month'], row['day'], row['hour'])\n",
    "            if key in compression_params:\n",
    "                P_lower, P_upper = compression_params[key]\n",
    "                value = row[self.price_column]\n",
    "                \n",
    "                if value < P_lower:\n",
    "                    offset = P_lower - value\n",
    "                    return P_lower - np.log1p(offset)\n",
    "                elif value > P_upper:\n",
    "                    offset = value - P_upper\n",
    "                    return P_upper + np.log1p(offset)\n",
    "                else:\n",
    "                    return value\n",
    "            else:\n",
    "                return row[self.price_column]\n",
    "        \n",
    "        df[f'{self.price_column}_compressed'] = df.apply(compress_value, axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def generate_synthetic_paths_from_bootstrap(self, df, compression_params):\n",
    "        \"\"\"\n",
    "        Generate synthetic paths using bootstrap selections\n",
    "        Apply compression to the synthetic paths\n",
    "        \"\"\"\n",
    "        print(f\"\\n🎲 Generating {self.n_synthetic_paths} synthetic paths from {self.pipeline_name} bootstrap selections...\")\n",
    "        \n",
    "        synthetic_data = {}\n",
    "        \n",
    "        for path_name, path_selection in self.bootstrap_selections.items():\n",
    "            print(f\"   Creating {path_name} ({self.pipeline_name_short})...\", end='')\n",
    "            path_data = []\n",
    "            \n",
    "            # For each month in the selection\n",
    "            for month_name, selected_year in path_selection.items():\n",
    "                if selected_year is None:\n",
    "                    continue\n",
    "                \n",
    "                # Get month number\n",
    "                month_num = self.month_names.index(month_name)\n",
    "                \n",
    "                # Get all data for this year-month combination\n",
    "                month_data = df[(df['year'] == selected_year) & (df['month'] == month_num)]\n",
    "                \n",
    "                if len(month_data) > 0:\n",
    "                    # Apply compression to this month's data\n",
    "                    month_data_compressed = self.apply_compression_to_dataframe(month_data, compression_params)\n",
    "                    path_data.append(month_data_compressed)\n",
    "            \n",
    "            # Combine all months for this path\n",
    "            if path_data:\n",
    "                path_df = pd.concat(path_data, ignore_index=True)\n",
    "                synthetic_data[path_name] = path_df\n",
    "                print(f\" ✓\")\n",
    "            else:\n",
    "                print(f\" ✗ (No data)\")\n",
    "        \n",
    "        print(f\"\\n   ✓ Successfully created {len(synthetic_data)} {self.pipeline_name} synthetic paths with compression\")\n",
    "        \n",
    "        return synthetic_data\n",
    "    \n",
    "    def create_hourly_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create hourly timeseries with COMPRESSED values for both historical and synthetic\n",
    "        \"\"\"\n",
    "        print(f\"\\n⏰ Creating HOURLY {self.pipeline_name} price timeseries (compressed)...\")\n",
    "        \n",
    "        df_work = df_filtered.copy()\n",
    "        df_work['month_order'] = df_work['month'].map(month_order_map)\n",
    "        \n",
    "        # Use compressed values for historical data\n",
    "        price_col_to_use = f'{self.price_column}_compressed'\n",
    "        \n",
    "        # Pivot for compressed prices\n",
    "        pivot_df = df_work.pivot_table(\n",
    "            index=['month', 'day', 'hour', 'month_order'],\n",
    "            columns='year',\n",
    "            values=price_col_to_use,\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths (already compressed)\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            path_grouped = path_filtered.groupby(['month', 'day', 'hour'])[price_col_to_use].mean()\n",
    "            \n",
    "            pivot_df[path_name] = pivot_df.apply(\n",
    "                lambda row: path_grouped.get((int(row['month']), int(row['day']), int(row['hour'])), np.nan),\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        pivot_df['datetime_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d} {int(row['hour']):02d}:00\",\n",
    "            axis=1\n",
    "        )\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns - only include years that were in overlap\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int) and col in overlap_years])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['datetime_label', 'month', 'day', 'hour'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   ✓ Created compressed timeseries with {len(year_cols)} historical years ({self.pipeline_name_short} overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_daily_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create daily GENERATION-WEIGHTED price timeseries with COMPRESSED values\n",
    "        \"\"\"\n",
    "        print(f\"\\n📅 Creating DAILY generation-weighted {self.pipeline_name} price timeseries...\")\n",
    "        \n",
    "        # Calculate weighted daily prices for historical data\n",
    "        def calc_weighted_price(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            gen_positive = group.loc[mask]\n",
    "            # Use compressed prices for weighting\n",
    "            price_col = f'{self.price_column}_compressed'\n",
    "            return (gen_positive[price_col] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "        \n",
    "        df_daily = df_filtered.groupby(['year', 'month', 'day']).apply(calc_weighted_price).reset_index()\n",
    "        df_daily.columns = ['year', 'month', 'day', f'weighted_{self.price_column}']\n",
    "        df_daily['month_order'] = df_daily['month'].map(month_order_map)\n",
    "        \n",
    "        # Create pivot for historical\n",
    "        pivot_df = df_daily.pivot_table(\n",
    "            index=['month', 'day', 'month_order'],\n",
    "            columns='year',\n",
    "            values=f'weighted_{self.price_column}',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            # Calculate weighted prices for path\n",
    "            path_daily_weighted = path_filtered.groupby(['month', 'day']).apply(\n",
    "                lambda g: (g[f'{self.price_column}_compressed'] * g['generation_mw']).sum() / g['generation_mw'].sum() \n",
    "                if (g['generation_mw'] > 0).sum() > 0 else np.nan\n",
    "            )\n",
    "            \n",
    "            pivot_df[path_name] = pivot_df.apply(\n",
    "                lambda row: path_daily_weighted.get((int(row['month']), int(row['day'])), np.nan),\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day']).reset_index(drop=True)\n",
    "        pivot_df['date_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d}\",\n",
    "            axis=1\n",
    "        )\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns - only include years that were in overlap\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int) and col in overlap_years])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['date_label', 'month', 'day'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   ✓ Created timeseries with {len(year_cols)} historical years ({self.pipeline_name_short} overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_monthly_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create monthly GENERATION-WEIGHTED price timeseries with COMPRESSED values\n",
    "        \"\"\"\n",
    "        print(f\"\\n📊 Creating MONTHLY generation-weighted {self.pipeline_name} price timeseries...\")\n",
    "        \n",
    "        # Calculate weighted monthly prices\n",
    "        def calc_weighted_price(group):\n",
    "            mask = group['generation_mw'] > 0\n",
    "            if mask.sum() == 0:\n",
    "                return np.nan\n",
    "            gen_positive = group.loc[mask]\n",
    "            price_col = f'{self.price_column}_compressed'\n",
    "            return (gen_positive[price_col] * gen_positive['generation_mw']).sum() / gen_positive['generation_mw'].sum()\n",
    "        \n",
    "        df_monthly = df_filtered.groupby(['year', 'month']).apply(calc_weighted_price).reset_index()\n",
    "        df_monthly.columns = ['year', 'month', f'weighted_{self.price_column}']\n",
    "        df_monthly['month_order'] = df_monthly['month'].map(month_order_map)\n",
    "        \n",
    "        # Create pivot\n",
    "        pivot_df = df_monthly.pivot_table(\n",
    "            index=['month', 'month_order'],\n",
    "            columns='year',\n",
    "            values=f'weighted_{self.price_column}',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            path_monthly_weighted = path_filtered.groupby('month').apply(\n",
    "                lambda g: (g[f'{self.price_column}_compressed'] * g['generation_mw']).sum() / g['generation_mw'].sum() \n",
    "                if (g['generation_mw'] > 0).sum() > 0 else np.nan\n",
    "            )\n",
    "            \n",
    "            pivot_df[path_name] = pivot_df['month'].apply(\n",
    "                lambda month: path_monthly_weighted.get(int(month), np.nan)\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order']).reset_index(drop=True)\n",
    "        pivot_df['month_name'] = pivot_df['month'].apply(lambda x: self.month_names_full[int(x)])\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns - only include years that were in overlap\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int) and col in overlap_years])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['month_name', 'month'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   ✓ Created timeseries with {len(year_cols)} historical years ({self.pipeline_name_short} overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_historical_continuous_data(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create historical data in continuous format with ORIGINAL (uncompressed) values\n",
    "        \"\"\"\n",
    "        print(f\"\\n📜 Creating historical continuous data (original {self.pipeline_name} prices)...\")\n",
    "        \n",
    "        # Filter for month range and valid prices\n",
    "        df_filtered = self.filter_data_for_months(df, start_month, end_month)\n",
    "        df_filtered = df_filtered[df_filtered[self.price_column].notna()].copy()\n",
    "        \n",
    "        # Hourly historical (original values)\n",
    "        hourly_hist = df_filtered[['datetime', 'year', 'month', 'day', 'hour', self.price_column, 'generation_mw']].copy()\n",
    "        hourly_hist = hourly_hist.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        # Daily historical (generation-weighted, original values)\n",
    "        daily_hist = df_filtered.groupby(['year', 'month', 'day']).apply(\n",
    "            lambda g: pd.Series({\n",
    "                'weighted_price': (g[self.price_column] * g['generation_mw']).sum() / g['generation_mw'].sum() \n",
    "                                if (g['generation_mw'] > 0).sum() > 0 else np.nan,\n",
    "                'total_generation': g['generation_mw'].sum(),\n",
    "                'datetime': g['datetime'].iloc[0]\n",
    "            })\n",
    "        ).reset_index()\n",
    "        daily_hist['date'] = daily_hist['datetime'].dt.date\n",
    "        daily_hist = daily_hist[['date', 'year', 'month', 'day', 'weighted_price', 'total_generation']]\n",
    "        daily_hist = daily_hist.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        # Monthly historical (generation-weighted, original values)\n",
    "        monthly_hist = df_filtered.groupby(['year', 'month']).apply(\n",
    "            lambda g: pd.Series({\n",
    "                'weighted_price': (g[self.price_column] * g['generation_mw']).sum() / g['generation_mw'].sum() \n",
    "                                if (g['generation_mw'] > 0).sum() > 0 else np.nan,\n",
    "                'total_generation': g['generation_mw'].sum()\n",
    "            })\n",
    "        ).reset_index()\n",
    "        monthly_hist['month_year'] = monthly_hist.apply(\n",
    "            lambda row: f\"{row['year']}-{int(row['month']):02d}\", axis=1\n",
    "        )\n",
    "        monthly_hist = monthly_hist[['month_year', 'year', 'month', 'weighted_price', 'total_generation']]\n",
    "        monthly_hist = monthly_hist.sort_values(['year', 'month']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   ✓ Created historical data (original {self.pipeline_name} values):\")\n",
    "        print(f\"      - Hourly: {len(hourly_hist)} records\")\n",
    "        print(f\"      - Daily: {len(daily_hist)} records (generation-weighted)\")\n",
    "        print(f\"      - Monthly: {len(monthly_hist)} records (generation-weighted)\")\n",
    "        \n",
    "        return hourly_hist, daily_hist, monthly_hist\n",
    "    \n",
    "    def save_all_results(self, hourly_ts, daily_ts, monthly_ts,\n",
    "                        hourly_hist, daily_hist, monthly_hist, site_name):\n",
    "        \"\"\"\n",
    "        Save timeseries (compressed) and historical (original) files\n",
    "        \"\"\"\n",
    "        # Create folder structure with proper subfolder\n",
    "        price_path = self.base_output_path / site_name / self.output_folder\n",
    "        forecast_path = price_path / 'forecast'\n",
    "        timeseries_path = forecast_path / 'timeseries'\n",
    "        historical_path = price_path / 'historical'\n",
    "        \n",
    "        timeseries_path.mkdir(parents=True, exist_ok=True)\n",
    "        historical_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save timeseries files (COMPRESSED VALUES)\n",
    "        print(f\"\\n📈 Saving TIMESERIES files (compressed {self.pipeline_name} prices)...\")\n",
    "        \n",
    "        # Format and save timeseries files\n",
    "        for ts_df, ts_name, ts_file in [\n",
    "            (hourly_ts, \"hourly\", f\"{site_name}_{self.file_prefix}_hourly_timeseries.csv\"),\n",
    "            (daily_ts, \"daily\", f\"{site_name}_{self.file_prefix}_daily_timeseries.csv\"),\n",
    "            (monthly_ts, \"monthly\", f\"{site_name}_{self.file_prefix}_monthly_timeseries.csv\")\n",
    "        ]:\n",
    "            ts_save = ts_df.copy()\n",
    "            # Format numeric columns\n",
    "            numeric_cols = [col for col in ts_save.columns if isinstance(col, int) or (isinstance(col, str) and col.startswith('path_'))]\n",
    "            for col in numeric_cols:\n",
    "                ts_save[col] = ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "            ts_save.to_csv(timeseries_path / ts_file, index=False)\n",
    "            print(f\"   ✓ {ts_file}\")\n",
    "        \n",
    "        # Save historical files (ORIGINAL VALUES)\n",
    "        print(f\"\\n📜 Saving HISTORICAL files (original {self.pipeline_name} prices)...\")\n",
    "        \n",
    "        # Hourly historical\n",
    "        hourly_hist_file = f\"{site_name}_{self.file_prefix}_hourly_historical.csv\"\n",
    "        hourly_hist.to_csv(historical_path / hourly_hist_file, index=False, float_format='%.2f')\n",
    "        print(f\"   ✓ {hourly_hist_file}\")\n",
    "        \n",
    "        # Daily historical (weighted)\n",
    "        daily_hist_file = f\"{site_name}_{self.file_prefix}_daily_historical.csv\"\n",
    "        daily_hist.to_csv(historical_path / daily_hist_file, index=False, float_format='%.2f')\n",
    "        print(f\"   ✓ {daily_hist_file}\")\n",
    "        \n",
    "        # Monthly historical (weighted)\n",
    "        monthly_hist_file = f\"{site_name}_{self.file_prefix}_monthly_historical.csv\"\n",
    "        monthly_hist.to_csv(historical_path / monthly_hist_file, index=False, float_format='%.2f')\n",
    "        print(f\"   ✓ {monthly_hist_file}\")\n",
    "        \n",
    "        print(f\"\\n📁 All files saved in:\")\n",
    "        print(f\"   • Renewable Portfolio LLC/{site_name}/{self.output_folder}/forecast/timeseries/ (compressed)\")\n",
    "        print(f\"   • Renewable Portfolio LLC/{site_name}/{self.output_folder}/historical/ (original)\")\n",
    "        print(f\"\\n📌 Note: These files use {self.pipeline_name} bootstrap selections and compressed {self.pipeline_name_short} prices\")\n",
    "    \n",
    "    def process_single_site(self, site_name, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Process a single site with given month range\n",
    "        \"\"\"\n",
    "        # Load bootstrap selections for this site\n",
    "        if not self.load_bootstrap_selections(site_name):\n",
    "            return False\n",
    "        \n",
    "        # Create month order mapping\n",
    "        month_order_map = self.create_month_order_map(start_month, end_month)\n",
    "        \n",
    "        # Load and prepare data\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {site_name} ({self.pipeline_name} Price Pipeline)\")\n",
    "        \n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        num_months = len(months_in_range)\n",
    "        \n",
    "        if start_month <= end_month:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} ({num_months} months)\")\n",
    "        else:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} (year-wrapping, {num_months} months)\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Use the mapping to get the actual filename\n",
    "        actual_filename = self.site_file_map.get(site_name)\n",
    "        if actual_filename:\n",
    "            file_path = self.data_path / actual_filename\n",
    "        else:\n",
    "            # Fallback - try the standard naming convention\n",
    "            file_path = self.data_path / f\"{site_name}_generation_price_combined.csv\"\n",
    "            \n",
    "        print(f\"\\n📁 Loading data from: {file_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            \n",
    "            # Ensure numeric columns are integers\n",
    "            df['year'] = df['year'].astype(int)\n",
    "            df['month'] = df['month'].astype(int)\n",
    "            df['hour'] = df['hour'].astype(int)\n",
    "            df['day'] = df['datetime'].dt.day.astype(int)\n",
    "            \n",
    "            # Filter out rows where price is NaN\n",
    "            print(f\"\\n🔍 Filtering {self.pipeline_name} price data...\")\n",
    "            total_rows = len(df)\n",
    "            df_price_valid = df[df[self.price_column].notna()].copy()\n",
    "            rows_with_price = len(df_price_valid)\n",
    "            \n",
    "            print(f\"   Total rows: {total_rows:,}\")\n",
    "            print(f\"   Rows with valid {self.pipeline_name} prices: {rows_with_price:,}\")\n",
    "            \n",
    "            # Calculate compression parameters from ALL data (not just filtered months)\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"COMPRESSION PARAMETER CALCULATION ({self.pipeline_name})\")\n",
    "            print(\"-\"*40)\n",
    "            compression_params = self.calculate_compression_parameters(df_price_valid)\n",
    "            \n",
    "            # Apply compression to the full dataset\n",
    "            df_compressed = self.apply_compression_to_dataframe(df_price_valid, compression_params)\n",
    "            \n",
    "            # NOW filter for selected months\n",
    "            df_filtered = self.filter_data_for_months(df_compressed, start_month, end_month)\n",
    "            \n",
    "            # Data summary\n",
    "            years_available = sorted(df_filtered['year'].unique())\n",
    "            overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "            years_in_overlap = sorted([y for y in years_available if y in overlap_years])\n",
    "            \n",
    "            print(f\"\\n📊 Data summary ({self.pipeline_name} price data):\")\n",
    "            print(f\"   All years available: {years_available[0]} to {years_available[-1]} ({len(years_available)} years)\")\n",
    "            print(f\"   {self.pipeline_name_short} overlap years: {years_in_overlap[0]} to {years_in_overlap[-1]} ({len(years_in_overlap)} years)\")\n",
    "            print(f\"   Total data points: {len(df_filtered):,}\")\n",
    "            \n",
    "            # Generate synthetic paths using bootstrap selections\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"SYNTHETIC PATH GENERATION FROM {self.pipeline_name} BOOTSTRAP\")\n",
    "            print(\"-\"*40)\n",
    "            synthetic_paths = self.generate_synthetic_paths_from_bootstrap(df_compressed, compression_params)\n",
    "            \n",
    "            # Create timeseries with synthetic paths (COMPRESSED)\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"{self.pipeline_name} PRICE TIMESERIES (COMPRESSED)\")\n",
    "            print(\"-\"*40)\n",
    "            hourly_ts = self.create_hourly_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            daily_ts = self.create_daily_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            monthly_ts = self.create_monthly_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            \n",
    "            # Create historical continuous data (ORIGINAL VALUES)\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"HISTORICAL DATA PREPARATION (ORIGINAL {self.pipeline_name} VALUES)\")\n",
    "            print(\"-\"*40)\n",
    "            hourly_hist, daily_hist, monthly_hist = self.create_historical_continuous_data(df, start_month, end_month)\n",
    "            \n",
    "            # Save all results\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"SAVING RESULTS\")\n",
    "            print(\"-\"*40)\n",
    "            self.save_all_results(hourly_ts, daily_ts, monthly_ts,\n",
    "                                hourly_hist, daily_hist, monthly_hist,\n",
    "                                site_name)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Error processing {site_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    def run_preparation(self):\n",
    "        \"\"\"\n",
    "        Main function to run the price data preparation\n",
    "        \"\"\"\n",
    "        print(f\"\\n💰 {self.pipeline_name} Price Data Preparation - Phase 1b\")\n",
    "        print(f\"   (Using {self.pipeline_name} Bootstrap Selections)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get site selection\n",
    "        site_selection = self.get_site_selection()\n",
    "        if not site_selection:\n",
    "            return\n",
    "        \n",
    "        site_selection, sites_to_process = site_selection\n",
    "        \n",
    "        # Get automatic month range\n",
    "        start_month, end_month = self.get_automatic_month_range()\n",
    "        \n",
    "        # Process based on selection\n",
    "        if site_selection == 'ALL_SITES':\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"🚀 PROCESSING ALL SITES - {self.pipeline_name} Prices\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            for i, site_name in enumerate(sites_to_process, 1):\n",
    "                print(f\"\\n[{i}/{len(sites_to_process)}] Processing {site_name}...\")\n",
    "                \n",
    "                if self.process_single_site(site_name, start_month, end_month):\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"✨ PHASE 1b COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\n📊 Summary:\")\n",
    "            print(f\"   ✅ Successfully processed: {successful} sites\")\n",
    "            if failed > 0:\n",
    "                print(f\"   ❌ Failed: {failed} sites\")\n",
    "            \n",
    "            print(f\"\\n📁 Files saved:\")\n",
    "            print(f\"   • {self.output_folder}/forecast/timeseries/ - Compressed {self.pipeline_name} prices + synthetic paths\")\n",
    "            print(f\"   • {self.output_folder}/historical/ - Original {self.pipeline_name} price values\")\n",
    "            \n",
    "            if self.pipeline_type == 'da':\n",
    "                print(f\"\\n📌 Next step: Run Phase 1c for day-ahead revenue data preparation\")\n",
    "            else:\n",
    "                print(f\"\\n📌 Next step: Run Phase 1c for real-time revenue data preparation\")\n",
    "            \n",
    "        else:\n",
    "            # Process single site\n",
    "            if self.process_single_site(site_selection, start_month, end_month):\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"✨ PHASE 1b COMPLETE!\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\n{self.pipeline_name} Price data prepared for {site_selection}\")\n",
    "                print(f\"12-month period: {self.month_names[start_month]} to {self.month_names[end_month]}\")\n",
    "                print(f\"Synthetic paths: {self.n_synthetic_paths} (from {self.pipeline_name_short} bootstrap selections)\")\n",
    "                \n",
    "                print(f\"\\n📁 Files saved in:\")\n",
    "                print(f\"   • Renewable Portfolio LLC/{site_selection}/{self.output_folder}/forecast/timeseries/ (compressed)\")\n",
    "                print(f\"   • Renewable Portfolio LLC/{site_selection}/{self.output_folder}/historical/ (original)\")\n",
    "                \n",
    "                print(f\"\\n💡 Key features:\")\n",
    "                print(f\"   • Timeseries use compressed {self.pipeline_name} prices (P15-P85)\")\n",
    "                print(f\"   • Historical files preserve original {self.pipeline_name} price values\")\n",
    "                print(f\"   • Synthetic paths use same monthly blocks as generation ({self.pipeline_name_short} overlap)\")\n",
    "                print(f\"   • Daily/Monthly use generation-weighted prices\")\n",
    "                \n",
    "                if self.pipeline_type == 'da':\n",
    "                    print(f\"\\n📌 Next step: Run Phase 1c for day-ahead revenue calculation\")\n",
    "                else:\n",
    "                    print(f\"\\n📌 Next step: Run Phase 1c for real-time revenue calculation\")\n",
    "        \n",
    "        # Ask if user wants to prepare another site\n",
    "        another = input(f\"\\n🔄 Prepare {self.pipeline_name} price data for another site? (y/n): \").strip().lower()\n",
    "        if another == 'y':\n",
    "            self.run_preparation()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask user which pipeline to run\n",
    "    print(\"\\n💰 Price Data Preparation\")\n",
    "    print(\"Select pipeline type:\")\n",
    "    print(\"1. Day-Ahead (DA)\")\n",
    "    print(\"2. Real-Time (RT)\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
    "        if choice == '1':\n",
    "            prep = PriceDataPreparation(pipeline_type='da')\n",
    "            break\n",
    "        elif choice == '2':\n",
    "            prep = PriceDataPreparation(pipeline_type='rt')\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Invalid choice! Please enter 1 or 2.\")\n",
    "    \n",
    "    prep.run_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ae525",
   "metadata": {},
   "source": [
    "# Phase 1c: Unified revenue preparation (handles both DA and RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022146e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💰 Revenue Data Preparation\n",
      "Select pipeline type:\n",
      "1. Day-Ahead (DA)\n",
      "2. Real-Time (RT)\n",
      "\n",
      "💰 REAL-TIME Revenue Data Preparation - Phase 1c\n",
      "   (Calculate revenue from original data and apply compression)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "REAL-TIME REVENUE DATA PREPARATION - SITE SELECTION\n",
      "============================================================\n",
      "\n",
      "✅ Found REAL-TIME bootstrap selections for 7 sites\n",
      "\n",
      "Available options:\n",
      "0. ALL SITES (Process all sites with RT bootstrap selections)\n",
      "1. Albemarle_Beach_Solar\n",
      "2. Blue_Wing_Solar_Energy_Generator\n",
      "3. Lamesa_Solar\n",
      "4. Midway_Solar_Farm_III\n",
      "5. Misae_Solar\n",
      "6. Mount_Signal_Solar_Farm_II\n",
      "7. RE_Mustang_LLC\n",
      "============================================================\n",
      "\n",
      "📅 Auto-detected period: Jul to Jun (12 months)\n",
      "   Starting from current month: Jul\n",
      "\n",
      "============================================================\n",
      "🚀 PROCESSING ALL SITES - REAL-TIME Revenue\n",
      "============================================================\n",
      "\n",
      "[1/7] Processing Albemarle_Beach_Solar...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Albemarle_Beach_Solar_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2025 (14 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Albemarle_Beach_Solar (REAL-TIME Revenue Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Albemarle_Beach_Solar_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering data with valid generation AND REAL-TIME prices...\n",
      "   Total rows: 398,213\n",
      "   Rows with valid revenue data: 116,154\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME REVENUE...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME revenue data):\n",
      "   All years available: 2012 to 2025 (14 years)\n",
      "   RT overlap years: 2012 to 2025 (14 years)\n",
      "   Total data points: 116,154\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic revenue paths from REAL-TIME bootstrap...\n",
      "   Creating path_1 (RT revenue)... ✓\n",
      "   Creating path_2 (RT revenue)... ✓\n",
      "   Creating path_3 (RT revenue)... ✓\n",
      "   Creating path_4 (RT revenue)... ✓\n",
      "   Creating path_5 (RT revenue)... ✓\n",
      "   Creating path_6 (RT revenue)... ✓\n",
      "   Creating path_7 (RT revenue)... ✓\n",
      "   Creating path_8 (RT revenue)... ✓\n",
      "   Creating path_9 (RT revenue)... ✓\n",
      "   Creating path_10 (RT revenue)... ✓\n",
      "   Creating path_11 (RT revenue)... ✓\n",
      "   Creating path_12 (RT revenue)... ✓\n",
      "   Creating path_13 (RT revenue)... ✓\n",
      "   Creating path_14 (RT revenue)... ✓\n",
      "   Creating path_15 (RT revenue)... ✓\n",
      "   Creating path_16 (RT revenue)... ✓\n",
      "   Creating path_17 (RT revenue)... ✓\n",
      "   Creating path_18 (RT revenue)... ✓\n",
      "   Creating path_19 (RT revenue)... ✓\n",
      "   Creating path_20 (RT revenue)... ✓\n",
      "   Creating path_21 (RT revenue)... ✓\n",
      "   Creating path_22 (RT revenue)... ✓\n",
      "   Creating path_23 (RT revenue)... ✓\n",
      "   Creating path_24 (RT revenue)... ✓\n",
      "   Creating path_25 (RT revenue)... ✓\n",
      "   Creating path_26 (RT revenue)... ✓\n",
      "   Creating path_27 (RT revenue)... ✓\n",
      "   Creating path_28 (RT revenue)... ✓\n",
      "   Creating path_29 (RT revenue)... ✓\n",
      "   Creating path_30 (RT revenue)... ✓\n",
      "   Creating path_31 (RT revenue)... ✓\n",
      "   Creating path_32 (RT revenue)... ✓\n",
      "   Creating path_33 (RT revenue)... ✓\n",
      "   Creating path_34 (RT revenue)... ✓\n",
      "   Creating path_35 (RT revenue)... ✓\n",
      "   Creating path_36 (RT revenue)... ✓\n",
      "   Creating path_37 (RT revenue)... ✓\n",
      "   Creating path_38 (RT revenue)... ✓\n",
      "   Creating path_39 (RT revenue)... ✓\n",
      "   Creating path_40 (RT revenue)... ✓\n",
      "   Creating path_41 (RT revenue)... ✓\n",
      "   Creating path_42 (RT revenue)... ✓\n",
      "   Creating path_43 (RT revenue)... ✓\n",
      "   Creating path_44 (RT revenue)... ✓\n",
      "   Creating path_45 (RT revenue)... ✓\n",
      "   Creating path_46 (RT revenue)... ✓\n",
      "   Creating path_47 (RT revenue)... ✓\n",
      "   Creating path_48 (RT revenue)... ✓\n",
      "   Creating path_49 (RT revenue)... ✓\n",
      "   Creating path_50 (RT revenue)... ✓\n",
      "   Creating path_51 (RT revenue)... ✓\n",
      "   Creating path_52 (RT revenue)... ✓\n",
      "   Creating path_53 (RT revenue)... ✓\n",
      "   Creating path_54 (RT revenue)... ✓\n",
      "   Creating path_55 (RT revenue)... ✓\n",
      "   Creating path_56 (RT revenue)... ✓\n",
      "   Creating path_57 (RT revenue)... ✓\n",
      "   Creating path_58 (RT revenue)... ✓\n",
      "   Creating path_59 (RT revenue)... ✓\n",
      "   Creating path_60 (RT revenue)... ✓\n",
      "   Creating path_61 (RT revenue)... ✓\n",
      "   Creating path_62 (RT revenue)... ✓\n",
      "   Creating path_63 (RT revenue)... ✓\n",
      "   Creating path_64 (RT revenue)... ✓\n",
      "   Creating path_65 (RT revenue)... ✓\n",
      "   Creating path_66 (RT revenue)... ✓\n",
      "   Creating path_67 (RT revenue)... ✓\n",
      "   Creating path_68 (RT revenue)... ✓\n",
      "   Creating path_69 (RT revenue)... ✓\n",
      "   Creating path_70 (RT revenue)... ✓\n",
      "   Creating path_71 (RT revenue)... ✓\n",
      "   Creating path_72 (RT revenue)... ✓\n",
      "   Creating path_73 (RT revenue)... ✓\n",
      "   Creating path_74 (RT revenue)... ✓\n",
      "   Creating path_75 (RT revenue)... ✓\n",
      "   Creating path_76 (RT revenue)... ✓\n",
      "   Creating path_77 (RT revenue)... ✓\n",
      "   Creating path_78 (RT revenue)... ✓\n",
      "   Creating path_79 (RT revenue)... ✓\n",
      "   Creating path_80 (RT revenue)... ✓\n",
      "   Creating path_81 (RT revenue)... ✓\n",
      "   Creating path_82 (RT revenue)... ✓\n",
      "   Creating path_83 (RT revenue)... ✓\n",
      "   Creating path_84 (RT revenue)... ✓\n",
      "   Creating path_85 (RT revenue)... ✓\n",
      "   Creating path_86 (RT revenue)... ✓\n",
      "   Creating path_87 (RT revenue)... ✓\n",
      "   Creating path_88 (RT revenue)... ✓\n",
      "   Creating path_89 (RT revenue)... ✓\n",
      "   Creating path_90 (RT revenue)... ✓\n",
      "   Creating path_91 (RT revenue)... ✓\n",
      "   Creating path_92 (RT revenue)... ✓\n",
      "   Creating path_93 (RT revenue)... ✓\n",
      "   Creating path_94 (RT revenue)... ✓\n",
      "   Creating path_95 (RT revenue)... ✓\n",
      "   Creating path_96 (RT revenue)... ✓\n",
      "   Creating path_97 (RT revenue)... ✓\n",
      "   Creating path_98 (RT revenue)... ✓\n",
      "   Creating path_99 (RT revenue)... ✓\n",
      "   Creating path_100 (RT revenue)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME revenue paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME REVENUE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME revenue timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 14 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 14 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 14 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME revenue)...\n",
      "   ✓ Created historical data (original REAL-TIME revenue):\n",
      "      - Hourly: 116154 records\n",
      "      - Daily: 4840 records\n",
      "      - Monthly: 159 records\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME revenue)...\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_hourly_timeseries.csv\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_daily_timeseries.csv\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME revenue)...\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_hourly_historical.csv\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_daily_historical.csv\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Revenue_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Revenue_rt/historical/ (original)\n",
      "\n",
      "📌 Note: Revenue calculated from original data, then compressed for forecast\n",
      "\n",
      "[2/7] Processing Blue_Wing_Solar_Energy_Generator...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Blue_Wing_Solar_Energy_Generator_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Blue_Wing_Solar_Energy_Generator (REAL-TIME Revenue Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Blue_Wing_Solar_Energy_Generator_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering data with valid generation AND REAL-TIME prices...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid revenue data: 112,261\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME REVENUE...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME revenue data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,261\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic revenue paths from REAL-TIME bootstrap...\n",
      "   Creating path_1 (RT revenue)... ✓\n",
      "   Creating path_2 (RT revenue)... ✓\n",
      "   Creating path_3 (RT revenue)... ✓\n",
      "   Creating path_4 (RT revenue)... ✓\n",
      "   Creating path_5 (RT revenue)... ✓\n",
      "   Creating path_6 (RT revenue)... ✓\n",
      "   Creating path_7 (RT revenue)... ✓\n",
      "   Creating path_8 (RT revenue)... ✓\n",
      "   Creating path_9 (RT revenue)... ✓\n",
      "   Creating path_10 (RT revenue)... ✓\n",
      "   Creating path_11 (RT revenue)... ✓\n",
      "   Creating path_12 (RT revenue)... ✓\n",
      "   Creating path_13 (RT revenue)... ✓\n",
      "   Creating path_14 (RT revenue)... ✓\n",
      "   Creating path_15 (RT revenue)... ✓\n",
      "   Creating path_16 (RT revenue)... ✓\n",
      "   Creating path_17 (RT revenue)... ✓\n",
      "   Creating path_18 (RT revenue)... ✓\n",
      "   Creating path_19 (RT revenue)... ✓\n",
      "   Creating path_20 (RT revenue)... ✓\n",
      "   Creating path_21 (RT revenue)... ✓\n",
      "   Creating path_22 (RT revenue)... ✓\n",
      "   Creating path_23 (RT revenue)... ✓\n",
      "   Creating path_24 (RT revenue)... ✓\n",
      "   Creating path_25 (RT revenue)... ✓\n",
      "   Creating path_26 (RT revenue)... ✓\n",
      "   Creating path_27 (RT revenue)... ✓\n",
      "   Creating path_28 (RT revenue)... ✓\n",
      "   Creating path_29 (RT revenue)... ✓\n",
      "   Creating path_30 (RT revenue)... ✓\n",
      "   Creating path_31 (RT revenue)... ✓\n",
      "   Creating path_32 (RT revenue)... ✓\n",
      "   Creating path_33 (RT revenue)... ✓\n",
      "   Creating path_34 (RT revenue)... ✓\n",
      "   Creating path_35 (RT revenue)... ✓\n",
      "   Creating path_36 (RT revenue)... ✓\n",
      "   Creating path_37 (RT revenue)... ✓\n",
      "   Creating path_38 (RT revenue)... ✓\n",
      "   Creating path_39 (RT revenue)... ✓\n",
      "   Creating path_40 (RT revenue)... ✓\n",
      "   Creating path_41 (RT revenue)... ✓\n",
      "   Creating path_42 (RT revenue)... ✓\n",
      "   Creating path_43 (RT revenue)... ✓\n",
      "   Creating path_44 (RT revenue)... ✓\n",
      "   Creating path_45 (RT revenue)... ✓\n",
      "   Creating path_46 (RT revenue)... ✓\n",
      "   Creating path_47 (RT revenue)... ✓\n",
      "   Creating path_48 (RT revenue)... ✓\n",
      "   Creating path_49 (RT revenue)... ✓\n",
      "   Creating path_50 (RT revenue)... ✓\n",
      "   Creating path_51 (RT revenue)... ✓\n",
      "   Creating path_52 (RT revenue)... ✓\n",
      "   Creating path_53 (RT revenue)... ✓\n",
      "   Creating path_54 (RT revenue)... ✓\n",
      "   Creating path_55 (RT revenue)... ✓\n",
      "   Creating path_56 (RT revenue)... ✓\n",
      "   Creating path_57 (RT revenue)... ✓\n",
      "   Creating path_58 (RT revenue)... ✓\n",
      "   Creating path_59 (RT revenue)... ✓\n",
      "   Creating path_60 (RT revenue)... ✓\n",
      "   Creating path_61 (RT revenue)... ✓\n",
      "   Creating path_62 (RT revenue)... ✓\n",
      "   Creating path_63 (RT revenue)... ✓\n",
      "   Creating path_64 (RT revenue)... ✓\n",
      "   Creating path_65 (RT revenue)... ✓\n",
      "   Creating path_66 (RT revenue)... ✓\n",
      "   Creating path_67 (RT revenue)... ✓\n",
      "   Creating path_68 (RT revenue)... ✓\n",
      "   Creating path_69 (RT revenue)... ✓\n",
      "   Creating path_70 (RT revenue)... ✓\n",
      "   Creating path_71 (RT revenue)... ✓\n",
      "   Creating path_72 (RT revenue)... ✓\n",
      "   Creating path_73 (RT revenue)... ✓\n",
      "   Creating path_74 (RT revenue)... ✓\n",
      "   Creating path_75 (RT revenue)... ✓\n",
      "   Creating path_76 (RT revenue)... ✓\n",
      "   Creating path_77 (RT revenue)... ✓\n",
      "   Creating path_78 (RT revenue)... ✓\n",
      "   Creating path_79 (RT revenue)... ✓\n",
      "   Creating path_80 (RT revenue)... ✓\n",
      "   Creating path_81 (RT revenue)... ✓\n",
      "   Creating path_82 (RT revenue)... ✓\n",
      "   Creating path_83 (RT revenue)... ✓\n",
      "   Creating path_84 (RT revenue)... ✓\n",
      "   Creating path_85 (RT revenue)... ✓\n",
      "   Creating path_86 (RT revenue)... ✓\n",
      "   Creating path_87 (RT revenue)... ✓\n",
      "   Creating path_88 (RT revenue)... ✓\n",
      "   Creating path_89 (RT revenue)... ✓\n",
      "   Creating path_90 (RT revenue)... ✓\n",
      "   Creating path_91 (RT revenue)... ✓\n",
      "   Creating path_92 (RT revenue)... ✓\n",
      "   Creating path_93 (RT revenue)... ✓\n",
      "   Creating path_94 (RT revenue)... ✓\n",
      "   Creating path_95 (RT revenue)... ✓\n",
      "   Creating path_96 (RT revenue)... ✓\n",
      "   Creating path_97 (RT revenue)... ✓\n",
      "   Creating path_98 (RT revenue)... ✓\n",
      "   Creating path_99 (RT revenue)... ✓\n",
      "   Creating path_100 (RT revenue)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME revenue paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME REVENUE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME revenue timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME revenue)...\n",
      "   ✓ Created historical data (original REAL-TIME revenue):\n",
      "      - Hourly: 112261 records\n",
      "      - Daily: 4685 records\n",
      "      - Monthly: 154 records\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME revenue)...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_hourly_timeseries.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_daily_timeseries.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME revenue)...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_hourly_historical.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_daily_historical.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Revenue_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Revenue_rt/historical/ (original)\n",
      "\n",
      "📌 Note: Revenue calculated from original data, then compressed for forecast\n",
      "\n",
      "[3/7] Processing Lamesa_Solar...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Lamesa_Solar_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2016-2025 (10 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Lamesa_Solar (REAL-TIME Revenue Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Lamesa_Solar_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering data with valid generation AND REAL-TIME prices...\n",
      "   Total rows: 398,209\n",
      "   Rows with valid revenue data: 82,244\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME REVENUE...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME revenue data):\n",
      "   All years available: 2016 to 2025 (10 years)\n",
      "   RT overlap years: 2016 to 2025 (10 years)\n",
      "   Total data points: 82,244\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic revenue paths from REAL-TIME bootstrap...\n",
      "   Creating path_1 (RT revenue)... ✓\n",
      "   Creating path_2 (RT revenue)... ✓\n",
      "   Creating path_3 (RT revenue)... ✓\n",
      "   Creating path_4 (RT revenue)... ✓\n",
      "   Creating path_5 (RT revenue)... ✓\n",
      "   Creating path_6 (RT revenue)... ✓\n",
      "   Creating path_7 (RT revenue)... ✓\n",
      "   Creating path_8 (RT revenue)... ✓\n",
      "   Creating path_9 (RT revenue)... ✓\n",
      "   Creating path_10 (RT revenue)... ✓\n",
      "   Creating path_11 (RT revenue)... ✓\n",
      "   Creating path_12 (RT revenue)... ✓\n",
      "   Creating path_13 (RT revenue)... ✓\n",
      "   Creating path_14 (RT revenue)... ✓\n",
      "   Creating path_15 (RT revenue)... ✓\n",
      "   Creating path_16 (RT revenue)... ✓\n",
      "   Creating path_17 (RT revenue)... ✓\n",
      "   Creating path_18 (RT revenue)... ✓\n",
      "   Creating path_19 (RT revenue)... ✓\n",
      "   Creating path_20 (RT revenue)... ✓\n",
      "   Creating path_21 (RT revenue)... ✓\n",
      "   Creating path_22 (RT revenue)... ✓\n",
      "   Creating path_23 (RT revenue)... ✓\n",
      "   Creating path_24 (RT revenue)... ✓\n",
      "   Creating path_25 (RT revenue)... ✓\n",
      "   Creating path_26 (RT revenue)... ✓\n",
      "   Creating path_27 (RT revenue)... ✓\n",
      "   Creating path_28 (RT revenue)... ✓\n",
      "   Creating path_29 (RT revenue)... ✓\n",
      "   Creating path_30 (RT revenue)... ✓\n",
      "   Creating path_31 (RT revenue)... ✓\n",
      "   Creating path_32 (RT revenue)... ✓\n",
      "   Creating path_33 (RT revenue)... ✓\n",
      "   Creating path_34 (RT revenue)... ✓\n",
      "   Creating path_35 (RT revenue)... ✓\n",
      "   Creating path_36 (RT revenue)... ✓\n",
      "   Creating path_37 (RT revenue)... ✓\n",
      "   Creating path_38 (RT revenue)... ✓\n",
      "   Creating path_39 (RT revenue)... ✓\n",
      "   Creating path_40 (RT revenue)... ✓\n",
      "   Creating path_41 (RT revenue)... ✓\n",
      "   Creating path_42 (RT revenue)... ✓\n",
      "   Creating path_43 (RT revenue)... ✓\n",
      "   Creating path_44 (RT revenue)... ✓\n",
      "   Creating path_45 (RT revenue)... ✓\n",
      "   Creating path_46 (RT revenue)... ✓\n",
      "   Creating path_47 (RT revenue)... ✓\n",
      "   Creating path_48 (RT revenue)... ✓\n",
      "   Creating path_49 (RT revenue)... ✓\n",
      "   Creating path_50 (RT revenue)... ✓\n",
      "   Creating path_51 (RT revenue)... ✓\n",
      "   Creating path_52 (RT revenue)... ✓\n",
      "   Creating path_53 (RT revenue)... ✓\n",
      "   Creating path_54 (RT revenue)... ✓\n",
      "   Creating path_55 (RT revenue)... ✓\n",
      "   Creating path_56 (RT revenue)... ✓\n",
      "   Creating path_57 (RT revenue)... ✓\n",
      "   Creating path_58 (RT revenue)... ✓\n",
      "   Creating path_59 (RT revenue)... ✓\n",
      "   Creating path_60 (RT revenue)... ✓\n",
      "   Creating path_61 (RT revenue)... ✓\n",
      "   Creating path_62 (RT revenue)... ✓\n",
      "   Creating path_63 (RT revenue)... ✓\n",
      "   Creating path_64 (RT revenue)... ✓\n",
      "   Creating path_65 (RT revenue)... ✓\n",
      "   Creating path_66 (RT revenue)... ✓\n",
      "   Creating path_67 (RT revenue)... ✓\n",
      "   Creating path_68 (RT revenue)... ✓\n",
      "   Creating path_69 (RT revenue)... ✓\n",
      "   Creating path_70 (RT revenue)... ✓\n",
      "   Creating path_71 (RT revenue)... ✓\n",
      "   Creating path_72 (RT revenue)... ✓\n",
      "   Creating path_73 (RT revenue)... ✓\n",
      "   Creating path_74 (RT revenue)... ✓\n",
      "   Creating path_75 (RT revenue)... ✓\n",
      "   Creating path_76 (RT revenue)... ✓\n",
      "   Creating path_77 (RT revenue)... ✓\n",
      "   Creating path_78 (RT revenue)... ✓\n",
      "   Creating path_79 (RT revenue)... ✓\n",
      "   Creating path_80 (RT revenue)... ✓\n",
      "   Creating path_81 (RT revenue)... ✓\n",
      "   Creating path_82 (RT revenue)... ✓\n",
      "   Creating path_83 (RT revenue)... ✓\n",
      "   Creating path_84 (RT revenue)... ✓\n",
      "   Creating path_85 (RT revenue)... ✓\n",
      "   Creating path_86 (RT revenue)... ✓\n",
      "   Creating path_87 (RT revenue)... ✓\n",
      "   Creating path_88 (RT revenue)... ✓\n",
      "   Creating path_89 (RT revenue)... ✓\n",
      "   Creating path_90 (RT revenue)... ✓\n",
      "   Creating path_91 (RT revenue)... ✓\n",
      "   Creating path_92 (RT revenue)... ✓\n",
      "   Creating path_93 (RT revenue)... ✓\n",
      "   Creating path_94 (RT revenue)... ✓\n",
      "   Creating path_95 (RT revenue)... ✓\n",
      "   Creating path_96 (RT revenue)... ✓\n",
      "   Creating path_97 (RT revenue)... ✓\n",
      "   Creating path_98 (RT revenue)... ✓\n",
      "   Creating path_99 (RT revenue)... ✓\n",
      "   Creating path_100 (RT revenue)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME revenue paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME REVENUE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME revenue timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 10 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 10 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 10 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME revenue)...\n",
      "   ✓ Created historical data (original REAL-TIME revenue):\n",
      "      - Hourly: 82244 records\n",
      "      - Daily: 3435 records\n",
      "      - Monthly: 113 records\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME revenue)...\n",
      "   ✓ Lamesa_Solar_revenue_rt_hourly_timeseries.csv\n",
      "   ✓ Lamesa_Solar_revenue_rt_daily_timeseries.csv\n",
      "   ✓ Lamesa_Solar_revenue_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME revenue)...\n",
      "   ✓ Lamesa_Solar_revenue_rt_hourly_historical.csv\n",
      "   ✓ Lamesa_Solar_revenue_rt_daily_historical.csv\n",
      "   ✓ Lamesa_Solar_revenue_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Revenue_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Revenue_rt/historical/ (original)\n",
      "\n",
      "📌 Note: Revenue calculated from original data, then compressed for forecast\n",
      "\n",
      "[4/7] Processing Midway_Solar_Farm_III...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Midway_Solar_Farm_III_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Midway_Solar_Farm_III (REAL-TIME Revenue Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Midway_Solar_Farm_III_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering data with valid generation AND REAL-TIME prices...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid revenue data: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME REVENUE...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME revenue data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic revenue paths from REAL-TIME bootstrap...\n",
      "   Creating path_1 (RT revenue)... ✓\n",
      "   Creating path_2 (RT revenue)... ✓\n",
      "   Creating path_3 (RT revenue)... ✓\n",
      "   Creating path_4 (RT revenue)... ✓\n",
      "   Creating path_5 (RT revenue)... ✓\n",
      "   Creating path_6 (RT revenue)... ✓\n",
      "   Creating path_7 (RT revenue)... ✓\n",
      "   Creating path_8 (RT revenue)... ✓\n",
      "   Creating path_9 (RT revenue)... ✓\n",
      "   Creating path_10 (RT revenue)... ✓\n",
      "   Creating path_11 (RT revenue)... ✓\n",
      "   Creating path_12 (RT revenue)... ✓\n",
      "   Creating path_13 (RT revenue)... ✓\n",
      "   Creating path_14 (RT revenue)... ✓\n",
      "   Creating path_15 (RT revenue)... ✓\n",
      "   Creating path_16 (RT revenue)... ✓\n",
      "   Creating path_17 (RT revenue)... ✓\n",
      "   Creating path_18 (RT revenue)... ✓\n",
      "   Creating path_19 (RT revenue)... ✓\n",
      "   Creating path_20 (RT revenue)... ✓\n",
      "   Creating path_21 (RT revenue)... ✓\n",
      "   Creating path_22 (RT revenue)... ✓\n",
      "   Creating path_23 (RT revenue)... ✓\n",
      "   Creating path_24 (RT revenue)... ✓\n",
      "   Creating path_25 (RT revenue)... ✓\n",
      "   Creating path_26 (RT revenue)... ✓\n",
      "   Creating path_27 (RT revenue)... ✓\n",
      "   Creating path_28 (RT revenue)... ✓\n",
      "   Creating path_29 (RT revenue)... ✓\n",
      "   Creating path_30 (RT revenue)... ✓\n",
      "   Creating path_31 (RT revenue)... ✓\n",
      "   Creating path_32 (RT revenue)... ✓\n",
      "   Creating path_33 (RT revenue)... ✓\n",
      "   Creating path_34 (RT revenue)... ✓\n",
      "   Creating path_35 (RT revenue)... ✓\n",
      "   Creating path_36 (RT revenue)... ✓\n",
      "   Creating path_37 (RT revenue)... ✓\n",
      "   Creating path_38 (RT revenue)... ✓\n",
      "   Creating path_39 (RT revenue)... ✓\n",
      "   Creating path_40 (RT revenue)... ✓\n",
      "   Creating path_41 (RT revenue)... ✓\n",
      "   Creating path_42 (RT revenue)... ✓\n",
      "   Creating path_43 (RT revenue)... ✓\n",
      "   Creating path_44 (RT revenue)... ✓\n",
      "   Creating path_45 (RT revenue)... ✓\n",
      "   Creating path_46 (RT revenue)... ✓\n",
      "   Creating path_47 (RT revenue)... ✓\n",
      "   Creating path_48 (RT revenue)... ✓\n",
      "   Creating path_49 (RT revenue)... ✓\n",
      "   Creating path_50 (RT revenue)... ✓\n",
      "   Creating path_51 (RT revenue)... ✓\n",
      "   Creating path_52 (RT revenue)... ✓\n",
      "   Creating path_53 (RT revenue)... ✓\n",
      "   Creating path_54 (RT revenue)... ✓\n",
      "   Creating path_55 (RT revenue)... ✓\n",
      "   Creating path_56 (RT revenue)... ✓\n",
      "   Creating path_57 (RT revenue)... ✓\n",
      "   Creating path_58 (RT revenue)... ✓\n",
      "   Creating path_59 (RT revenue)... ✓\n",
      "   Creating path_60 (RT revenue)... ✓\n",
      "   Creating path_61 (RT revenue)... ✓\n",
      "   Creating path_62 (RT revenue)... ✓\n",
      "   Creating path_63 (RT revenue)... ✓\n",
      "   Creating path_64 (RT revenue)... ✓\n",
      "   Creating path_65 (RT revenue)... ✓\n",
      "   Creating path_66 (RT revenue)... ✓\n",
      "   Creating path_67 (RT revenue)... ✓\n",
      "   Creating path_68 (RT revenue)... ✓\n",
      "   Creating path_69 (RT revenue)... ✓\n",
      "   Creating path_70 (RT revenue)... ✓\n",
      "   Creating path_71 (RT revenue)... ✓\n",
      "   Creating path_72 (RT revenue)... ✓\n",
      "   Creating path_73 (RT revenue)... ✓\n",
      "   Creating path_74 (RT revenue)... ✓\n",
      "   Creating path_75 (RT revenue)... ✓\n",
      "   Creating path_76 (RT revenue)... ✓\n",
      "   Creating path_77 (RT revenue)... ✓\n",
      "   Creating path_78 (RT revenue)... ✓\n",
      "   Creating path_79 (RT revenue)... ✓\n",
      "   Creating path_80 (RT revenue)... ✓\n",
      "   Creating path_81 (RT revenue)... ✓\n",
      "   Creating path_82 (RT revenue)... ✓\n",
      "   Creating path_83 (RT revenue)... ✓\n",
      "   Creating path_84 (RT revenue)... ✓\n",
      "   Creating path_85 (RT revenue)... ✓\n",
      "   Creating path_86 (RT revenue)... ✓\n",
      "   Creating path_87 (RT revenue)... ✓\n",
      "   Creating path_88 (RT revenue)... ✓\n",
      "   Creating path_89 (RT revenue)... ✓\n",
      "   Creating path_90 (RT revenue)... ✓\n",
      "   Creating path_91 (RT revenue)... ✓\n",
      "   Creating path_92 (RT revenue)... ✓\n",
      "   Creating path_93 (RT revenue)... ✓\n",
      "   Creating path_94 (RT revenue)... ✓\n",
      "   Creating path_95 (RT revenue)... ✓\n",
      "   Creating path_96 (RT revenue)... ✓\n",
      "   Creating path_97 (RT revenue)... ✓\n",
      "   Creating path_98 (RT revenue)... ✓\n",
      "   Creating path_99 (RT revenue)... ✓\n",
      "   Creating path_100 (RT revenue)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME revenue paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME REVENUE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME revenue timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME revenue)...\n",
      "   ✓ Created historical data (original REAL-TIME revenue):\n",
      "      - Hourly: 112546 records\n",
      "      - Daily: 4689 records\n",
      "      - Monthly: 154 records\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME revenue)...\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_hourly_timeseries.csv\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_daily_timeseries.csv\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME revenue)...\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_hourly_historical.csv\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_daily_historical.csv\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Revenue_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Revenue_rt/historical/ (original)\n",
      "\n",
      "📌 Note: Revenue calculated from original data, then compressed for forecast\n",
      "\n",
      "[5/7] Processing Misae_Solar...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Misae_Solar_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Misae_Solar (REAL-TIME Revenue Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Misae_Solar_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering data with valid generation AND REAL-TIME prices...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid revenue data: 112,244\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME REVENUE...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME revenue data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,244\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic revenue paths from REAL-TIME bootstrap...\n",
      "   Creating path_1 (RT revenue)... ✓\n",
      "   Creating path_2 (RT revenue)... ✓\n",
      "   Creating path_3 (RT revenue)... ✓\n",
      "   Creating path_4 (RT revenue)... ✓\n",
      "   Creating path_5 (RT revenue)... ✓\n",
      "   Creating path_6 (RT revenue)... ✓\n",
      "   Creating path_7 (RT revenue)... ✓\n",
      "   Creating path_8 (RT revenue)... ✓\n",
      "   Creating path_9 (RT revenue)... ✓\n",
      "   Creating path_10 (RT revenue)... ✓\n",
      "   Creating path_11 (RT revenue)... ✓\n",
      "   Creating path_12 (RT revenue)... ✓\n",
      "   Creating path_13 (RT revenue)... ✓\n",
      "   Creating path_14 (RT revenue)... ✓\n",
      "   Creating path_15 (RT revenue)... ✓\n",
      "   Creating path_16 (RT revenue)... ✓\n",
      "   Creating path_17 (RT revenue)... ✓\n",
      "   Creating path_18 (RT revenue)... ✓\n",
      "   Creating path_19 (RT revenue)... ✓\n",
      "   Creating path_20 (RT revenue)... ✓\n",
      "   Creating path_21 (RT revenue)... ✓\n",
      "   Creating path_22 (RT revenue)... ✓\n",
      "   Creating path_23 (RT revenue)... ✓\n",
      "   Creating path_24 (RT revenue)... ✓\n",
      "   Creating path_25 (RT revenue)... ✓\n",
      "   Creating path_26 (RT revenue)... ✓\n",
      "   Creating path_27 (RT revenue)... ✓\n",
      "   Creating path_28 (RT revenue)... ✓\n",
      "   Creating path_29 (RT revenue)... ✓\n",
      "   Creating path_30 (RT revenue)... ✓\n",
      "   Creating path_31 (RT revenue)... ✓\n",
      "   Creating path_32 (RT revenue)... ✓\n",
      "   Creating path_33 (RT revenue)... ✓\n",
      "   Creating path_34 (RT revenue)... ✓\n",
      "   Creating path_35 (RT revenue)... ✓\n",
      "   Creating path_36 (RT revenue)... ✓\n",
      "   Creating path_37 (RT revenue)... ✓\n",
      "   Creating path_38 (RT revenue)... ✓\n",
      "   Creating path_39 (RT revenue)... ✓\n",
      "   Creating path_40 (RT revenue)... ✓\n",
      "   Creating path_41 (RT revenue)... ✓\n",
      "   Creating path_42 (RT revenue)... ✓\n",
      "   Creating path_43 (RT revenue)... ✓\n",
      "   Creating path_44 (RT revenue)... ✓\n",
      "   Creating path_45 (RT revenue)... ✓\n",
      "   Creating path_46 (RT revenue)... ✓\n",
      "   Creating path_47 (RT revenue)... ✓\n",
      "   Creating path_48 (RT revenue)... ✓\n",
      "   Creating path_49 (RT revenue)... ✓\n",
      "   Creating path_50 (RT revenue)... ✓\n",
      "   Creating path_51 (RT revenue)... ✓\n",
      "   Creating path_52 (RT revenue)... ✓\n",
      "   Creating path_53 (RT revenue)... ✓\n",
      "   Creating path_54 (RT revenue)... ✓\n",
      "   Creating path_55 (RT revenue)... ✓\n",
      "   Creating path_56 (RT revenue)... ✓\n",
      "   Creating path_57 (RT revenue)... ✓\n",
      "   Creating path_58 (RT revenue)... ✓\n",
      "   Creating path_59 (RT revenue)... ✓\n",
      "   Creating path_60 (RT revenue)... ✓\n",
      "   Creating path_61 (RT revenue)... ✓\n",
      "   Creating path_62 (RT revenue)... ✓\n",
      "   Creating path_63 (RT revenue)... ✓\n",
      "   Creating path_64 (RT revenue)... ✓\n",
      "   Creating path_65 (RT revenue)... ✓\n",
      "   Creating path_66 (RT revenue)... ✓\n",
      "   Creating path_67 (RT revenue)... ✓\n",
      "   Creating path_68 (RT revenue)... ✓\n",
      "   Creating path_69 (RT revenue)... ✓\n",
      "   Creating path_70 (RT revenue)... ✓\n",
      "   Creating path_71 (RT revenue)... ✓\n",
      "   Creating path_72 (RT revenue)... ✓\n",
      "   Creating path_73 (RT revenue)... ✓\n",
      "   Creating path_74 (RT revenue)... ✓\n",
      "   Creating path_75 (RT revenue)... ✓\n",
      "   Creating path_76 (RT revenue)... ✓\n",
      "   Creating path_77 (RT revenue)... ✓\n",
      "   Creating path_78 (RT revenue)... ✓\n",
      "   Creating path_79 (RT revenue)... ✓\n",
      "   Creating path_80 (RT revenue)... ✓\n",
      "   Creating path_81 (RT revenue)... ✓\n",
      "   Creating path_82 (RT revenue)... ✓\n",
      "   Creating path_83 (RT revenue)... ✓\n",
      "   Creating path_84 (RT revenue)... ✓\n",
      "   Creating path_85 (RT revenue)... ✓\n",
      "   Creating path_86 (RT revenue)... ✓\n",
      "   Creating path_87 (RT revenue)... ✓\n",
      "   Creating path_88 (RT revenue)... ✓\n",
      "   Creating path_89 (RT revenue)... ✓\n",
      "   Creating path_90 (RT revenue)... ✓\n",
      "   Creating path_91 (RT revenue)... ✓\n",
      "   Creating path_92 (RT revenue)... ✓\n",
      "   Creating path_93 (RT revenue)... ✓\n",
      "   Creating path_94 (RT revenue)... ✓\n",
      "   Creating path_95 (RT revenue)... ✓\n",
      "   Creating path_96 (RT revenue)... ✓\n",
      "   Creating path_97 (RT revenue)... ✓\n",
      "   Creating path_98 (RT revenue)... ✓\n",
      "   Creating path_99 (RT revenue)... ✓\n",
      "   Creating path_100 (RT revenue)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME revenue paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME REVENUE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME revenue timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME revenue)...\n",
      "   ✓ Created historical data (original REAL-TIME revenue):\n",
      "      - Hourly: 112244 records\n",
      "      - Daily: 4685 records\n",
      "      - Monthly: 154 records\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME revenue)...\n",
      "   ✓ Misae_Solar_revenue_rt_hourly_timeseries.csv\n",
      "   ✓ Misae_Solar_revenue_rt_daily_timeseries.csv\n",
      "   ✓ Misae_Solar_revenue_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME revenue)...\n",
      "   ✓ Misae_Solar_revenue_rt_hourly_historical.csv\n",
      "   ✓ Misae_Solar_revenue_rt_daily_historical.csv\n",
      "   ✓ Misae_Solar_revenue_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Revenue_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Revenue_rt/historical/ (original)\n",
      "\n",
      "📌 Note: Revenue calculated from original data, then compressed for forecast\n",
      "\n",
      "[6/7] Processing Mount_Signal_Solar_Farm_II...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: Mount_Signal_Solar_Farm_II_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: Mount_Signal_Solar_Farm_II (REAL-TIME Revenue Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: Mount_Signal_Solar_Farm_II_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering data with valid generation AND REAL-TIME prices...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid revenue data: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME REVENUE...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME revenue data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,546\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic revenue paths from REAL-TIME bootstrap...\n",
      "   Creating path_1 (RT revenue)... ✓\n",
      "   Creating path_2 (RT revenue)... ✓\n",
      "   Creating path_3 (RT revenue)... ✓\n",
      "   Creating path_4 (RT revenue)... ✓\n",
      "   Creating path_5 (RT revenue)... ✓\n",
      "   Creating path_6 (RT revenue)... ✓\n",
      "   Creating path_7 (RT revenue)... ✓\n",
      "   Creating path_8 (RT revenue)... ✓\n",
      "   Creating path_9 (RT revenue)... ✓\n",
      "   Creating path_10 (RT revenue)... ✓\n",
      "   Creating path_11 (RT revenue)... ✓\n",
      "   Creating path_12 (RT revenue)... ✓\n",
      "   Creating path_13 (RT revenue)... ✓\n",
      "   Creating path_14 (RT revenue)... ✓\n",
      "   Creating path_15 (RT revenue)... ✓\n",
      "   Creating path_16 (RT revenue)... ✓\n",
      "   Creating path_17 (RT revenue)... ✓\n",
      "   Creating path_18 (RT revenue)... ✓\n",
      "   Creating path_19 (RT revenue)... ✓\n",
      "   Creating path_20 (RT revenue)... ✓\n",
      "   Creating path_21 (RT revenue)... ✓\n",
      "   Creating path_22 (RT revenue)... ✓\n",
      "   Creating path_23 (RT revenue)... ✓\n",
      "   Creating path_24 (RT revenue)... ✓\n",
      "   Creating path_25 (RT revenue)... ✓\n",
      "   Creating path_26 (RT revenue)... ✓\n",
      "   Creating path_27 (RT revenue)... ✓\n",
      "   Creating path_28 (RT revenue)... ✓\n",
      "   Creating path_29 (RT revenue)... ✓\n",
      "   Creating path_30 (RT revenue)... ✓\n",
      "   Creating path_31 (RT revenue)... ✓\n",
      "   Creating path_32 (RT revenue)... ✓\n",
      "   Creating path_33 (RT revenue)... ✓\n",
      "   Creating path_34 (RT revenue)... ✓\n",
      "   Creating path_35 (RT revenue)... ✓\n",
      "   Creating path_36 (RT revenue)... ✓\n",
      "   Creating path_37 (RT revenue)... ✓\n",
      "   Creating path_38 (RT revenue)... ✓\n",
      "   Creating path_39 (RT revenue)... ✓\n",
      "   Creating path_40 (RT revenue)... ✓\n",
      "   Creating path_41 (RT revenue)... ✓\n",
      "   Creating path_42 (RT revenue)... ✓\n",
      "   Creating path_43 (RT revenue)... ✓\n",
      "   Creating path_44 (RT revenue)... ✓\n",
      "   Creating path_45 (RT revenue)... ✓\n",
      "   Creating path_46 (RT revenue)... ✓\n",
      "   Creating path_47 (RT revenue)... ✓\n",
      "   Creating path_48 (RT revenue)... ✓\n",
      "   Creating path_49 (RT revenue)... ✓\n",
      "   Creating path_50 (RT revenue)... ✓\n",
      "   Creating path_51 (RT revenue)... ✓\n",
      "   Creating path_52 (RT revenue)... ✓\n",
      "   Creating path_53 (RT revenue)... ✓\n",
      "   Creating path_54 (RT revenue)... ✓\n",
      "   Creating path_55 (RT revenue)... ✓\n",
      "   Creating path_56 (RT revenue)... ✓\n",
      "   Creating path_57 (RT revenue)... ✓\n",
      "   Creating path_58 (RT revenue)... ✓\n",
      "   Creating path_59 (RT revenue)... ✓\n",
      "   Creating path_60 (RT revenue)... ✓\n",
      "   Creating path_61 (RT revenue)... ✓\n",
      "   Creating path_62 (RT revenue)... ✓\n",
      "   Creating path_63 (RT revenue)... ✓\n",
      "   Creating path_64 (RT revenue)... ✓\n",
      "   Creating path_65 (RT revenue)... ✓\n",
      "   Creating path_66 (RT revenue)... ✓\n",
      "   Creating path_67 (RT revenue)... ✓\n",
      "   Creating path_68 (RT revenue)... ✓\n",
      "   Creating path_69 (RT revenue)... ✓\n",
      "   Creating path_70 (RT revenue)... ✓\n",
      "   Creating path_71 (RT revenue)... ✓\n",
      "   Creating path_72 (RT revenue)... ✓\n",
      "   Creating path_73 (RT revenue)... ✓\n",
      "   Creating path_74 (RT revenue)... ✓\n",
      "   Creating path_75 (RT revenue)... ✓\n",
      "   Creating path_76 (RT revenue)... ✓\n",
      "   Creating path_77 (RT revenue)... ✓\n",
      "   Creating path_78 (RT revenue)... ✓\n",
      "   Creating path_79 (RT revenue)... ✓\n",
      "   Creating path_80 (RT revenue)... ✓\n",
      "   Creating path_81 (RT revenue)... ✓\n",
      "   Creating path_82 (RT revenue)... ✓\n",
      "   Creating path_83 (RT revenue)... ✓\n",
      "   Creating path_84 (RT revenue)... ✓\n",
      "   Creating path_85 (RT revenue)... ✓\n",
      "   Creating path_86 (RT revenue)... ✓\n",
      "   Creating path_87 (RT revenue)... ✓\n",
      "   Creating path_88 (RT revenue)... ✓\n",
      "   Creating path_89 (RT revenue)... ✓\n",
      "   Creating path_90 (RT revenue)... ✓\n",
      "   Creating path_91 (RT revenue)... ✓\n",
      "   Creating path_92 (RT revenue)... ✓\n",
      "   Creating path_93 (RT revenue)... ✓\n",
      "   Creating path_94 (RT revenue)... ✓\n",
      "   Creating path_95 (RT revenue)... ✓\n",
      "   Creating path_96 (RT revenue)... ✓\n",
      "   Creating path_97 (RT revenue)... ✓\n",
      "   Creating path_98 (RT revenue)... ✓\n",
      "   Creating path_99 (RT revenue)... ✓\n",
      "   Creating path_100 (RT revenue)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME revenue paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME REVENUE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME revenue timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME revenue)...\n",
      "   ✓ Created historical data (original REAL-TIME revenue):\n",
      "      - Hourly: 112546 records\n",
      "      - Daily: 4689 records\n",
      "      - Monthly: 154 records\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME revenue)...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_hourly_timeseries.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_daily_timeseries.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME revenue)...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_hourly_historical.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_daily_historical.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Revenue_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Revenue_rt/historical/ (original)\n",
      "\n",
      "📌 Note: Revenue calculated from original data, then compressed for forecast\n",
      "\n",
      "[7/7] Processing RE_Mustang_LLC...\n",
      "\n",
      "📁 Loading REAL-TIME bootstrap selections from: RE_Mustang_LLC_bootstrap_selections_rt_latest.json\n",
      "   ✓ Loaded 100 REAL-TIME path selections\n",
      "   ✓ Years used: 2012-2024 (13 years)\n",
      "   ✓ Price type: REAL-TIME\n",
      "   ✓ Price column: price_rt\n",
      "\n",
      "============================================================\n",
      "Processing: RE_Mustang_LLC (REAL-TIME Revenue Pipeline)\n",
      "Month range: Jul to Jun (year-wrapping, 12 months)\n",
      "============================================================\n",
      "\n",
      "📁 Loading data from: RE_Mustang_LLC_generation_price_combined.csv\n",
      "\n",
      "🔍 Filtering data with valid generation AND REAL-TIME prices...\n",
      "   Total rows: 394,589\n",
      "   Rows with valid revenue data: 112,530\n",
      "\n",
      "----------------------------------------\n",
      "COMPRESSION PARAMETER CALCULATION (REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📊 Calculating compression parameters for REAL-TIME REVENUE...\n",
      "   ✓ Calculated compression parameters for 8760 time slots\n",
      "\n",
      "📊 Data summary (REAL-TIME revenue data):\n",
      "   All years available: 2012 to 2024 (13 years)\n",
      "   RT overlap years: 2012 to 2024 (13 years)\n",
      "   Total data points: 112,530\n",
      "\n",
      "----------------------------------------\n",
      "SYNTHETIC PATH GENERATION FROM REAL-TIME BOOTSTRAP\n",
      "----------------------------------------\n",
      "\n",
      "🎲 Generating 100 synthetic revenue paths from REAL-TIME bootstrap...\n",
      "   Creating path_1 (RT revenue)... ✓\n",
      "   Creating path_2 (RT revenue)... ✓\n",
      "   Creating path_3 (RT revenue)... ✓\n",
      "   Creating path_4 (RT revenue)... ✓\n",
      "   Creating path_5 (RT revenue)... ✓\n",
      "   Creating path_6 (RT revenue)... ✓\n",
      "   Creating path_7 (RT revenue)... ✓\n",
      "   Creating path_8 (RT revenue)... ✓\n",
      "   Creating path_9 (RT revenue)... ✓\n",
      "   Creating path_10 (RT revenue)... ✓\n",
      "   Creating path_11 (RT revenue)... ✓\n",
      "   Creating path_12 (RT revenue)... ✓\n",
      "   Creating path_13 (RT revenue)... ✓\n",
      "   Creating path_14 (RT revenue)... ✓\n",
      "   Creating path_15 (RT revenue)... ✓\n",
      "   Creating path_16 (RT revenue)... ✓\n",
      "   Creating path_17 (RT revenue)... ✓\n",
      "   Creating path_18 (RT revenue)... ✓\n",
      "   Creating path_19 (RT revenue)... ✓\n",
      "   Creating path_20 (RT revenue)... ✓\n",
      "   Creating path_21 (RT revenue)... ✓\n",
      "   Creating path_22 (RT revenue)... ✓\n",
      "   Creating path_23 (RT revenue)... ✓\n",
      "   Creating path_24 (RT revenue)... ✓\n",
      "   Creating path_25 (RT revenue)... ✓\n",
      "   Creating path_26 (RT revenue)... ✓\n",
      "   Creating path_27 (RT revenue)... ✓\n",
      "   Creating path_28 (RT revenue)... ✓\n",
      "   Creating path_29 (RT revenue)... ✓\n",
      "   Creating path_30 (RT revenue)... ✓\n",
      "   Creating path_31 (RT revenue)... ✓\n",
      "   Creating path_32 (RT revenue)... ✓\n",
      "   Creating path_33 (RT revenue)... ✓\n",
      "   Creating path_34 (RT revenue)... ✓\n",
      "   Creating path_35 (RT revenue)... ✓\n",
      "   Creating path_36 (RT revenue)... ✓\n",
      "   Creating path_37 (RT revenue)... ✓\n",
      "   Creating path_38 (RT revenue)... ✓\n",
      "   Creating path_39 (RT revenue)... ✓\n",
      "   Creating path_40 (RT revenue)... ✓\n",
      "   Creating path_41 (RT revenue)... ✓\n",
      "   Creating path_42 (RT revenue)... ✓\n",
      "   Creating path_43 (RT revenue)... ✓\n",
      "   Creating path_44 (RT revenue)... ✓\n",
      "   Creating path_45 (RT revenue)... ✓\n",
      "   Creating path_46 (RT revenue)... ✓\n",
      "   Creating path_47 (RT revenue)... ✓\n",
      "   Creating path_48 (RT revenue)... ✓\n",
      "   Creating path_49 (RT revenue)... ✓\n",
      "   Creating path_50 (RT revenue)... ✓\n",
      "   Creating path_51 (RT revenue)... ✓\n",
      "   Creating path_52 (RT revenue)... ✓\n",
      "   Creating path_53 (RT revenue)... ✓\n",
      "   Creating path_54 (RT revenue)... ✓\n",
      "   Creating path_55 (RT revenue)... ✓\n",
      "   Creating path_56 (RT revenue)... ✓\n",
      "   Creating path_57 (RT revenue)... ✓\n",
      "   Creating path_58 (RT revenue)... ✓\n",
      "   Creating path_59 (RT revenue)... ✓\n",
      "   Creating path_60 (RT revenue)... ✓\n",
      "   Creating path_61 (RT revenue)... ✓\n",
      "   Creating path_62 (RT revenue)... ✓\n",
      "   Creating path_63 (RT revenue)... ✓\n",
      "   Creating path_64 (RT revenue)... ✓\n",
      "   Creating path_65 (RT revenue)... ✓\n",
      "   Creating path_66 (RT revenue)... ✓\n",
      "   Creating path_67 (RT revenue)... ✓\n",
      "   Creating path_68 (RT revenue)... ✓\n",
      "   Creating path_69 (RT revenue)... ✓\n",
      "   Creating path_70 (RT revenue)... ✓\n",
      "   Creating path_71 (RT revenue)... ✓\n",
      "   Creating path_72 (RT revenue)... ✓\n",
      "   Creating path_73 (RT revenue)... ✓\n",
      "   Creating path_74 (RT revenue)... ✓\n",
      "   Creating path_75 (RT revenue)... ✓\n",
      "   Creating path_76 (RT revenue)... ✓\n",
      "   Creating path_77 (RT revenue)... ✓\n",
      "   Creating path_78 (RT revenue)... ✓\n",
      "   Creating path_79 (RT revenue)... ✓\n",
      "   Creating path_80 (RT revenue)... ✓\n",
      "   Creating path_81 (RT revenue)... ✓\n",
      "   Creating path_82 (RT revenue)... ✓\n",
      "   Creating path_83 (RT revenue)... ✓\n",
      "   Creating path_84 (RT revenue)... ✓\n",
      "   Creating path_85 (RT revenue)... ✓\n",
      "   Creating path_86 (RT revenue)... ✓\n",
      "   Creating path_87 (RT revenue)... ✓\n",
      "   Creating path_88 (RT revenue)... ✓\n",
      "   Creating path_89 (RT revenue)... ✓\n",
      "   Creating path_90 (RT revenue)... ✓\n",
      "   Creating path_91 (RT revenue)... ✓\n",
      "   Creating path_92 (RT revenue)... ✓\n",
      "   Creating path_93 (RT revenue)... ✓\n",
      "   Creating path_94 (RT revenue)... ✓\n",
      "   Creating path_95 (RT revenue)... ✓\n",
      "   Creating path_96 (RT revenue)... ✓\n",
      "   Creating path_97 (RT revenue)... ✓\n",
      "   Creating path_98 (RT revenue)... ✓\n",
      "   Creating path_99 (RT revenue)... ✓\n",
      "   Creating path_100 (RT revenue)... ✓\n",
      "\n",
      "   ✓ Successfully created 100 REAL-TIME revenue paths with compression\n",
      "\n",
      "----------------------------------------\n",
      "REAL-TIME REVENUE TIMESERIES (COMPRESSED)\n",
      "----------------------------------------\n",
      "\n",
      "⏰ Creating HOURLY REAL-TIME revenue timeseries (compressed)...\n",
      "   ✓ Created compressed timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📅 Creating DAILY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "📊 Creating MONTHLY REAL-TIME revenue timeseries...\n",
      "   ✓ Created timeseries with 13 historical years (RT overlap) and 100 synthetic paths\n",
      "\n",
      "----------------------------------------\n",
      "HISTORICAL DATA PREPARATION (ORIGINAL REAL-TIME REVENUE)\n",
      "----------------------------------------\n",
      "\n",
      "📜 Creating historical continuous data (original REAL-TIME revenue)...\n",
      "   ✓ Created historical data (original REAL-TIME revenue):\n",
      "      - Hourly: 112530 records\n",
      "      - Daily: 4689 records\n",
      "      - Monthly: 154 records\n",
      "\n",
      "----------------------------------------\n",
      "SAVING RESULTS\n",
      "----------------------------------------\n",
      "\n",
      "📈 Saving TIMESERIES files (compressed REAL-TIME revenue)...\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_hourly_timeseries.csv\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_daily_timeseries.csv\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_monthly_timeseries.csv\n",
      "\n",
      "📜 Saving HISTORICAL files (original REAL-TIME revenue)...\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_hourly_historical.csv\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_daily_historical.csv\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_monthly_historical.csv\n",
      "\n",
      "📁 All files saved in:\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Revenue_rt/forecast/timeseries/ (compressed)\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Revenue_rt/historical/ (original)\n",
      "\n",
      "📌 Note: Revenue calculated from original data, then compressed for forecast\n",
      "\n",
      "============================================================\n",
      "✨ PHASE 1c COMPLETE!\n",
      "============================================================\n",
      "\n",
      "📊 Summary:\n",
      "   ✅ Successfully processed: 7 sites\n",
      "\n",
      "📁 Files saved:\n",
      "   • Revenue_rt/forecast/timeseries/ - Compressed REAL-TIME revenue + synthetic paths\n",
      "   • Revenue_rt/historical/ - Original REAL-TIME revenue values\n",
      "\n",
      "📌 Next step: Run Phase 2 for all distribution calculations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RevenueDataPreparation:\n",
    "    \"\"\"\n",
    "    Phase 1c: Create revenue historical data and timeseries (with synthetic paths)\n",
    "    Unified implementation for both DAY-AHEAD and REAL-TIME pipelines\n",
    "    Reads ORIGINAL data, calculates revenue (Gen × Price), applies compression\n",
    "    Uses bootstrap selections from Phase 0\n",
    "    Applies compression for forecast files, keeps original for historical\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline_type='da'):\n",
    "        \"\"\"\n",
    "        Initialize the revenue data preparation\n",
    "        \n",
    "        Args:\n",
    "            pipeline_type (str): 'da' for day-ahead or 'rt' for real-time\n",
    "        \"\"\"\n",
    "        # Validate pipeline type\n",
    "        if pipeline_type not in ['da', 'rt']:\n",
    "            raise ValueError(\"pipeline_type must be 'da' or 'rt'\")\n",
    "        \n",
    "        self.pipeline_type = pipeline_type\n",
    "        \n",
    "        # Define paths\n",
    "        self.data_path = Path('aamani_data')\n",
    "        self.base_output_path = Path('Renewable Portfolio LLC')\n",
    "        \n",
    "        # Set pipeline-specific configurations\n",
    "        if pipeline_type == 'da':\n",
    "            self.bootstrap_path = self.base_output_path / 'bootstrap_selections_da'\n",
    "            self.price_column = 'price_da'\n",
    "            self.revenue_column = 'revenue_da'\n",
    "            self.output_folder = 'Revenue_da'\n",
    "            self.file_prefix = 'revenue_da'\n",
    "            self.pipeline_name = \"DAY-AHEAD\"\n",
    "            self.pipeline_name_short = \"DA\"\n",
    "        else:  # rt\n",
    "            self.bootstrap_path = self.base_output_path / 'bootstrap_selections_rt'\n",
    "            self.price_column = 'price_rt'  # Default, may be overridden per site\n",
    "            self.revenue_column = 'revenue_rt'\n",
    "            self.output_folder = 'Revenue_rt'\n",
    "            self.file_prefix = 'revenue_rt'\n",
    "            self.pipeline_name = \"REAL-TIME\"\n",
    "            self.pipeline_name_short = \"RT\"\n",
    "        \n",
    "        # Get available combined files and create mapping\n",
    "        self.available_files = list(self.data_path.glob('*_generation_price_combined.csv'))\n",
    "        self.available_sites = []\n",
    "        self.site_file_map = {}  # Map clean site names to actual filenames\n",
    "        \n",
    "        for f in self.available_files:\n",
    "            # Store the full filename (without path)\n",
    "            full_filename = f.name\n",
    "            \n",
    "            # Extract site name by removing '_generation_price_combined.csv'\n",
    "            site_name = f.stem.replace('_generation_price_combined', '')\n",
    "            \n",
    "            # Clean up the site name by removing '_hourly' to avoid redundancy\n",
    "            clean_site_name = site_name.replace('_hourly', '')\n",
    "            \n",
    "            self.available_sites.append(clean_site_name)\n",
    "            # Map the clean name to the actual filename\n",
    "            self.site_file_map[clean_site_name] = full_filename\n",
    "        \n",
    "        # Bootstrap selections will be loaded per site\n",
    "        self.bootstrap_selections = None\n",
    "        self.n_synthetic_paths = None\n",
    "        self.bootstrap_metadata = None\n",
    "        \n",
    "        # Define compression thresholds (P15 and P85 for compression)\n",
    "        self.compression_lower = 15\n",
    "        self.compression_upper = 85\n",
    "        \n",
    "        # Month names for labeling\n",
    "        self.month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        self.month_names_full = ['', 'January', 'February', 'March', 'April', 'May', 'June',\n",
    "                                'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    def get_site_selection(self):\n",
    "        \"\"\"\n",
    "        Interactive site selection with bootstrap availability check\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{self.pipeline_name} REVENUE DATA PREPARATION - SITE SELECTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.available_sites:\n",
    "            print(\"❌ No combined generation-price files found in aamani_data!\")\n",
    "            return None\n",
    "        \n",
    "        # Check which sites have bootstrap selections\n",
    "        sites_with_bootstrap = []\n",
    "        for site in self.available_sites:\n",
    "            bootstrap_file = self.bootstrap_path / f\"{site}_bootstrap_selections_{self.pipeline_type}_latest.json\"\n",
    "            if bootstrap_file.exists():\n",
    "                # Verify it's actually the correct bootstrap file\n",
    "                with open(bootstrap_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    expected_type = 'day_ahead' if self.pipeline_type == 'da' else 'real_time'\n",
    "                    if data.get('pipeline_type') == expected_type:\n",
    "                        sites_with_bootstrap.append(site)\n",
    "        \n",
    "        if not sites_with_bootstrap:\n",
    "            print(f\"❌ No {self.pipeline_name} bootstrap selections found!\")\n",
    "            print(f\"   Please run Phase 0 first.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n✅ Found {self.pipeline_name} bootstrap selections for {len(sites_with_bootstrap)} sites\")\n",
    "        \n",
    "        print(\"\\nAvailable options:\")\n",
    "        print(f\"0. ALL SITES (Process all sites with {self.pipeline_name_short} bootstrap selections)\")\n",
    "        for i, site in enumerate(sites_with_bootstrap):\n",
    "            print(f\"{i+1}. {site}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selection = input(\"\\n💰 Select option number (0 for all sites): \").strip()\n",
    "                if selection == '0':\n",
    "                    return 'ALL_SITES', sites_with_bootstrap\n",
    "                else:\n",
    "                    idx = int(selection) - 1\n",
    "                    if 0 <= idx < len(sites_with_bootstrap):\n",
    "                        return sites_with_bootstrap[idx], [sites_with_bootstrap[idx]]\n",
    "                    else:\n",
    "                        print(\"❌ Invalid selection!\")\n",
    "            except:\n",
    "                print(\"❌ Please enter a valid number!\")\n",
    "    \n",
    "    def load_bootstrap_selections(self, site_name):\n",
    "        \"\"\"\n",
    "        Load bootstrap selections for a specific site\n",
    "        \"\"\"\n",
    "        bootstrap_file = self.bootstrap_path / f\"{site_name}_bootstrap_selections_{self.pipeline_type}_latest.json\"\n",
    "        \n",
    "        if not bootstrap_file.exists():\n",
    "            print(f\"❌ {self.pipeline_name} bootstrap selections not found for {site_name}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"\\n📁 Loading {self.pipeline_name} bootstrap selections from: {bootstrap_file.name}\")\n",
    "        \n",
    "        with open(bootstrap_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Verify this is the correct bootstrap file\n",
    "        expected_type = 'day_ahead' if self.pipeline_type == 'da' else 'real_time'\n",
    "        if data.get('pipeline_type') != expected_type:\n",
    "            print(f\"❌ Error: Bootstrap file is not for {self.pipeline_name.lower()} pipeline!\")\n",
    "            return False\n",
    "        \n",
    "        self.bootstrap_selections = data['selections']\n",
    "        self.n_synthetic_paths = data['n_paths']\n",
    "        self.bootstrap_metadata = data['metadata']\n",
    "        \n",
    "        # For RT, get the actual price column used\n",
    "        if self.pipeline_type == 'rt' and 'price_column' in self.bootstrap_metadata:\n",
    "            self.price_column = self.bootstrap_metadata['price_column']\n",
    "        \n",
    "        print(f\"   ✓ Loaded {self.n_synthetic_paths} {self.pipeline_name} path selections\")\n",
    "        print(f\"   ✓ Years used: {self.bootstrap_metadata['year_range']} ({self.bootstrap_metadata['n_years']} years)\")\n",
    "        print(f\"   ✓ Price type: {self.pipeline_name}\")\n",
    "        if self.pipeline_type == 'rt':\n",
    "            print(f\"   ✓ Price column: {self.price_column}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def get_automatic_month_range(self):\n",
    "        \"\"\"\n",
    "        Automatically determine month range: current month to 11 months later\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        start_month = current_month\n",
    "        if start_month == 1:\n",
    "            end_month = 12\n",
    "        else:\n",
    "            end_month = start_month - 1\n",
    "        \n",
    "        print(f\"\\n📅 Auto-detected period: {self.month_names[start_month]} to {self.month_names[end_month]} (12 months)\")\n",
    "        print(f\"   Starting from current month: {self.month_names[current_month]}\")\n",
    "        \n",
    "        return start_month, end_month\n",
    "    \n",
    "    def get_months_in_range(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Get list of months in range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        if start_month <= end_month:\n",
    "            return list(range(start_month, end_month + 1))\n",
    "        else:\n",
    "            return list(range(start_month, 13)) + list(range(1, end_month + 1))\n",
    "    \n",
    "    def filter_data_for_months(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Filter dataframe for month range, handling year-wrapping\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return df[df['month'].isin(months_in_range)].copy()\n",
    "    \n",
    "    def create_month_order_map(self, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create a mapping for sorting months in the specified order\n",
    "        \"\"\"\n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        return {month: idx for idx, month in enumerate(months_in_range)}\n",
    "    \n",
    "    def calculate_compression_parameters(self, df):\n",
    "        \"\"\"\n",
    "        Calculate P15 and P85 for each month-day-hour slot across all years for REVENUE\n",
    "        \"\"\"\n",
    "        print(f\"\\n📊 Calculating compression parameters for {self.pipeline_name} REVENUE...\")\n",
    "        \n",
    "        compression_params = {}\n",
    "        grouped = df.groupby(['month', 'day', 'hour'])\n",
    "        \n",
    "        for (month, day, hour), group in grouped:\n",
    "            if len(group) >= 5 and group[self.revenue_column].notna().sum() >= 5:\n",
    "                revenues = group[self.revenue_column].dropna().values\n",
    "                P_lower = np.percentile(revenues, self.compression_lower)\n",
    "                P_upper = np.percentile(revenues, self.compression_upper)\n",
    "                compression_params[(month, day, hour)] = (P_lower, P_upper)\n",
    "        \n",
    "        print(f\"   ✓ Calculated compression parameters for {len(compression_params)} time slots\")\n",
    "        \n",
    "        return compression_params\n",
    "    \n",
    "    def apply_compression_to_dataframe(self, df, compression_params):\n",
    "        \"\"\"\n",
    "        Apply compression to revenue values in dataframe\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        def compress_value(row):\n",
    "            if pd.isna(row[self.revenue_column]):\n",
    "                return np.nan\n",
    "                \n",
    "            key = (row['month'], row['day'], row['hour'])\n",
    "            if key in compression_params:\n",
    "                P_lower, P_upper = compression_params[key]\n",
    "                value = row[self.revenue_column]\n",
    "                \n",
    "                if value < P_lower:\n",
    "                    offset = P_lower - value\n",
    "                    return P_lower - np.log1p(offset)\n",
    "                elif value > P_upper:\n",
    "                    offset = value - P_upper\n",
    "                    return P_upper + np.log1p(offset)\n",
    "                else:\n",
    "                    return value\n",
    "            else:\n",
    "                return row[self.revenue_column]\n",
    "        \n",
    "        df[f'{self.revenue_column}_compressed'] = df.apply(compress_value, axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def generate_synthetic_paths_from_bootstrap(self, df, compression_params):\n",
    "        \"\"\"\n",
    "        Generate synthetic paths using bootstrap selections\n",
    "        Calculate revenue and apply compression\n",
    "        \"\"\"\n",
    "        print(f\"\\n🎲 Generating {self.n_synthetic_paths} synthetic revenue paths from {self.pipeline_name} bootstrap...\")\n",
    "        \n",
    "        synthetic_data = {}\n",
    "        \n",
    "        for path_name, path_selection in self.bootstrap_selections.items():\n",
    "            print(f\"   Creating {path_name} ({self.pipeline_name_short} revenue)...\", end='')\n",
    "            path_data = []\n",
    "            \n",
    "            # For each month in the selection\n",
    "            for month_name, selected_year in path_selection.items():\n",
    "                if selected_year is None:\n",
    "                    continue\n",
    "                \n",
    "                # Get month number\n",
    "                month_num = self.month_names.index(month_name)\n",
    "                \n",
    "                # Get all data for this year-month combination\n",
    "                month_data = df[(df['year'] == selected_year) & (df['month'] == month_num)].copy()\n",
    "                \n",
    "                if len(month_data) > 0:\n",
    "                    # Calculate revenue for this month\n",
    "                    month_data[self.revenue_column] = month_data['generation_mw'] * month_data[self.price_column]\n",
    "                    \n",
    "                    # Apply compression to this month's revenue\n",
    "                    month_data_compressed = self.apply_compression_to_dataframe(month_data, compression_params)\n",
    "                    path_data.append(month_data_compressed)\n",
    "            \n",
    "            # Combine all months for this path\n",
    "            if path_data:\n",
    "                path_df = pd.concat(path_data, ignore_index=True)\n",
    "                synthetic_data[path_name] = path_df\n",
    "                print(f\" ✓\")\n",
    "            else:\n",
    "                print(f\" ✗ (No data)\")\n",
    "        \n",
    "        print(f\"\\n   ✓ Successfully created {len(synthetic_data)} {self.pipeline_name} revenue paths with compression\")\n",
    "        \n",
    "        return synthetic_data\n",
    "    \n",
    "    def create_hourly_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create hourly timeseries with COMPRESSED revenue values\n",
    "        \"\"\"\n",
    "        print(f\"\\n⏰ Creating HOURLY {self.pipeline_name} revenue timeseries (compressed)...\")\n",
    "        \n",
    "        df_work = df_filtered.copy()\n",
    "        df_work['month_order'] = df_work['month'].map(month_order_map)\n",
    "        \n",
    "        # Use compressed values for historical data\n",
    "        revenue_col_to_use = f'{self.revenue_column}_compressed'\n",
    "        \n",
    "        # Pivot for compressed revenues\n",
    "        pivot_df = df_work.pivot_table(\n",
    "            index=['month', 'day', 'hour', 'month_order'],\n",
    "            columns='year',\n",
    "            values=revenue_col_to_use,\n",
    "            aggfunc='mean'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths (already compressed)\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            path_grouped = path_filtered.groupby(['month', 'day', 'hour'])[revenue_col_to_use].mean()\n",
    "            \n",
    "            pivot_df[path_name] = pivot_df.apply(\n",
    "                lambda row: path_grouped.get((int(row['month']), int(row['day']), int(row['hour'])), np.nan),\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day', 'hour']).reset_index(drop=True)\n",
    "        pivot_df['datetime_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d} {int(row['hour']):02d}:00\",\n",
    "            axis=1\n",
    "        )\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns - only include years that were in overlap\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int) and col in overlap_years])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['datetime_label', 'month', 'day', 'hour'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   ✓ Created compressed timeseries with {len(year_cols)} historical years ({self.pipeline_name_short} overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_daily_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create daily revenue timeseries by summing hourly revenues\n",
    "        \"\"\"\n",
    "        print(f\"\\n📅 Creating DAILY {self.pipeline_name} revenue timeseries...\")\n",
    "        \n",
    "        # Aggregate hourly revenue to daily\n",
    "        df_daily = df_filtered.groupby(['year', 'month', 'day'])[f'{self.revenue_column}_compressed'].sum().reset_index()\n",
    "        df_daily.rename(columns={f'{self.revenue_column}_compressed': f'daily_{self.revenue_column}'}, inplace=True)\n",
    "        df_daily['month_order'] = df_daily['month'].map(month_order_map)\n",
    "        \n",
    "        # Create pivot for historical data\n",
    "        pivot_df = df_daily.pivot_table(\n",
    "            index=['month', 'day', 'month_order'],\n",
    "            columns='year',\n",
    "            values=f'daily_{self.revenue_column}',\n",
    "            aggfunc='sum'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            # Aggregate to daily\n",
    "            path_daily = path_filtered.groupby(['month', 'day'])[f'{self.revenue_column}_compressed'].sum()\n",
    "            \n",
    "            # Add to pivot dataframe\n",
    "            pivot_df[path_name] = pivot_df.apply(\n",
    "                lambda row: path_daily.get((int(row['month']), int(row['day'])), np.nan),\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order', 'day']).reset_index(drop=True)\n",
    "        pivot_df['date_label'] = pivot_df.apply(\n",
    "            lambda row: f\"{self.month_names[int(row['month'])]}-{int(row['day']):02d}\",\n",
    "            axis=1\n",
    "        )\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int) and col in overlap_years])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['date_label', 'month', 'day'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   ✓ Created timeseries with {len(year_cols)} historical years ({self.pipeline_name_short} overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_monthly_timeseries_with_paths(self, df_filtered, synthetic_paths, month_order_map):\n",
    "        \"\"\"\n",
    "        Create monthly revenue timeseries by summing daily revenues\n",
    "        \"\"\"\n",
    "        print(f\"\\n📊 Creating MONTHLY {self.pipeline_name} revenue timeseries...\")\n",
    "        \n",
    "        # Aggregate to monthly\n",
    "        df_monthly = df_filtered.groupby(['year', 'month'])[f'{self.revenue_column}_compressed'].sum().reset_index()\n",
    "        df_monthly.rename(columns={f'{self.revenue_column}_compressed': f'monthly_{self.revenue_column}'}, inplace=True)\n",
    "        df_monthly['month_order'] = df_monthly['month'].map(month_order_map)\n",
    "        \n",
    "        # Create pivot\n",
    "        pivot_df = df_monthly.pivot_table(\n",
    "            index=['month', 'month_order'],\n",
    "            columns='year',\n",
    "            values=f'monthly_{self.revenue_column}',\n",
    "            aggfunc='sum'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add synthetic paths\n",
    "        for path_name, path_data in synthetic_paths.items():\n",
    "            path_filtered = self.filter_data_for_months(path_data, \n",
    "                                                      min(month_order_map.keys()), \n",
    "                                                      max(month_order_map.keys()))\n",
    "            \n",
    "            path_monthly = path_filtered.groupby('month')[f'{self.revenue_column}_compressed'].sum()\n",
    "            \n",
    "            pivot_df[path_name] = pivot_df['month'].apply(\n",
    "                lambda month: path_monthly.get(int(month), np.nan)\n",
    "            )\n",
    "        \n",
    "        # Sort and format\n",
    "        pivot_df = pivot_df.sort_values(['month_order']).reset_index(drop=True)\n",
    "        pivot_df['month_name'] = pivot_df['month'].apply(lambda x: self.month_names_full[int(x)])\n",
    "        pivot_df = pivot_df.drop('month_order', axis=1)\n",
    "        \n",
    "        # Reorder columns\n",
    "        overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "        year_cols = sorted([col for col in pivot_df.columns if isinstance(col, int) and col in overlap_years])\n",
    "        path_cols = sorted([col for col in pivot_df.columns if isinstance(col, str) and col.startswith('path_')])\n",
    "        cols = ['month_name', 'month'] + year_cols + path_cols\n",
    "        pivot_df = pivot_df[cols]\n",
    "        \n",
    "        print(f\"   ✓ Created timeseries with {len(year_cols)} historical years ({self.pipeline_name_short} overlap) and {len(path_cols)} synthetic paths\")\n",
    "        \n",
    "        return pivot_df\n",
    "    \n",
    "    def create_historical_continuous_data(self, df, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Create historical data in continuous format with ORIGINAL (uncompressed) revenue values\n",
    "        \"\"\"\n",
    "        print(f\"\\n📜 Creating historical continuous data (original {self.pipeline_name} revenue)...\")\n",
    "        \n",
    "        # Filter for month range and valid prices AND generation\n",
    "        df_filtered = self.filter_data_for_months(df, start_month, end_month)\n",
    "        df_filtered = df_filtered[(df_filtered[self.price_column].notna()) & \n",
    "                                  (df_filtered['generation_mw'].notna())].copy()\n",
    "        \n",
    "        # Calculate revenue (original values)\n",
    "        df_filtered[self.revenue_column] = df_filtered['generation_mw'] * df_filtered[self.price_column]\n",
    "        \n",
    "        # Hourly historical (original values)\n",
    "        hourly_hist = df_filtered[['datetime', 'year', 'month', 'day', 'hour', \n",
    "                                   'generation_mw', self.price_column, self.revenue_column]].copy()\n",
    "        hourly_hist = hourly_hist.sort_values('datetime').reset_index(drop=True)\n",
    "        \n",
    "        # Daily historical\n",
    "        daily_hist = df_filtered.groupby(['year', 'month', 'day']).agg({\n",
    "            self.revenue_column: 'sum',\n",
    "            'generation_mw': 'sum',\n",
    "            'datetime': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Calculate weighted average price for daily\n",
    "        daily_hist[f'weighted_{self.price_column}'] = daily_hist[self.revenue_column] / daily_hist['generation_mw']\n",
    "        daily_hist['date'] = pd.to_datetime(daily_hist['datetime']).dt.date\n",
    "        daily_hist = daily_hist[['date', 'year', 'month', 'day', self.revenue_column, 'generation_mw', f'weighted_{self.price_column}']]\n",
    "        daily_hist = daily_hist.sort_values('date').reset_index(drop=True)\n",
    "        \n",
    "        # Monthly historical\n",
    "        monthly_hist = df_filtered.groupby(['year', 'month']).agg({\n",
    "            self.revenue_column: 'sum',\n",
    "            'generation_mw': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Calculate weighted average price for monthly\n",
    "        monthly_hist[f'weighted_{self.price_column}'] = monthly_hist[self.revenue_column] / monthly_hist['generation_mw']\n",
    "        monthly_hist['month_year'] = monthly_hist.apply(\n",
    "            lambda row: f\"{row['year']}-{int(row['month']):02d}\", axis=1\n",
    "        )\n",
    "        monthly_hist = monthly_hist[['month_year', 'year', 'month', self.revenue_column, 'generation_mw', f'weighted_{self.price_column}']]\n",
    "        monthly_hist = monthly_hist.sort_values(['year', 'month']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"   ✓ Created historical data (original {self.pipeline_name} revenue):\")\n",
    "        print(f\"      - Hourly: {len(hourly_hist)} records\")\n",
    "        print(f\"      - Daily: {len(daily_hist)} records\")\n",
    "        print(f\"      - Monthly: {len(monthly_hist)} records\")\n",
    "        \n",
    "        return hourly_hist, daily_hist, monthly_hist\n",
    "    \n",
    "    def save_all_results(self, hourly_ts, daily_ts, monthly_ts,\n",
    "                        hourly_hist, daily_hist, monthly_hist, site_name):\n",
    "        \"\"\"\n",
    "        Save timeseries (compressed) and historical (original) files\n",
    "        \"\"\"\n",
    "        # Create folder structure with proper subfolder\n",
    "        revenue_path = self.base_output_path / site_name / self.output_folder\n",
    "        forecast_path = revenue_path / 'forecast'\n",
    "        timeseries_path = forecast_path / 'timeseries'\n",
    "        historical_path = revenue_path / 'historical'\n",
    "        \n",
    "        timeseries_path.mkdir(parents=True, exist_ok=True)\n",
    "        historical_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save timeseries files (COMPRESSED VALUES)\n",
    "        print(f\"\\n📈 Saving TIMESERIES files (compressed {self.pipeline_name} revenue)...\")\n",
    "        \n",
    "        # Format and save timeseries files\n",
    "        for ts_df, ts_name, ts_file in [\n",
    "            (hourly_ts, \"hourly\", f\"{site_name}_{self.file_prefix}_hourly_timeseries.csv\"),\n",
    "            (daily_ts, \"daily\", f\"{site_name}_{self.file_prefix}_daily_timeseries.csv\"),\n",
    "            (monthly_ts, \"monthly\", f\"{site_name}_{self.file_prefix}_monthly_timeseries.csv\")\n",
    "        ]:\n",
    "            ts_save = ts_df.copy()\n",
    "            # Format numeric columns\n",
    "            numeric_cols = [col for col in ts_save.columns if isinstance(col, int) or (isinstance(col, str) and col.startswith('path_'))]\n",
    "            for col in numeric_cols:\n",
    "                ts_save[col] = ts_save[col].apply(lambda x: '' if pd.isna(x) else f'{x:.2f}')\n",
    "            ts_save.to_csv(timeseries_path / ts_file, index=False)\n",
    "            print(f\"   ✓ {ts_file}\")\n",
    "        \n",
    "        # Save historical files (ORIGINAL VALUES)\n",
    "        print(f\"\\n📜 Saving HISTORICAL files (original {self.pipeline_name} revenue)...\")\n",
    "        \n",
    "        # Hourly historical\n",
    "        hourly_hist_file = f\"{site_name}_{self.file_prefix}_hourly_historical.csv\"\n",
    "        hourly_hist.to_csv(historical_path / hourly_hist_file, index=False, float_format='%.2f')\n",
    "        print(f\"   ✓ {hourly_hist_file}\")\n",
    "        \n",
    "        # Daily historical\n",
    "        daily_hist_file = f\"{site_name}_{self.file_prefix}_daily_historical.csv\"\n",
    "        daily_hist.to_csv(historical_path / daily_hist_file, index=False, float_format='%.2f')\n",
    "        print(f\"   ✓ {daily_hist_file}\")\n",
    "        \n",
    "        # Monthly historical\n",
    "        monthly_hist_file = f\"{site_name}_{self.file_prefix}_monthly_historical.csv\"\n",
    "        monthly_hist.to_csv(historical_path / monthly_hist_file, index=False, float_format='%.2f')\n",
    "        print(f\"   ✓ {monthly_hist_file}\")\n",
    "        \n",
    "        print(f\"\\n📁 All files saved in:\")\n",
    "        print(f\"   • Renewable Portfolio LLC/{site_name}/{self.output_folder}/forecast/timeseries/ (compressed)\")\n",
    "        print(f\"   • Renewable Portfolio LLC/{site_name}/{self.output_folder}/historical/ (original)\")\n",
    "        print(f\"\\n📌 Note: Revenue calculated from original data, then compressed for forecast\")\n",
    "    \n",
    "    def process_single_site(self, site_name, start_month, end_month):\n",
    "        \"\"\"\n",
    "        Process a single site with given month range\n",
    "        \"\"\"\n",
    "        # Load bootstrap selections for this site\n",
    "        if not self.load_bootstrap_selections(site_name):\n",
    "            return False\n",
    "        \n",
    "        # Create month order mapping\n",
    "        month_order_map = self.create_month_order_map(start_month, end_month)\n",
    "        \n",
    "        # Load and prepare data\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {site_name} ({self.pipeline_name} Revenue Pipeline)\")\n",
    "        \n",
    "        months_in_range = self.get_months_in_range(start_month, end_month)\n",
    "        num_months = len(months_in_range)\n",
    "        \n",
    "        if start_month <= end_month:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} ({num_months} months)\")\n",
    "        else:\n",
    "            print(f\"Month range: {self.month_names[start_month]} to {self.month_names[end_month]} (year-wrapping, {num_months} months)\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Use the mapping to get the actual filename\n",
    "        actual_filename = self.site_file_map.get(site_name)\n",
    "        if actual_filename:\n",
    "            file_path = self.data_path / actual_filename\n",
    "        else:\n",
    "            # Fallback - try the standard naming convention\n",
    "            file_path = self.data_path / f\"{site_name}_generation_price_combined.csv\"\n",
    "            \n",
    "        print(f\"\\n📁 Loading data from: {file_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            \n",
    "            # Ensure numeric columns are integers\n",
    "            df['year'] = df['year'].astype(int)\n",
    "            df['month'] = df['month'].astype(int)\n",
    "            df['hour'] = df['hour'].astype(int)\n",
    "            df['day'] = df['datetime'].dt.day.astype(int)\n",
    "            \n",
    "            # Filter for valid generation AND price data\n",
    "            print(f\"\\n🔍 Filtering data with valid generation AND {self.pipeline_name} prices...\")\n",
    "            total_rows = len(df)\n",
    "            df_valid = df[(df['generation_mw'].notna()) & (df[self.price_column].notna())].copy()\n",
    "            \n",
    "            # Calculate revenue\n",
    "            df_valid[self.revenue_column] = df_valid['generation_mw'] * df_valid[self.price_column]\n",
    "            rows_with_revenue = len(df_valid)\n",
    "            \n",
    "            print(f\"   Total rows: {total_rows:,}\")\n",
    "            print(f\"   Rows with valid revenue data: {rows_with_revenue:,}\")\n",
    "            \n",
    "            # Calculate compression parameters from ALL data (not just filtered months)\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"COMPRESSION PARAMETER CALCULATION ({self.pipeline_name} REVENUE)\")\n",
    "            print(\"-\"*40)\n",
    "            compression_params = self.calculate_compression_parameters(df_valid)\n",
    "            \n",
    "            # Apply compression to the full dataset\n",
    "            df_compressed = self.apply_compression_to_dataframe(df_valid, compression_params)\n",
    "            \n",
    "            # NOW filter for selected months\n",
    "            df_filtered = self.filter_data_for_months(df_compressed, start_month, end_month)\n",
    "            \n",
    "            # Data summary\n",
    "            years_available = sorted(df_filtered['year'].unique())\n",
    "            overlap_years = set(self.bootstrap_metadata['years_used'])\n",
    "            years_in_overlap = sorted([y for y in years_available if y in overlap_years])\n",
    "            \n",
    "            print(f\"\\n📊 Data summary ({self.pipeline_name} revenue data):\")\n",
    "            print(f\"   All years available: {years_available[0]} to {years_available[-1]} ({len(years_available)} years)\")\n",
    "            print(f\"   {self.pipeline_name_short} overlap years: {years_in_overlap[0]} to {years_in_overlap[-1]} ({len(years_in_overlap)} years)\")\n",
    "            print(f\"   Total data points: {len(df_filtered):,}\")\n",
    "            \n",
    "            # Generate synthetic paths using bootstrap selections\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"SYNTHETIC PATH GENERATION FROM {self.pipeline_name} BOOTSTRAP\")\n",
    "            print(\"-\"*40)\n",
    "            synthetic_paths = self.generate_synthetic_paths_from_bootstrap(df_valid, compression_params)\n",
    "            \n",
    "            # Create timeseries with synthetic paths (COMPRESSED)\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"{self.pipeline_name} REVENUE TIMESERIES (COMPRESSED)\")\n",
    "            print(\"-\"*40)\n",
    "            hourly_ts = self.create_hourly_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            daily_ts = self.create_daily_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            monthly_ts = self.create_monthly_timeseries_with_paths(df_filtered, synthetic_paths, month_order_map)\n",
    "            \n",
    "            # Create historical continuous data (ORIGINAL VALUES)\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(f\"HISTORICAL DATA PREPARATION (ORIGINAL {self.pipeline_name} REVENUE)\")\n",
    "            print(\"-\"*40)\n",
    "            hourly_hist, daily_hist, monthly_hist = self.create_historical_continuous_data(df, start_month, end_month)\n",
    "            \n",
    "            # Save all results\n",
    "            print(\"\\n\" + \"-\"*40)\n",
    "            print(\"SAVING RESULTS\")\n",
    "            print(\"-\"*40)\n",
    "            self.save_all_results(hourly_ts, daily_ts, monthly_ts,\n",
    "                                hourly_hist, daily_hist, monthly_hist,\n",
    "                                site_name)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Error processing {site_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    def run_preparation(self):\n",
    "        \"\"\"\n",
    "        Main function to run the revenue data preparation\n",
    "        \"\"\"\n",
    "        print(f\"\\n💰 {self.pipeline_name} Revenue Data Preparation - Phase 1c\")\n",
    "        print(f\"   (Calculate revenue from original data and apply compression)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get site selection\n",
    "        site_selection = self.get_site_selection()\n",
    "        if not site_selection:\n",
    "            return\n",
    "        \n",
    "        site_selection, sites_to_process = site_selection\n",
    "        \n",
    "        # Get automatic month range\n",
    "        start_month, end_month = self.get_automatic_month_range()\n",
    "        \n",
    "        # Process based on selection\n",
    "        if site_selection == 'ALL_SITES':\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"🚀 PROCESSING ALL SITES - {self.pipeline_name} Revenue\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            for i, site_name in enumerate(sites_to_process, 1):\n",
    "                print(f\"\\n[{i}/{len(sites_to_process)}] Processing {site_name}...\")\n",
    "                \n",
    "                if self.process_single_site(site_name, start_month, end_month):\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"✨ PHASE 1c COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\n📊 Summary:\")\n",
    "            print(f\"   ✅ Successfully processed: {successful} sites\")\n",
    "            if failed > 0:\n",
    "                print(f\"   ❌ Failed: {failed} sites\")\n",
    "            \n",
    "            print(f\"\\n📁 Files saved:\")\n",
    "            print(f\"   • {self.output_folder}/forecast/timeseries/ - Compressed {self.pipeline_name} revenue + synthetic paths\")\n",
    "            print(f\"   • {self.output_folder}/historical/ - Original {self.pipeline_name} revenue values\")\n",
    "            \n",
    "            print(f\"\\n📌 Next step: Run Phase 2 for all distribution calculations\")\n",
    "            \n",
    "        else:\n",
    "            # Process single site\n",
    "            if self.process_single_site(site_selection, start_month, end_month):\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"✨ PHASE 1c COMPLETE!\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\n{self.pipeline_name} Revenue data prepared for {site_selection}\")\n",
    "                print(f\"12-month period: {self.month_names[start_month]} to {self.month_names[end_month]}\")\n",
    "                print(f\"Synthetic paths: {self.n_synthetic_paths} (from {self.pipeline_name_short} bootstrap selections)\")\n",
    "                \n",
    "                print(f\"\\n📁 Files saved in:\")\n",
    "                print(f\"   • Renewable Portfolio LLC/{site_selection}/{self.output_folder}/forecast/timeseries/ (compressed)\")\n",
    "                print(f\"   • Renewable Portfolio LLC/{site_selection}/{self.output_folder}/historical/ (original)\")\n",
    "                \n",
    "                print(f\"\\n💡 Key features:\")\n",
    "                print(f\"   • Revenue calculated from original Gen × {self.pipeline_name_short} Price data\")\n",
    "                print(f\"   • Timeseries use compressed revenue values (P15-P85)\")\n",
    "                print(f\"   • Historical files preserve original revenue values\")\n",
    "                print(f\"   • Synthetic paths use same monthly blocks as generation\")\n",
    "                \n",
    "                print(f\"\\n📌 Next step: Run Phase 2 for all distribution calculations\")\n",
    "        \n",
    "        # Ask if user wants to prepare another site\n",
    "        another = input(f\"\\n🔄 Prepare {self.pipeline_name} revenue data for another site? (y/n): \").strip().lower()\n",
    "        if another == 'y':\n",
    "            self.run_preparation()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask user which pipeline to run\n",
    "    print(\"\\n💰 Revenue Data Preparation\")\n",
    "    print(\"Select pipeline type:\")\n",
    "    print(\"1. Day-Ahead (DA)\")\n",
    "    print(\"2. Real-Time (RT)\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
    "        if choice == '1':\n",
    "            prep = RevenueDataPreparation(pipeline_type='da')\n",
    "            break\n",
    "        elif choice == '2':\n",
    "            prep = RevenueDataPreparation(pipeline_type='rt')\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Invalid choice! Please enter 1 or 2.\")\n",
    "    \n",
    "    prep.run_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d6951",
   "metadata": {},
   "source": [
    "# Phase 2: Unified distribution calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ae5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Distribution Calculator\n",
      "Select pipeline type:\n",
      "1. Day-Ahead (DA)\n",
      "2. Real-Time (RT)\n",
      "\n",
      "🌟 REAL-TIME Distribution Calculator - Phase 2\n",
      "   Calculate distributions for Generation, Price, and Revenue\n",
      "   Using compressed timeseries from Phases 1a, 1b, and 1c\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "REAL-TIME DISTRIBUTION CALCULATOR - SITE SELECTION\n",
      "============================================================\n",
      "\n",
      "✅ Found 7 sites with complete REAL-TIME data\n",
      "   (Generation, Price, and Revenue timeseries)\n",
      "\n",
      "Available options:\n",
      "0. ALL SITES (Process all ready sites)\n",
      "1. Albemarle_Beach_Solar\n",
      "2. Blue_Wing_Solar_Energy_Generator\n",
      "3. Lamesa_Solar\n",
      "4. Midway_Solar_Farm_III\n",
      "5. Misae_Solar\n",
      "6. Mount_Signal_Solar_Farm_II\n",
      "7. RE_Mustang_LLC\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "🚀 PROCESSING ALL SITES\n",
      "============================================================\n",
      "\n",
      "[1/7] Processing Albemarle_Beach_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing distributions for: Albemarle_Beach_Solar\n",
      "============================================================\n",
      "\n",
      "📌 Note: Generation data was created using DA bootstrap\n",
      "   ⚠️  Warning: Current pipeline (RT) differs from generation bootstrap (DA)\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING GENERATION DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY Generation distribution...\n",
      "   Using 146 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY Generation distribution...\n",
      "   Using 146 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY Generation distribution...\n",
      "   Using 146 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE GENERATION DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $344.73\n",
      "   P10: $121.67 | P50: $386.95 | P90: $554.05\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📊 Saving GENERATION distribution files...\n",
      "   ✓ Albemarle_Beach_Solar_generation_hourly_distribution.csv\n",
      "   ✓ Albemarle_Beach_Solar_generation_daily_distribution.csv\n",
      "   ✓ Albemarle_Beach_Solar_generation_monthly_distribution.csv\n",
      "\n",
      "📁 Generation distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Generation/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME PRICE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Price distribution...\n",
      "   Using 114 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Price distribution...\n",
      "   Using 114 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Price distribution...\n",
      "   Using 114 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME PRICE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $26.98\n",
      "   P10: $17.71 | P50: $25.68 | P90: $37.27\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $27.14\n",
      "   P10: $20.26 | P50: $26.06 | P90: $34.33\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME PRICE distribution files...\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_hourly_distribution.csv\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_daily_distribution.csv\n",
      "   ✓ Albemarle_Beach_Solar_price_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Price distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Price_rt/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME REVENUE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Revenue distribution...\n",
      "   Using 114 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Revenue distribution...\n",
      "   Using 114 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Revenue distribution...\n",
      "   Using 114 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME REVENUE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $10,014.42\n",
      "   P10: $3,403.67 | P50: $10,552.22 | P90: $14,481.78\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME REVENUE distribution files...\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_hourly_distribution.csv\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_daily_distribution.csv\n",
      "   ✓ Albemarle_Beach_Solar_revenue_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Revenue distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Albemarle_Beach_Solar/Revenue_rt/forecast/distribution/\n",
      "\n",
      "==================================================\n",
      "REAL-TIME REVENUE SUMMARY\n",
      "==================================================\n",
      "\n",
      "💰 Estimated Annual Revenue:\n",
      "   Mean: $8,637,733.49\n",
      "   P10:  $6,473,414.17\n",
      "   P90:  $11,500,057.05\n",
      "\n",
      "📊 Top Revenue Months:\n",
      "   July     : Mean $1,126,954.36 (P10: $879,873.92, P90: $1,605,941.30)\n",
      "   May      : Mean $999,402.09 (P10: $669,739.53, P90: $1,451,849.68)\n",
      "   June     : Mean $993,823.72 (P10: $758,851.40, P90: $1,343,869.03)\n",
      "\n",
      "[2/7] Processing Blue_Wing_Solar_Energy_Generator...\n",
      "\n",
      "============================================================\n",
      "Processing distributions for: Blue_Wing_Solar_Energy_Generator\n",
      "============================================================\n",
      "\n",
      "📌 Note: Generation data was created using DA bootstrap\n",
      "   ⚠️  Warning: Current pipeline (RT) differs from generation bootstrap (DA)\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING GENERATION DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE GENERATION DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $42.59\n",
      "   P10: $11.10 | P50: $48.69 | P90: $69.45\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📊 Saving GENERATION distribution files...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_hourly_distribution.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_daily_distribution.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_generation_monthly_distribution.csv\n",
      "\n",
      "📁 Generation distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Generation/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME PRICE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME PRICE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $18.09\n",
      "   P10: $11.05 | P50: $19.48 | P90: $21.43\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $20.44\n",
      "   P10: $11.82 | P50: $20.10 | P90: $27.44\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME PRICE distribution files...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_hourly_distribution.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_daily_distribution.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_price_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Price distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Price_rt/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME REVENUE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME REVENUE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $647.48\n",
      "   P10: $197.16 | P50: $648.20 | P90: $1,091.94\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME REVENUE distribution files...\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_hourly_distribution.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_daily_distribution.csv\n",
      "   ✓ Blue_Wing_Solar_Energy_Generator_revenue_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Revenue distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Blue_Wing_Solar_Energy_Generator/Revenue_rt/forecast/distribution/\n",
      "\n",
      "==================================================\n",
      "REAL-TIME REVENUE SUMMARY\n",
      "==================================================\n",
      "\n",
      "💰 Estimated Annual Revenue:\n",
      "   Mean: $662,079.75\n",
      "   P10:  $480,113.46\n",
      "   P90:  $868,252.14\n",
      "\n",
      "📊 Top Revenue Months:\n",
      "   August   : Mean $100,135.01 (P10: $77,784.77, P90: $142,854.01)\n",
      "   July     : Mean $82,196.92 (P10: $59,470.98, P90: $92,046.40)\n",
      "   September: Mean $71,513.77 (P10: $46,224.15, P90: $93,761.43)\n",
      "\n",
      "[3/7] Processing Lamesa_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing distributions for: Lamesa_Solar\n",
      "============================================================\n",
      "\n",
      "📌 Note: Generation data was created using DA bootstrap\n",
      "   ⚠️  Warning: Current pipeline (RT) differs from generation bootstrap (DA)\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING GENERATION DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY Generation distribution...\n",
      "   Using 146 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY Generation distribution...\n",
      "   Using 146 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY Generation distribution...\n",
      "   Using 146 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE GENERATION DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $408.25\n",
      "   P10: $55.62 | P50: $505.31 | P90: $537.12\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📊 Saving GENERATION distribution files...\n",
      "   ✓ Lamesa_Solar_generation_hourly_distribution.csv\n",
      "   ✓ Lamesa_Solar_generation_daily_distribution.csv\n",
      "   ✓ Lamesa_Solar_generation_monthly_distribution.csv\n",
      "\n",
      "📁 Generation distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Generation/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME PRICE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Price distribution...\n",
      "   Using 110 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Price distribution...\n",
      "   Using 110 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Price distribution...\n",
      "   Using 110 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME PRICE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $19.40\n",
      "   P10: $11.65 | P50: $19.52 | P90: $30.29\n",
      "   Based on 109 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $17.37\n",
      "   P10: $6.28 | P50: $17.21 | P90: $25.64\n",
      "   Based on 109 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME PRICE distribution files...\n",
      "   ✓ Lamesa_Solar_price_rt_hourly_distribution.csv\n",
      "   ✓ Lamesa_Solar_price_rt_daily_distribution.csv\n",
      "   ✓ Lamesa_Solar_price_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Price distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Price_rt/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME REVENUE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Revenue distribution...\n",
      "   Using 110 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Revenue distribution...\n",
      "   Using 110 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Revenue distribution...\n",
      "   Using 110 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME REVENUE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 109 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $5,782.88\n",
      "   P10: $1,121.00 | P50: $6,763.70 | P90: $9,010.91\n",
      "   Based on 109 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME REVENUE distribution files...\n",
      "   ✓ Lamesa_Solar_revenue_rt_hourly_distribution.csv\n",
      "   ✓ Lamesa_Solar_revenue_rt_daily_distribution.csv\n",
      "   ✓ Lamesa_Solar_revenue_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Revenue distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Lamesa_Solar/Revenue_rt/forecast/distribution/\n",
      "\n",
      "==================================================\n",
      "REAL-TIME REVENUE SUMMARY\n",
      "==================================================\n",
      "\n",
      "💰 Estimated Annual Revenue:\n",
      "   Mean: $6,602,062.26\n",
      "   P10:  $4,763,171.43\n",
      "   P90:  $8,746,413.39\n",
      "\n",
      "📊 Top Revenue Months:\n",
      "   August   : Mean $1,054,046.40 (P10: $775,692.86, P90: $1,336,457.53)\n",
      "   July     : Mean $1,025,470.60 (P10: $654,610.80, P90: $1,614,752.35)\n",
      "   June     : Mean $771,888.91 (P10: $646,492.61, P90: $881,880.03)\n",
      "\n",
      "[4/7] Processing Midway_Solar_Farm_III...\n",
      "\n",
      "============================================================\n",
      "Processing distributions for: Midway_Solar_Farm_III\n",
      "============================================================\n",
      "\n",
      "📌 Note: Generation data was created using DA bootstrap\n",
      "   ⚠️  Warning: Current pipeline (RT) differs from generation bootstrap (DA)\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING GENERATION DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE GENERATION DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $81.25\n",
      "   P10: $48.34 | P50: $77.83 | P90: $106.65\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📊 Saving GENERATION distribution files...\n",
      "   ✓ Midway_Solar_Farm_III_generation_hourly_distribution.csv\n",
      "   ✓ Midway_Solar_Farm_III_generation_daily_distribution.csv\n",
      "   ✓ Midway_Solar_Farm_III_generation_monthly_distribution.csv\n",
      "\n",
      "📁 Generation distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Generation/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME PRICE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME PRICE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $34.40\n",
      "   P10: $27.90 | P50: $33.47 | P90: $46.59\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $28.19\n",
      "   P10: $20.98 | P50: $26.58 | P90: $36.34\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME PRICE distribution files...\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_hourly_distribution.csv\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_daily_distribution.csv\n",
      "   ✓ Midway_Solar_Farm_III_price_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Price distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Price_rt/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME REVENUE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME REVENUE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $2,070.19\n",
      "   P10: $1,644.49 | P50: $1,982.32 | P90: $2,598.74\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME REVENUE distribution files...\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_hourly_distribution.csv\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_daily_distribution.csv\n",
      "   ✓ Midway_Solar_Farm_III_revenue_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Revenue distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Midway_Solar_Farm_III/Revenue_rt/forecast/distribution/\n",
      "\n",
      "==================================================\n",
      "REAL-TIME REVENUE SUMMARY\n",
      "==================================================\n",
      "\n",
      "💰 Estimated Annual Revenue:\n",
      "   Mean: $1,270,607.18\n",
      "   P10:  $692,415.84\n",
      "   P90:  $1,856,564.49\n",
      "\n",
      "📊 Top Revenue Months:\n",
      "   July     : Mean $194,532.51 (P10: $139,443.64, P90: $246,309.91)\n",
      "   August   : Mean $189,638.30 (P10: $146,509.47, P90: $225,726.13)\n",
      "   June     : Mean $144,506.20 (P10: $96,138.95, P90: $207,462.04)\n",
      "\n",
      "[5/7] Processing Misae_Solar...\n",
      "\n",
      "============================================================\n",
      "Processing distributions for: Misae_Solar\n",
      "============================================================\n",
      "\n",
      "📌 Note: Generation data was created using DA bootstrap\n",
      "   ⚠️  Warning: Current pipeline (RT) differs from generation bootstrap (DA)\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING GENERATION DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE GENERATION DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $852.51\n",
      "   P10: $241.42 | P50: $968.72 | P90: $1306.94\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📊 Saving GENERATION distribution files...\n",
      "   ✓ Misae_Solar_generation_hourly_distribution.csv\n",
      "   ✓ Misae_Solar_generation_daily_distribution.csv\n",
      "   ✓ Misae_Solar_generation_monthly_distribution.csv\n",
      "\n",
      "📁 Generation distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Generation/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME PRICE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME PRICE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $15.57\n",
      "   P10: $6.73 | P50: $18.25 | P90: $21.54\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $21.09\n",
      "   P10: $15.55 | P50: $19.31 | P90: $28.38\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME PRICE distribution files...\n",
      "   ✓ Misae_Solar_price_rt_hourly_distribution.csv\n",
      "   ✓ Misae_Solar_price_rt_daily_distribution.csv\n",
      "   ✓ Misae_Solar_price_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Price distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Price_rt/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME REVENUE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME REVENUE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $14,244.31\n",
      "   P10: $4,448.06 | P50: $16,301.41 | P90: $24,499.22\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME REVENUE distribution files...\n",
      "   ✓ Misae_Solar_revenue_rt_hourly_distribution.csv\n",
      "   ✓ Misae_Solar_revenue_rt_daily_distribution.csv\n",
      "   ✓ Misae_Solar_revenue_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Revenue distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Misae_Solar/Revenue_rt/forecast/distribution/\n",
      "\n",
      "==================================================\n",
      "REAL-TIME REVENUE SUMMARY\n",
      "==================================================\n",
      "\n",
      "💰 Estimated Annual Revenue:\n",
      "   Mean: $16,166,584.83\n",
      "   P10:  $10,802,439.84\n",
      "   P90:  $21,242,678.99\n",
      "\n",
      "📊 Top Revenue Months:\n",
      "   August   : Mean $2,518,689.32 (P10: $1,914,307.35, P90: $2,972,915.96)\n",
      "   July     : Mean $2,432,274.26 (P10: $1,742,654.01, P90: $3,337,144.72)\n",
      "   June     : Mean $1,924,520.65 (P10: $1,522,986.32, P90: $2,535,894.17)\n",
      "\n",
      "[6/7] Processing Mount_Signal_Solar_Farm_II...\n",
      "\n",
      "============================================================\n",
      "Processing distributions for: Mount_Signal_Solar_Farm_II\n",
      "============================================================\n",
      "\n",
      "📌 Note: Generation data was created using DA bootstrap\n",
      "   ⚠️  Warning: Current pipeline (RT) differs from generation bootstrap (DA)\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING GENERATION DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE GENERATION DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $634.82\n",
      "   P10: $413.13 | P50: $654.28 | P90: $825.43\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📊 Saving GENERATION distribution files...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_hourly_distribution.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_daily_distribution.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_generation_monthly_distribution.csv\n",
      "\n",
      "📁 Generation distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Generation/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME PRICE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME PRICE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $29.23\n",
      "   P10: $23.08 | P50: $28.76 | P90: $34.34\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $28.19\n",
      "   P10: $21.12 | P50: $30.40 | P90: $33.43\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME PRICE distribution files...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_hourly_distribution.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_daily_distribution.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_price_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Price distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Price_rt/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME REVENUE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME REVENUE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $16,842.37\n",
      "   P10: $13,566.02 | P50: $15,759.25 | P90: $21,095.06\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME REVENUE distribution files...\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_hourly_distribution.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_daily_distribution.csv\n",
      "   ✓ Mount_Signal_Solar_Farm_II_revenue_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Revenue distribution files saved in:\n",
      "   • Renewable Portfolio LLC/Mount_Signal_Solar_Farm_II/Revenue_rt/forecast/distribution/\n",
      "\n",
      "==================================================\n",
      "REAL-TIME REVENUE SUMMARY\n",
      "==================================================\n",
      "\n",
      "💰 Estimated Annual Revenue:\n",
      "   Mean: $9,916,275.94\n",
      "   P10:  $6,921,012.53\n",
      "   P90:  $13,879,631.79\n",
      "\n",
      "📊 Top Revenue Months:\n",
      "   July     : Mean $1,457,407.61 (P10: $1,051,933.76, P90: $1,791,518.85)\n",
      "   August   : Mean $1,393,920.42 (P10: $1,117,032.58, P90: $1,647,537.66)\n",
      "   June     : Mean $1,138,378.38 (P10: $855,262.32, P90: $1,644,325.30)\n",
      "\n",
      "[7/7] Processing RE_Mustang_LLC...\n",
      "\n",
      "============================================================\n",
      "Processing distributions for: RE_Mustang_LLC\n",
      "============================================================\n",
      "\n",
      "📌 Note: Generation data was created using DA bootstrap\n",
      "   ⚠️  Warning: Current pipeline (RT) differs from generation bootstrap (DA)\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING GENERATION DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY Generation distribution...\n",
      "   Using 145 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE GENERATION DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $333.99\n",
      "   P10: $65.64 | P50: $379.95 | P90: $484.83\n",
      "   Based on 145 scenarios\n",
      "\n",
      "📊 Saving GENERATION distribution files...\n",
      "   ✓ RE_Mustang_LLC_generation_hourly_distribution.csv\n",
      "   ✓ RE_Mustang_LLC_generation_daily_distribution.csv\n",
      "   ✓ RE_Mustang_LLC_generation_monthly_distribution.csv\n",
      "\n",
      "📁 Generation distribution files saved in:\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Generation/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME PRICE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Price distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME PRICE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $35.71\n",
      "   P10: $27.88 | P50: $33.45 | P90: $47.71\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $31.08\n",
      "   P10: $21.91 | P50: $30.67 | P90: $41.89\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME PRICE distribution files...\n",
      "   ✓ RE_Mustang_LLC_price_rt_hourly_distribution.csv\n",
      "   ✓ RE_Mustang_LLC_price_rt_daily_distribution.csv\n",
      "   ✓ RE_Mustang_LLC_price_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Price distribution files saved in:\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Price_rt/forecast/distribution/\n",
      "\n",
      "----------------------------------------\n",
      "PROCESSING REAL-TIME REVENUE DISTRIBUTIONS\n",
      "----------------------------------------\n",
      "\n",
      "⚡ Calculating HOURLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 8784 hourly slots\n",
      "\n",
      "📅 Calculating DAILY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 366 daily slots\n",
      "\n",
      "📊 Calculating MONTHLY REAL-TIME Revenue distribution...\n",
      "   Using 113 scenarios (historical RT years + synthetic paths)\n",
      "   ✓ Calculated distribution for 12 months\n",
      "\n",
      "========================================\n",
      "SAMPLE REAL-TIME REVENUE DISTRIBUTION RESULTS\n",
      "========================================\n",
      "\n",
      "⚡ Hourly Sample - Dec-31 00:00:\n",
      "   Mean: $0.00\n",
      "   P10: $0.00 | P50: $0.00 | P90: $0.00\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📅 Daily Sample - Dec-31:\n",
      "   Mean: $8,604.74\n",
      "   P10: $5,681.51 | P50: $8,084.54 | P90: $13,008.98\n",
      "   Based on 113 scenarios\n",
      "\n",
      "📊 Saving REAL-TIME REVENUE distribution files...\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_hourly_distribution.csv\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_daily_distribution.csv\n",
      "   ✓ RE_Mustang_LLC_revenue_rt_monthly_distribution.csv\n",
      "\n",
      "📁 REAL-TIME Revenue distribution files saved in:\n",
      "   • Renewable Portfolio LLC/RE_Mustang_LLC/Revenue_rt/forecast/distribution/\n",
      "\n",
      "==================================================\n",
      "REAL-TIME REVENUE SUMMARY\n",
      "==================================================\n",
      "\n",
      "💰 Estimated Annual Revenue:\n",
      "   Mean: $6,920,535.85\n",
      "   P10:  $4,390,387.77\n",
      "   P90:  $9,637,498.16\n",
      "\n",
      "📊 Top Revenue Months:\n",
      "   July     : Mean $1,040,519.49 (P10: $820,184.60, P90: $1,335,049.56)\n",
      "   August   : Mean $1,018,725.55 (P10: $738,358.31, P90: $1,283,899.64)\n",
      "   June     : Mean $793,455.45 (P10: $446,836.30, P90: $1,084,111.99)\n",
      "\n",
      "============================================================\n",
      "✨ PHASE 2 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "📊 Summary:\n",
      "   ✅ Successfully processed: 7 sites\n",
      "\n",
      "📁 Distribution files created for:\n",
      "   • Generation/forecast/distribution/\n",
      "   • Price_rt/forecast/distribution/\n",
      "   • Revenue_rt/forecast/distribution/\n",
      "\n",
      "✅ REAL-TIME Pipeline Complete!\n",
      "\n",
      "📌 Pipeline Summary:\n",
      "   Phase 0: Bootstrap selections\n",
      "   Phase 1a: Generation timeseries\n",
      "   Phase 1b: Price timeseries (compressed)\n",
      "   Phase 1c: Revenue timeseries (compressed)\n",
      "   Phase 2: All distributions ✓\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DistributionCalculator:\n",
    "    \"\"\"\n",
    "    Phase 2: Calculate distributions from timeseries files\n",
    "    Unified implementation for both DAY-AHEAD and REAL-TIME pipelines\n",
    "    Handles Generation, Price, and Revenue distributions\n",
    "    Assumes all timeseries files have been created by Phase 1a, 1b, and 1c\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline_type='da'):\n",
    "        \"\"\"\n",
    "        Initialize the distribution calculator\n",
    "        \n",
    "        Args:\n",
    "            pipeline_type (str): 'da' for day-ahead or 'rt' for real-time\n",
    "        \"\"\"\n",
    "        # Validate pipeline type\n",
    "        if pipeline_type not in ['da', 'rt']:\n",
    "            raise ValueError(\"pipeline_type must be 'da' or 'rt'\")\n",
    "        \n",
    "        self.pipeline_type = pipeline_type\n",
    "        \n",
    "        # Define paths\n",
    "        self.base_path = Path('Renewable Portfolio LLC')\n",
    "        \n",
    "        # Set pipeline-specific configurations\n",
    "        if pipeline_type == 'da':\n",
    "            self.price_folder = 'Price_da'\n",
    "            self.revenue_folder = 'Revenue_da'\n",
    "            self.price_prefix = 'price_da'\n",
    "            self.revenue_prefix = 'revenue_da'\n",
    "            self.pipeline_name = \"DAY-AHEAD\"\n",
    "            self.pipeline_name_short = \"DA\"\n",
    "        else:  # rt\n",
    "            self.price_folder = 'Price_rt'\n",
    "            self.revenue_folder = 'Revenue_rt'\n",
    "            self.price_prefix = 'price_rt'\n",
    "            self.revenue_prefix = 'revenue_rt'\n",
    "            self.pipeline_name = \"REAL-TIME\"\n",
    "            self.pipeline_name_short = \"RT\"\n",
    "        \n",
    "        # Get available sites\n",
    "        self.available_sites = []\n",
    "        if self.base_path.exists():\n",
    "            for site_dir in self.base_path.iterdir():\n",
    "                if site_dir.is_dir() and site_dir.name not in ['bootstrap_selections', 'bootstrap_selections_da', 'bootstrap_selections_rt']:\n",
    "                    self.available_sites.append(site_dir.name)\n",
    "        \n",
    "        # Define percentiles to calculate\n",
    "        self.percentiles = [1, 5, 10, 15, 25, 50, 75, 85, 90, 95, 99]\n",
    "        \n",
    "        # Month names for formatting\n",
    "        self.month_names = ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        self.month_names_full = ['', 'January', 'February', 'March', 'April', 'May', 'June',\n",
    "                                'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    def get_site_selection(self):\n",
    "        \"\"\"\n",
    "        Interactive site selection from available sites\n",
    "        Checks for all three data types: Generation, Price, and Revenue\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"{self.pipeline_name} DISTRIBUTION CALCULATOR - SITE SELECTION\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if not self.available_sites:\n",
    "            print(\"❌ No sites found in Renewable Portfolio LLC!\")\n",
    "            print(\"   Please run Phase 1 first to generate timeseries files.\")\n",
    "            return None\n",
    "        \n",
    "        # Check which sites have complete data for this pipeline\n",
    "        sites_ready = []\n",
    "        for site in self.available_sites:\n",
    "            site_path = self.base_path / site\n",
    "            \n",
    "            # Check for all three data types\n",
    "            gen_ts_path = site_path / 'Generation' / 'forecast' / 'timeseries'\n",
    "            price_ts_path = site_path / self.price_folder / 'forecast' / 'timeseries'\n",
    "            revenue_ts_path = site_path / self.revenue_folder / 'forecast' / 'timeseries'\n",
    "            \n",
    "            if gen_ts_path.exists() and price_ts_path.exists() and revenue_ts_path.exists():\n",
    "                sites_ready.append(site)\n",
    "        \n",
    "        if not sites_ready:\n",
    "            print(f\"❌ No sites with complete {self.pipeline_name} timeseries data found!\")\n",
    "            print(f\"   Please run Phases 1a, 1b, and 1c first.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n✅ Found {len(sites_ready)} sites with complete {self.pipeline_name} data\")\n",
    "        print(\"   (Generation, Price, and Revenue timeseries)\")\n",
    "        \n",
    "        print(\"\\nAvailable options:\")\n",
    "        print(\"0. ALL SITES (Process all ready sites)\")\n",
    "        for i, site in enumerate(sites_ready):\n",
    "            print(f\"{i+1}. {site}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selection = input(\"\\n📊 Select option number (0 for all sites): \").strip()\n",
    "                if selection == '0':\n",
    "                    return 'ALL_SITES', sites_ready\n",
    "                else:\n",
    "                    idx = int(selection) - 1\n",
    "                    if 0 <= idx < len(sites_ready):\n",
    "                        return sites_ready[idx], [sites_ready[idx]]\n",
    "                    else:\n",
    "                        print(\"❌ Invalid selection!\")\n",
    "            except:\n",
    "                print(\"❌ Please enter a valid number!\")\n",
    "    \n",
    "    def get_forecast_year(self, month):\n",
    "        \"\"\"\n",
    "        Determine the forecast year for a given month based on current date\n",
    "        \"\"\"\n",
    "        current_date = datetime.now()\n",
    "        current_year = current_date.year\n",
    "        current_month = current_date.month\n",
    "        \n",
    "        # Ensure month is an integer\n",
    "        month = int(month)\n",
    "        \n",
    "        if month >= current_month:\n",
    "            return current_year\n",
    "        else:\n",
    "            return current_year + 1\n",
    "    \n",
    "    def get_scenario_columns(self, df):\n",
    "        \"\"\"\n",
    "        Get all scenario columns (years and paths) from the dataframe\n",
    "        \"\"\"\n",
    "        scenario_cols = []\n",
    "        for col in df.columns:\n",
    "            if isinstance(col, str):\n",
    "                if col.startswith('path_') or col.isdigit():\n",
    "                    scenario_cols.append(col)\n",
    "            elif isinstance(col, int):\n",
    "                scenario_cols.append(col)\n",
    "        \n",
    "        return scenario_cols\n",
    "    \n",
    "    def calculate_hourly_distribution(self, hourly_ts_path, data_type='generation'):\n",
    "        \"\"\"\n",
    "        Calculate hourly distribution from timeseries file\n",
    "        \"\"\"\n",
    "        print(f\"\\n⚡ Calculating HOURLY {data_type} distribution...\")\n",
    "        \n",
    "        # Read the timeseries file\n",
    "        df = pd.read_csv(hourly_ts_path)\n",
    "        \n",
    "        # Get scenario columns\n",
    "        scenario_cols = self.get_scenario_columns(df)\n",
    "        print(f\"   Using {len(scenario_cols)} scenarios (historical {self.pipeline_name_short} years + synthetic paths)\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # For each hour in the timeseries\n",
    "        for idx, row in df.iterrows():\n",
    "            # Get values from all scenarios\n",
    "            values = []\n",
    "            for col in scenario_cols:\n",
    "                val = row[col]\n",
    "                if pd.notna(val) and val != '':\n",
    "                    try:\n",
    "                        values.append(float(val))\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            if len(values) >= 5:  # Need at least 5 values for statistics\n",
    "                values_array = np.array(values)\n",
    "                \n",
    "                forecast_year = self.get_forecast_year(row['month'])\n",
    "                \n",
    "                stats = {\n",
    "                    'datetime_label': row['datetime_label'],\n",
    "                    'year': forecast_year,\n",
    "                    'month': int(row['month']),\n",
    "                    'day': int(row['day']),\n",
    "                    'hour': int(row['hour']),\n",
    "                    'mean': values_array.mean(),\n",
    "                    'std_dev': values_array.std(),\n",
    "                    'count': len(values),\n",
    "                    'min': values_array.min(),\n",
    "                    'max': values_array.max()\n",
    "                }\n",
    "                \n",
    "                # Calculate percentiles\n",
    "                for p in self.percentiles:\n",
    "                    stats[f'p{p}'] = np.percentile(values_array, p)\n",
    "                \n",
    "                results.append(stats)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(f\"   ✓ Calculated distribution for {len(results_df)} hourly slots\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def calculate_daily_distribution(self, daily_ts_path, data_type='generation'):\n",
    "        \"\"\"\n",
    "        Calculate daily distribution from timeseries file\n",
    "        \"\"\"\n",
    "        print(f\"\\n📅 Calculating DAILY {data_type} distribution...\")\n",
    "        \n",
    "        # Read the timeseries file\n",
    "        df = pd.read_csv(daily_ts_path)\n",
    "        \n",
    "        # Get scenario columns\n",
    "        scenario_cols = self.get_scenario_columns(df)\n",
    "        print(f\"   Using {len(scenario_cols)} scenarios (historical {self.pipeline_name_short} years + synthetic paths)\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # For each day in the timeseries\n",
    "        for idx, row in df.iterrows():\n",
    "            # Get values from all scenarios\n",
    "            values = []\n",
    "            for col in scenario_cols:\n",
    "                val = row[col]\n",
    "                if pd.notna(val) and val != '':\n",
    "                    try:\n",
    "                        values.append(float(val))\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            if len(values) >= 5:  # Need at least 5 values for statistics\n",
    "                values_array = np.array(values)\n",
    "                \n",
    "                forecast_year = self.get_forecast_year(row['month'])\n",
    "                \n",
    "                stats = {\n",
    "                    'date_label': row['date_label'],\n",
    "                    'year': forecast_year,\n",
    "                    'month': int(row['month']),\n",
    "                    'day': int(row['day']),\n",
    "                    'mean': values_array.mean(),\n",
    "                    'std_dev': values_array.std(),\n",
    "                    'count': len(values),\n",
    "                    'min': values_array.min(),\n",
    "                    'max': values_array.max()\n",
    "                }\n",
    "                \n",
    "                # Calculate percentiles\n",
    "                for p in self.percentiles:\n",
    "                    stats[f'p{p}'] = np.percentile(values_array, p)\n",
    "                \n",
    "                results.append(stats)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(f\"   ✓ Calculated distribution for {len(results_df)} daily slots\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def calculate_monthly_distribution(self, monthly_ts_path, data_type='generation'):\n",
    "        \"\"\"\n",
    "        Calculate monthly distribution from timeseries file\n",
    "        \"\"\"\n",
    "        print(f\"\\n📊 Calculating MONTHLY {data_type} distribution...\")\n",
    "        \n",
    "        # Read the timeseries file\n",
    "        df = pd.read_csv(monthly_ts_path)\n",
    "        \n",
    "        # Get scenario columns\n",
    "        scenario_cols = self.get_scenario_columns(df)\n",
    "        print(f\"   Using {len(scenario_cols)} scenarios (historical {self.pipeline_name_short} years + synthetic paths)\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # For each month in the timeseries\n",
    "        for idx, row in df.iterrows():\n",
    "            # Get values from all scenarios\n",
    "            values = []\n",
    "            for col in scenario_cols:\n",
    "                val = row[col]\n",
    "                if pd.notna(val) and val != '':\n",
    "                    try:\n",
    "                        values.append(float(val))\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            if len(values) >= 5:  # Need at least 5 values for statistics\n",
    "                values_array = np.array(values)\n",
    "                \n",
    "                month_idx = int(row['month'])\n",
    "                forecast_year = self.get_forecast_year(month_idx)\n",
    "                \n",
    "                stats = {\n",
    "                    'month_name': row['month_name'],\n",
    "                    'year': forecast_year,\n",
    "                    'month': month_idx,\n",
    "                    'mean': values_array.mean(),\n",
    "                    'std_dev': values_array.std(),\n",
    "                    'count': len(values),\n",
    "                    'min': values_array.min(),\n",
    "                    'max': values_array.max()\n",
    "                }\n",
    "                \n",
    "                # Calculate percentiles\n",
    "                for p in self.percentiles:\n",
    "                    stats[f'p{p}'] = np.percentile(values_array, p)\n",
    "                \n",
    "                results.append(stats)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(f\"   ✓ Calculated distribution for {len(results_df)} months\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def save_distributions(self, hourly_dist, daily_dist, monthly_dist, site_name, data_type, folder_name, file_prefix):\n",
    "        \"\"\"\n",
    "        Generic function to save distribution files\n",
    "        \"\"\"\n",
    "        # Create distribution folder\n",
    "        dist_path = self.base_path / site_name / folder_name / 'forecast' / 'distribution'\n",
    "        dist_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n📊 Saving {data_type.upper()} distribution files...\")\n",
    "        \n",
    "        # Determine float format based on data type\n",
    "        float_fmt = '%.3f' if 'generation' in data_type.lower() else '%.2f'\n",
    "        \n",
    "        # Hourly distribution\n",
    "        hourly_dist_file = f\"{site_name}_{file_prefix}_hourly_distribution.csv\"\n",
    "        cols_hourly = ['datetime_label', 'year', 'month', 'day', 'hour', 'mean', 'std_dev'] + \\\n",
    "                     [f'p{p}' for p in self.percentiles] + ['min', 'max', 'count']\n",
    "        \n",
    "        hourly_dist[cols_hourly].to_csv(dist_path / hourly_dist_file, index=False, float_format=float_fmt)\n",
    "        print(f\"   ✓ {hourly_dist_file}\")\n",
    "        \n",
    "        # Daily distribution\n",
    "        daily_dist_file = f\"{site_name}_{file_prefix}_daily_distribution.csv\"\n",
    "        cols_daily = ['date_label', 'year', 'month', 'day', 'mean', 'std_dev'] + \\\n",
    "                    [f'p{p}' for p in self.percentiles] + ['min', 'max', 'count']\n",
    "        \n",
    "        daily_dist[cols_daily].to_csv(dist_path / daily_dist_file, index=False, float_format=float_fmt)\n",
    "        print(f\"   ✓ {daily_dist_file}\")\n",
    "        \n",
    "        # Monthly distribution\n",
    "        monthly_dist_file = f\"{site_name}_{file_prefix}_monthly_distribution.csv\"\n",
    "        cols_monthly = ['month_name', 'year', 'month', 'mean', 'std_dev'] + \\\n",
    "                      [f'p{p}' for p in self.percentiles] + ['min', 'max', 'count']\n",
    "        \n",
    "        monthly_dist[cols_monthly].to_csv(dist_path / monthly_dist_file, index=False, float_format=float_fmt)\n",
    "        print(f\"   ✓ {monthly_dist_file}\")\n",
    "        \n",
    "        print(f\"\\n📁 {data_type} distribution files saved in:\")\n",
    "        print(f\"   • Renewable Portfolio LLC/{site_name}/{folder_name}/forecast/distribution/\")\n",
    "    \n",
    "    def print_distribution_sample(self, hourly_dist, daily_dist, monthly_dist, data_type='generation'):\n",
    "        \"\"\"\n",
    "        Print sample results from distributions\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(f\"SAMPLE {data_type.upper()} DISTRIBUTION RESULTS\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # Sample hourly distribution\n",
    "        if not hourly_dist.empty:\n",
    "            sample_idx = len(hourly_dist) // 2  # Middle of the period\n",
    "            if sample_idx < len(hourly_dist):\n",
    "                row = hourly_dist.iloc[sample_idx]\n",
    "                print(f\"\\n⚡ Hourly Sample - {row['datetime_label']}:\")\n",
    "                if data_type == 'generation':\n",
    "                    print(f\"   Mean: {row['mean']:.2f} MW\")\n",
    "                    print(f\"   P10: {row['p10']:.2f} MW | P50: {row['p50']:.2f} MW | P90: {row['p90']:.2f} MW\")\n",
    "                elif 'revenue' in data_type.lower():\n",
    "                    print(f\"   Mean: ${row['mean']:,.2f}\")\n",
    "                    print(f\"   P10: ${row['p10']:,.2f} | P50: ${row['p50']:,.2f} | P90: ${row['p90']:,.2f}\")\n",
    "                else:\n",
    "                    print(f\"   Mean: ${row['mean']:.2f}\")\n",
    "                    print(f\"   P10: ${row['p10']:.2f} | P50: ${row['p50']:.2f} | P90: ${row['p90']:.2f}\")\n",
    "                print(f\"   Based on {int(row['count'])} scenarios\")\n",
    "        \n",
    "        # Sample daily distribution\n",
    "        if not daily_dist.empty:\n",
    "            sample_idx = len(daily_dist) // 2\n",
    "            if sample_idx < len(daily_dist):\n",
    "                row = daily_dist.iloc[sample_idx]\n",
    "                print(f\"\\n📅 Daily Sample - {row['date_label']}:\")\n",
    "                if data_type == 'generation':\n",
    "                    print(f\"   Mean: {row['mean']:.2f} MWh\")\n",
    "                    print(f\"   P10: {row['p10']:.2f} MWh | P50: {row['p50']:.2f} MWh | P90: {row['p90']:.2f} MWh\")\n",
    "                elif 'revenue' in data_type.lower():\n",
    "                    print(f\"   Mean: ${row['mean']:,.2f}\")\n",
    "                    print(f\"   P10: ${row['p10']:,.2f} | P50: ${row['p50']:,.2f} | P90: ${row['p90']:,.2f}\")\n",
    "                else:\n",
    "                    print(f\"   Mean: ${row['mean']:.2f}\")\n",
    "                    print(f\"   P10: ${row['p10']:.2f} | P50: ${row['p50']:.2f} | P90: ${row['p90']:.2f}\")\n",
    "                print(f\"   Based on {int(row['count'])} scenarios\")\n",
    "    \n",
    "    def process_distributions(self, site_name, data_type, folder_name, file_prefix):\n",
    "        \"\"\"\n",
    "        Generic function to process distributions for any data type\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(f\"PROCESSING {data_type.upper()} DISTRIBUTIONS\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Define paths to timeseries files\n",
    "        ts_path = self.base_path / site_name / folder_name / 'forecast' / 'timeseries'\n",
    "        \n",
    "        hourly_ts_file = ts_path / f\"{site_name}_{file_prefix}_hourly_timeseries.csv\"\n",
    "        daily_ts_file = ts_path / f\"{site_name}_{file_prefix}_daily_timeseries.csv\"\n",
    "        monthly_ts_file = ts_path / f\"{site_name}_{file_prefix}_monthly_timeseries.csv\"\n",
    "        \n",
    "        # Check if files exist\n",
    "        if not all([hourly_ts_file.exists(), daily_ts_file.exists(), monthly_ts_file.exists()]):\n",
    "            print(f\"❌ Missing {data_type} timeseries files for {site_name}\")\n",
    "            return False\n",
    "        \n",
    "        # Calculate distributions\n",
    "        hourly_dist = self.calculate_hourly_distribution(hourly_ts_file, data_type)\n",
    "        daily_dist = self.calculate_daily_distribution(daily_ts_file, data_type)\n",
    "        monthly_dist = self.calculate_monthly_distribution(monthly_ts_file, data_type)\n",
    "        \n",
    "        # Print sample results\n",
    "        self.print_distribution_sample(hourly_dist, daily_dist, monthly_dist, data_type)\n",
    "        \n",
    "        # Save distribution files\n",
    "        self.save_distributions(hourly_dist, daily_dist, monthly_dist, site_name, data_type, folder_name, file_prefix)\n",
    "        \n",
    "        # Print revenue summary if processing revenue\n",
    "        if 'revenue' in data_type.lower():\n",
    "            self.print_revenue_summary(monthly_dist, data_type)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def print_revenue_summary(self, monthly_dist, revenue_type):\n",
    "        \"\"\"\n",
    "        Print summary of revenue results\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"{revenue_type.upper()} SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Annual revenue estimate (sum of monthly means)\n",
    "        annual_revenue_mean = monthly_dist['mean'].sum()\n",
    "        annual_revenue_p10 = monthly_dist['p10'].sum()\n",
    "        annual_revenue_p90 = monthly_dist['p90'].sum()\n",
    "        \n",
    "        print(f\"\\n💰 Estimated Annual Revenue:\")\n",
    "        print(f\"   Mean: ${annual_revenue_mean:,.2f}\")\n",
    "        print(f\"   P10:  ${annual_revenue_p10:,.2f}\")\n",
    "        print(f\"   P90:  ${annual_revenue_p90:,.2f}\")\n",
    "        \n",
    "        # Monthly breakdown - top 3 months\n",
    "        top_months = monthly_dist.nlargest(3, 'mean')\n",
    "        print(f\"\\n📊 Top Revenue Months:\")\n",
    "        for _, row in top_months.iterrows():\n",
    "            print(f\"   {row['month_name']:9s}: Mean ${row['mean']:,.2f} (P10: ${row['p10']:,.2f}, P90: ${row['p90']:,.2f})\")\n",
    "    \n",
    "    def check_generation_metadata(self, site_name):\n",
    "        \"\"\"\n",
    "        Check which bootstrap was used for generation data\n",
    "        \"\"\"\n",
    "        metadata_file = self.base_path / site_name / 'Generation' / 'generation_metadata.json'\n",
    "        if metadata_file.exists():\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "                return metadata.get('bootstrap_type', 'unknown')\n",
    "        return 'unknown'\n",
    "    \n",
    "    def process_single_site(self, site_name):\n",
    "        \"\"\"\n",
    "        Process all distributions for a single site\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing distributions for: {site_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Check which bootstrap was used for generation\n",
    "        gen_bootstrap = self.check_generation_metadata(site_name)\n",
    "        if gen_bootstrap != 'unknown':\n",
    "            gen_pipeline = 'DA' if gen_bootstrap == 'da' else 'RT'\n",
    "            print(f\"\\n📌 Note: Generation data was created using {gen_pipeline} bootstrap\")\n",
    "            if gen_bootstrap != self.pipeline_type:\n",
    "                print(f\"   ⚠️  Warning: Current pipeline ({self.pipeline_name_short}) differs from generation bootstrap ({gen_pipeline})\")\n",
    "        \n",
    "        success = True\n",
    "        \n",
    "        try:\n",
    "            # Process Generation distributions\n",
    "            if not self.process_distributions(site_name, 'Generation', 'Generation', 'generation'):\n",
    "                success = False\n",
    "            \n",
    "            # Process Price distributions (pipeline-specific)\n",
    "            if not self.process_distributions(site_name, f'{self.pipeline_name} Price', self.price_folder, self.price_prefix):\n",
    "                success = False\n",
    "            \n",
    "            # Process Revenue distributions (pipeline-specific)\n",
    "            if not self.process_distributions(site_name, f'{self.pipeline_name} Revenue', self.revenue_folder, self.revenue_prefix):\n",
    "                success = False\n",
    "            \n",
    "            return success\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Error processing {site_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    def run_calculator(self):\n",
    "        \"\"\"\n",
    "        Main function to run the distribution calculator\n",
    "        \"\"\"\n",
    "        print(f\"\\n🌟 {self.pipeline_name} Distribution Calculator - Phase 2\")\n",
    "        print(f\"   Calculate distributions for Generation, Price, and Revenue\")\n",
    "        print(f\"   Using compressed timeseries from Phases 1a, 1b, and 1c\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get site selection\n",
    "        site_selection = self.get_site_selection()\n",
    "        if not site_selection:\n",
    "            return\n",
    "        \n",
    "        site_selection, sites_to_process = site_selection\n",
    "        \n",
    "        # Process based on selection\n",
    "        if site_selection == 'ALL_SITES':\n",
    "            # Process all sites\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"🚀 PROCESSING ALL SITES\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            successful = 0\n",
    "            failed = 0\n",
    "            \n",
    "            for i, site_name in enumerate(sites_to_process, 1):\n",
    "                print(f\"\\n[{i}/{len(sites_to_process)}] Processing {site_name}...\")\n",
    "                \n",
    "                if self.process_single_site(site_name):\n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"✨ PHASE 2 COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"\\n📊 Summary:\")\n",
    "            print(f\"   ✅ Successfully processed: {successful} sites\")\n",
    "            if failed > 0:\n",
    "                print(f\"   ❌ Failed: {failed} sites\")\n",
    "            \n",
    "            print(f\"\\n📁 Distribution files created for:\")\n",
    "            print(f\"   • Generation/forecast/distribution/\")\n",
    "            print(f\"   • {self.price_folder}/forecast/distribution/\")\n",
    "            print(f\"   • {self.revenue_folder}/forecast/distribution/\")\n",
    "            \n",
    "        else:\n",
    "            # Process single site\n",
    "            if self.process_single_site(site_selection):\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"✨ PHASE 2 COMPLETE!\")\n",
    "                print(\"=\"*60)\n",
    "                print(f\"\\nDistributions calculated for {site_selection}\")\n",
    "                \n",
    "                print(f\"\\n📁 Files saved in:\")\n",
    "                print(f\"   • {site_selection}/Generation/forecast/distribution/\")\n",
    "                print(f\"   • {site_selection}/{self.price_folder}/forecast/distribution/\")\n",
    "                print(f\"   • {site_selection}/{self.revenue_folder}/forecast/distribution/\")\n",
    "        \n",
    "        print(f\"\\n✅ {self.pipeline_name} Pipeline Complete!\")\n",
    "        print(f\"\\n📌 Pipeline Summary:\")\n",
    "        print(f\"   Phase 0: Bootstrap selections\")\n",
    "        print(f\"   Phase 1a: Generation timeseries\")\n",
    "        print(f\"   Phase 1b: Price timeseries (compressed)\")\n",
    "        print(f\"   Phase 1c: Revenue timeseries (compressed)\")\n",
    "        print(f\"   Phase 2: All distributions ✓\")\n",
    "        \n",
    "        # Ask if user wants to process another site\n",
    "        another = input(\"\\n🔄 Calculate distributions for another site? (y/n): \").strip().lower()\n",
    "        if another == 'y':\n",
    "            self.run_calculator()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Ask user which pipeline to run\n",
    "    print(\"\\n📊 Distribution Calculator\")\n",
    "    print(\"Select pipeline type:\")\n",
    "    print(\"1. Day-Ahead (DA)\")\n",
    "    print(\"2. Real-Time (RT)\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
    "        if choice == '1':\n",
    "            calc = DistributionCalculator(pipeline_type='da')\n",
    "            break\n",
    "        elif choice == '2':\n",
    "            calc = DistributionCalculator(pipeline_type='rt')\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Invalid choice! Please enter 1 or 2.\")\n",
    "    \n",
    "    calc.run_calculator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
